[
  {
    "objectID": "13_Tutorials_GrowthMixtureModels.html",
    "href": "13_Tutorials_GrowthMixtureModels.html",
    "title": "Growth Mixture Models",
    "section": "",
    "text": "Growth Mixture Models (GMMs) are a type of statistical model that aims to identify distinct subgroups or classes within a population based on their growth trajectories. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a Growth Mixture Model using the lcmm package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lcmm package, which provides functions for fitting Growth Mixture Models."
  },
  {
    "objectID": "13_Tutorials_GrowthMixtureModels.html#overview",
    "href": "13_Tutorials_GrowthMixtureModels.html#overview",
    "title": "Growth Mixture Models",
    "section": "",
    "text": "Growth Mixture Models (GMMs) are a type of statistical model that aims to identify distinct subgroups or classes within a population based on their growth trajectories. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a Growth Mixture Model using the lcmm package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lcmm package, which provides functions for fitting Growth Mixture Models."
  },
  {
    "objectID": "13_Tutorials_GrowthMixtureModels.html#basic-example",
    "href": "13_Tutorials_GrowthMixtureModels.html#basic-example",
    "title": "Growth Mixture Models",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Install the lcmm package if not already installed\nif (!(\"lcmm\" %in% installed.packages())) {\n  install.packages(\"lcmm\")\n}\n\n\nLoad the lcmm package\n\n\nCode\nlibrary(lcmm)\n\n\nSimulating the Data For this tutorial, we will use a simulated dataset with three growth trajectory classes, where each class represents a different pattern of change over time. The dataset will consist of 300 individuals with four repeated measurements (time points) for each individual.\n\n\nCode\nset.seed(123)\nn &lt;- 300\ntimepoints &lt;- 4\n\n# Simulate the data for each class\nclass1 &lt;- data.frame(id = 1:(n / 3),\n                     time = rep(1:timepoints, each = n / 3),\n                     class = 1,\n                     value = rnorm(n * timepoints / 3, mean = 1 + 0.5 * (1:timepoints), sd = 0.5))\n\nclass2 &lt;- data.frame(id = (n / 3 + 1):(2 * n / 3),\n                     time = rep(1:timepoints, each = n / 3),\n                     class = 2,\n                     value = rnorm(n * timepoints / 3, mean = 2 - 0.3 * (1:timepoints), sd = 0.5))\n\nclass3 &lt;- data.frame(id = (2 * n / 3 + 1):n,\n                     time = rep(1:timepoints, each = n / 3),\n                     class = 3,\n                     value = rnorm(n * timepoints / 3, mean = 3 + 0.1 * (1:timepoints), sd = 0.5))\n\n\n\n\nCode\n# Combine the data from all classes\ndata &lt;- rbind(class1, class2, class3)\n\n\n\nModel Specification and Estimation\nNow that we have our simulated data, we can fit a Growth Mixture Model. In this example, we will assume that there are three latent classes. However, in practice, the number of classes is usually unknown and must be determined through model comparisons or other methods.\n\n\nCode\n# Fit the Growth Mixture Model\ngmm &lt;- hlme(value ~ time,\n            random = ~ time,\n            subject = \"id\",\n            mixture = ~ time,\n            data = data,\n            ng = 3,\n            B = list(value = c(1, 0, 0, 0)\n\n\n\n\nInterpreting the Results\nxxxxxx"
  },
  {
    "objectID": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html",
    "href": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "",
    "text": "Random-Intercept Cross-Lagged Panel Models (RI-CLPM) are a type of structural equation model used to analyze longitudinal data with repeated measures of multiple variables. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a RI-CLPM using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including RI-CLPMs.\n\n\nCode\n# Install the lavaan package if not already installed\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}\n# Load the lavaan package\nlibrary(lavaan)"
  },
  {
    "objectID": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#overview",
    "href": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#overview",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "",
    "text": "Random-Intercept Cross-Lagged Panel Models (RI-CLPM) are a type of structural equation model used to analyze longitudinal data with repeated measures of multiple variables. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a RI-CLPM using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including RI-CLPMs.\n\n\nCode\n# Install the lavaan package if not already installed\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}\n# Load the lavaan package\nlibrary(lavaan)"
  },
  {
    "objectID": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#basic-example",
    "href": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#basic-example",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "Basic Example",
    "text": "Basic Example\nSimulating the Data For this tutorial, we will use a simulated dataset with 500 individuals, each measured at five time points. The dataset will contain two variables, X and Y, with cross-lagged effects.\n\n\nCode\nset.seed(123)\nn &lt;- 500\ntimepoints &lt;- 5\n\n# Simulate the data\ndata &lt;- data.frame(id = rep(1:n, each = timepoints),\n                   time = rep(1:timepoints, times = n),\n                   X = rnorm(n * timepoints, mean = 0, sd = 1),\n                   Y = rnorm(n * timepoints, mean = 0, sd = 1))\n\n# Introduce cross-lagged effects\nfor (i in 2:timepoints) {\n  data$X[data$time == i] &lt;- 0.3 * data$Y[data$time == (i - 1)] + data$X[data$time == i]\n  data$Y[data$time == i] &lt;- 0.2 * data$X[data$time == (i - 1)] + data$Y[data$time == i]\n}\n\n\n\nModel Specification and Estimation\nNow that we have our simulated data, we can fit a Random-Intercept Cross-Lagged Panel Model using the lavaan package.\n\n\nCode\n# Define the model\nmodel &lt;- '\n  # Random intercepts\n  i_X =~ 1 * X_t1 + 1 * X_t2 + 1 * X_t3 + 1 * X_t4 + 1 * X_t5\n  i_Y =~ 1 * Y_t1 + 1 * Y_t2 + 1 * Y_t3 + 1 * Y_t4 + 1 * Y_t5\n\n  # Cross-lagged effects\n  Y_t2 ~ beta_YX * X_t1\n  Y_t3 ~ beta_YX * X_t2\n  Y_t4 ~ beta_YX * X_t3\n  Y_t5 ~ beta_YX * X_t4\n\n  X_t2 ~ beta_XY * Y_t1\n  X_t3 ~ beta_XY *\n\n\n\n\nInterpreting the Results\nxxxxxx"
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html",
    "href": "5_Tutorials_MarginalModels.html",
    "title": "Marginal Models",
    "section": "",
    "text": "Marginal models are a statistical method used to analyze longitudinal or clustered data. The marginal model estimates the average effect of the independent variables on the outcome while accounting for the within-subject correlation, and allows for the estimation of population-averaged effects, in contrast to subject-specific effects estimated by random-effects models (Verbeke & Molenberghs, 2000). The method is similar to the GEE approach but uses a different estimation technique and does not account for subject-specific effects. Marginal models have been shown to be robust to non-normality and non-constant variance, and can handle unbalanced or unequally spaced data (Fitzmaurice et al., 2011). The term marginal in this context is used to emphasize that the model for the mean response at each occasion depends only on the covariates of interest, and not on any random effects or previous responses.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal marginal models and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal marginal models.\nFit a longitudinal marginal model using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html#overview",
    "href": "5_Tutorials_MarginalModels.html#overview",
    "title": "Marginal Models",
    "section": "",
    "text": "Marginal models are a statistical method used to analyze longitudinal or clustered data. The marginal model estimates the average effect of the independent variables on the outcome while accounting for the within-subject correlation, and allows for the estimation of population-averaged effects, in contrast to subject-specific effects estimated by random-effects models (Verbeke & Molenberghs, 2000). The method is similar to the GEE approach but uses a different estimation technique and does not account for subject-specific effects. Marginal models have been shown to be robust to non-normality and non-constant variance, and can handle unbalanced or unequally spaced data (Fitzmaurice et al., 2011). The term marginal in this context is used to emphasize that the model for the mean response at each occasion depends only on the covariates of interest, and not on any random effects or previous responses.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal marginal models and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal marginal models.\nFit a longitudinal marginal model using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html#basic-example",
    "href": "5_Tutorials_MarginalModels.html#basic-example",
    "title": "Marginal Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\nModel Specification and Estimation\nWe will use the geepack package in R to fit a longitudinal marginal model. First, install and load the required package:\n\n\nCode\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"geepack\")\nlibrary(geepack)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\n\nFit the longitudinal marginal model with a binary outcome using a logit link function:\n\n\nCode\nmodel &lt;- geeglm(outcome ~ time, data = data, id = subject_id, family = binomial(link = \"logit\"), corstr = \"exchangeable\")\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal marginal model, we can use the summary() function in R to display the estimated population-averaged effects:\n\n\nCode\nsummary(model)\n\n\n\nCall:\ngeeglm(formula = outcome ~ time, family = binomial(link = \"logit\"), \n    data = data, id = subject_id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err Wald Pr(&gt;|W|)\n(Intercept)   -43.54     NaN  NaN      NaN\ntime           82.78     NaN  NaN      NaN\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept) 2.22e-16     NaN\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha     -0.5     NaN\nNumber of clusters:   2  Maximum cluster size: 3 \n\n\nThe output will show the estimated effect of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level."
  },
  {
    "objectID": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html",
    "href": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "",
    "text": "xxxx Autoregressive cross-lagged panel models (ACPMs) are a type of statistical model used to analyze longitudinal data and examine the temporal relationships between two or more variables over time. These models help to disentangle within-person effects from between-person effects and can estimate both autoregressive effects (influence of a variable on itself over time) and cross-lagged effects (influence of one variable on another variable over time).\nautoregressive cross-lagged panel models, commonly known as CLPMs. CLPMs are a statistical method used to analyze longitudinal data, particularly when we want to examine the reciprocal relationships between two or more variables over time. In essence, CLPMs allow us to investigate whether one variable at an earlier time point can predict another variable at a later time point, and vice versa.\nCLPMs are useful when we want to go beyond simple correlations between variables at different time points and instead model the dynamic interplay between them. Specifically, CLPMs account for the possibility that the relationship between two variables at one time point may influence their relationship at a subsequent time point. These models can also account for autocorrelation, meaning that the same variable measured over time is correlated with itself.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of autoregressive cross-lagged panel models (ACPMs) and guide you through a simple example using a larger dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of ACPMs.\nFit an ACPM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#overview",
    "href": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#overview",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "",
    "text": "xxxx Autoregressive cross-lagged panel models (ACPMs) are a type of statistical model used to analyze longitudinal data and examine the temporal relationships between two or more variables over time. These models help to disentangle within-person effects from between-person effects and can estimate both autoregressive effects (influence of a variable on itself over time) and cross-lagged effects (influence of one variable on another variable over time).\nautoregressive cross-lagged panel models, commonly known as CLPMs. CLPMs are a statistical method used to analyze longitudinal data, particularly when we want to examine the reciprocal relationships between two or more variables over time. In essence, CLPMs allow us to investigate whether one variable at an earlier time point can predict another variable at a later time point, and vice versa.\nCLPMs are useful when we want to go beyond simple correlations between variables at different time points and instead model the dynamic interplay between them. Specifically, CLPMs account for the possibility that the relationship between two variables at one time point may influence their relationship at a subsequent time point. These models can also account for autocorrelation, meaning that the same variable measured over time is correlated with itself.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of autoregressive cross-lagged panel models (ACPMs) and guide you through a simple example using a larger dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of ACPMs.\nFit an ACPM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#basic-example",
    "href": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#basic-example",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simulated dataset containing the following information for a group of 100 individuals:\n\nSubject ID\nTime (in years)\nVariable 1 (e.g., stress level)\nVariable 2 (e.g., job satisfaction)\n\n\n\nCode\nset.seed(123)  # For reproducibility\nn_subjects &lt;- 100\nn_timepoints &lt;- 3\nsubject_ids &lt;- factor(rep(1:n_subjects, each = n_timepoints))\ntime &lt;- rep(0:(n_timepoints - 1), times = n_subjects)\nvariable1 &lt;- rnorm(n_subjects * n_timepoints, mean = 3, sd = 1)\nvariable2 &lt;- rnorm(n_subjects * n_timepoints, mean = 3, sd = 1)\n\ndata &lt;- data.frame(subject_id = subject_ids, time = time, variable1 = variable1, variable2 = variable2)\n\n\n\nModel Specification and Estimation\nWe will use the lavaan package in R to fit an ACPM. First, install the required package, if not already installed:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nlibrary(lavaan)\n\n\nDefine the ACPM with three timepoints:\n\n\nCode\nmodel &lt;- \n  # Autoregressive paths\n  variable1_t2 ~ a1 * variable1_t1\n  variable1_t1 ~ a2 * variable1_t0\n\n\nvariable1_t1 ~ a2 * variable1_t0\n\n\nCode\n  variable2_t2 ~ a3 * variable2_t1\n\n\nvariable2_t2 ~ a3 * variable2_t1\n\n\nCode\n  variable2_t1 ~ a4 * variable2_t0\n\n\nvariable2_t1 ~ a4 * variable2_t0\n\n\nCode\n  # Cross-lagged paths\n  variable1_t2 ~ b1 * variable2_t1\n\n\nvariable1_t2 ~ b1 * variable2_t1\n\n\nCode\n  variable1_t1 ~ b2 * variable2_t0\n\n\nvariable1_t1 ~ b2 * variable2_t0\n\n\nCode\n  variable2_t2 ~ b3 * variable1_t1\n\n\nvariable2_t2 ~ b3 * variable1_t1\n\n\nCode\n  variable2_t1 ~ b4 * variable1_t0\n\n\nvariable2_t1 ~ b4 * variable1_t0\n\n\nFit the ACPM using the lavaan function:\n\n\nCode\n#fit &lt;- lavaan(model, data = data, missing = )\n\n\n\n\nInterpreting the Results\nxxxxxxxx"
  },
  {
    "objectID": "16_Tutorials_LatentCurveModelsStructuredResiduals.html",
    "href": "16_Tutorials_LatentCurveModelsStructuredResiduals.html",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "",
    "text": "In this tutorial, we will explore Latent Curve Models with Structured Residuals (LCM-SR). LCM-SR allows for the separation of between-person and within-person components of individual change over time. By using structured residuals, we can account for time-varying covariates and interactions between variables at both the within-person and between-person levels.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nYou need to have the lavaan and semTools packages installed in R to perform LCM-SR. Install them using the following commands:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nif (!(\"semTools\" %in% installed.packages())) install.packages(\"semTools\")"
  },
  {
    "objectID": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#overview",
    "href": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#overview",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "",
    "text": "In this tutorial, we will explore Latent Curve Models with Structured Residuals (LCM-SR). LCM-SR allows for the separation of between-person and within-person components of individual change over time. By using structured residuals, we can account for time-varying covariates and interactions between variables at both the within-person and between-person levels.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nYou need to have the lavaan and semTools packages installed in R to perform LCM-SR. Install them using the following commands:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nif (!(\"semTools\" %in% installed.packages())) install.packages(\"semTools\")"
  },
  {
    "objectID": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#basic-example",
    "href": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#basic-example",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use simulated data with 500 individuals and 5 timepoints. The data will include a time-varying covariate, covariate, and an outcome variable, outcome.\n\n\nCode\nset.seed(123)\nlibrary(lavaan)\nlibrary(semTools)\n\n# Simulate data\nn &lt;- 500\ntimepoints &lt;- 5\n\nid &lt;- rep(1:n, each = timepoints)\ntime &lt;- rep(1:timepoints, n)\n\ncovariate &lt;- rnorm(n * timepoints, mean = 0, sd = 1)\noutcome &lt;- rnorm(n * timepoints, mean = 0, sd = 1)\n\ndata &lt;- data.frame(id, time, covariate, outcome)\n\n\n\nModel Specification and Estimation\nTo specify an LCM-SR, we will use the lavaan syntax to define the measurement model and the structural model. We will model the linear growth of the outcome variable while accounting for the effect of the time-varying covariate.\n\n\nCode\nmodel &lt;- '\n  # Latent variables\n  intercept =~ 1 * outcome_t1 + 1 * outcome_t2 + 1 * outcome_t3 + 1 * outcome_t4 + 1 * outcome_t5\n  slope =~ 0 * outcome_t1 + 1 * outcome_t2 + 2 * outcome_t3 + 3 * outcome_t4 + 4 * outcome_t5\n\n  # Time-varying covariate effect on outcome\n  outcome_t1 ~ c1 * covariate_t1\n  outcome_t2 ~ c2 * covariate_t2\n  outcome_t3 ~ c3 * covariate_t3\n  outcome_t4 ~ c4 * covariate_t4\n  outcome_t5 ~ c5 * covariate_t5\n\n  # Residual variances and covariances\n  outcome_t1 ~~ r1 * outcome_t1\n  outcome_t2 ~~ r2 * outcome_t2\n  outcome_t3 ~~ r3 * outcome_t3\n  outcome_t4 ~~ r4 * outcome_t4\n  outcome_t5 ~~ r5 * outcome_t5\n\n  # Latent variable variances\n  intercept ~~ i_var * intercept\n  slope ~~ s_var * slope\n\n  # Latent variable covariances\n  intercept ~~ i_s_cov * slope\n'\n\n\nModel Estimation Now we will estimate the model using the lavaan function sem().\n\n\nCode\n# Reshape data to wide format\nwide_data &lt;- spread(data, key = time, value = outcome, sep\n\n\n\n\nInterpreting the Results\nxxxxx"
  },
  {
    "objectID": "10_Tutorials_LatentGrowthCurveModels.html",
    "href": "10_Tutorials_LatentGrowthCurveModels.html",
    "title": "Latent Growth Curve Models",
    "section": "",
    "text": "In this tutorial, we’ll introduce Latent Growth Curve Models (LGCM), a powerful technique for analyzing longitudinal data. Latent Growth Curve Models allow researchers to examine individual differences in growth trajectories and the factors that might influence these trajectories. We’ll walk through an example using a dataset with three time points and a sample size of 250 participants.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "10_Tutorials_LatentGrowthCurveModels.html#overview",
    "href": "10_Tutorials_LatentGrowthCurveModels.html#overview",
    "title": "Latent Growth Curve Models",
    "section": "",
    "text": "In this tutorial, we’ll introduce Latent Growth Curve Models (LGCM), a powerful technique for analyzing longitudinal data. Latent Growth Curve Models allow researchers to examine individual differences in growth trajectories and the factors that might influence these trajectories. We’ll walk through an example using a dataset with three time points and a sample size of 250 participants.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "10_Tutorials_LatentGrowthCurveModels.html#basic-example",
    "href": "10_Tutorials_LatentGrowthCurveModels.html#basic-example",
    "title": "Latent Growth Curve Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we’ll use a hypothetical dataset called “data” with the following variables:\nsubject_id: A unique identifier for each participant score_t1: The measurement of a variable of interest at Time 1 score_t2: The measurement of the same variable at Time 2 score_t3: The measurement of the same variable at Time 3 First, let’s load the “lavaan” package and create a dataset for this example:\n\n\nCode\nlibrary(lavaan)\n\n# Create a sample dataset with 250 participants\nset.seed(42) # For reproducibility\nsubject_id &lt;- 1:250\nscore_t1 &lt;- rnorm(250, mean = 20, sd = 5)\nscore_t2 &lt;- score_t1 + rnorm(250, mean = 2, sd = 3)\nscore_t3 &lt;- score_t2 + rnorm(250, mean = 3, sd = 4)\ndata &lt;- data.frame(subject_id, score_t1, score_t2, score_t3)\n\n\n\nModel Specification and Estimation\nNow, let’s specify the Latent Growth Curve Model. In this example, we’ll estimate the intercept (initial level) and slope (rate of change) for the variable of interest, as well as the variances of the intercept and slope.\n\n\nCode\n# Define the Latent Growth Curve Model\nmodel &lt;- '\n  # Latent variables\n    i =~ 1 * score_t1 + 1 * score_t2 + 1 * score_t3\n    s =~ 0 * score_t1 + 1 * score_t2 + 2 * score_t3\n\n  # Means\n    i ~ mu_i\n    s ~ mu_s\n\n  # Variances\n    i ~~ var_i * i\n    s ~~ var_s * s\n\n  # Covariance\n    i ~~ cov_is * s\n'\n\n\n\n\nCode\n# Fit the model\nfit &lt;- sem(model, data = data, missing = \"FIML\")\n\n\n\n\nInterpreting the Results\nWe can now examine the results of our Latent Growth Curve Model. The main parameters of interest are:\nmu_i: The mean intercept (initial level) of the variable of interest mu_s: The mean slope (rate of change) of the variable of interest var_i: The variance of the intercept, which reflects individual differences in initial levels var_s: The variance of the slope, which reflects individual differences in rates"
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html",
    "href": "4_Tutorials_SignedRankTest.html",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The longitudinal signed-rank test is a nonparametric alternative to the paired t-test and is appropriate when the data are not normally distributed or when the assumptions of the paired t-test are violated. The test is based on the signed-rank of the differences between the paired observations, and it tests the null hypothesis that the median of the differences is zero. The repeated-measures design allows for the assessment of within-subject changes over time or under different conditions. The signed-rank test is robust to outliers and does not assume a normal distribution of the differences. This method has been shown to have good statistical power and efficiency, particularly when the sample size is small or the distribution is heavily skewed (Erceg-Hurn & Mirosevich, 2008; Bakdash & Marusich, 2017; Garcia-Berthou & Alcaraz, 2004). The signed-rank test is a useful tool for analyzing paired data when the assumption of normality is violated or when the data is highly skewed or contains outliers.\n[+add diagrams/figures]\n\n\nYou should use a Wilcoxon Signed-Rank Test in the following scenario:\n\nYou want to know if two groups are different on your variable of interest\nYour variable of interest is continuous\nYou have two and only two groups\nYou have independent samples\nYou have a skewed variable of interest\n\n\n\n\nIn this tutorial, we will introduce the concept of the longitudinal signed-rank test and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of the longitudinal signed-rank test.\nPerform a longitudinal signed-rank test using example data in R.\nInterpret the results of the test."
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html#overview",
    "href": "4_Tutorials_SignedRankTest.html#overview",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The longitudinal signed-rank test is a nonparametric alternative to the paired t-test and is appropriate when the data are not normally distributed or when the assumptions of the paired t-test are violated. The test is based on the signed-rank of the differences between the paired observations, and it tests the null hypothesis that the median of the differences is zero. The repeated-measures design allows for the assessment of within-subject changes over time or under different conditions. The signed-rank test is robust to outliers and does not assume a normal distribution of the differences. This method has been shown to have good statistical power and efficiency, particularly when the sample size is small or the distribution is heavily skewed (Erceg-Hurn & Mirosevich, 2008; Bakdash & Marusich, 2017; Garcia-Berthou & Alcaraz, 2004). The signed-rank test is a useful tool for analyzing paired data when the assumption of normality is violated or when the data is highly skewed or contains outliers.\n[+add diagrams/figures]\n\n\nYou should use a Wilcoxon Signed-Rank Test in the following scenario:\n\nYou want to know if two groups are different on your variable of interest\nYour variable of interest is continuous\nYou have two and only two groups\nYou have independent samples\nYou have a skewed variable of interest\n\n\n\n\nIn this tutorial, we will introduce the concept of the longitudinal signed-rank test and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of the longitudinal signed-rank test.\nPerform a longitudinal signed-rank test using example data in R.\nInterpret the results of the test."
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html#basic-example",
    "href": "4_Tutorials_SignedRankTest.html#basic-example",
    "title": "Signed-Rank Test",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime point 1 (T1) measurement\nTime point 2 (T2) measurement\n\n\n\n\nSubject ID\nT1\nT2\n\n\n\n\n1\n100\n105\n\n\n2\n95\n100\n\n\n3\n110\n112\n\n\n\n\nModel Specification and Estimation\nWe will use the wilcox.test() function in R to perform a longitudinal signed-rank test. First, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 2, 3),\n  t1 = c(100, 95, 110),\n  t2 = c(105, 100, 112)\n)\n\n\nPerform the longitudinal signed-rank test using the wilcox.test() function with the paired = TRUE argument:\n\n\nCode\ntest_result &lt;- wilcox.test(data$t1, data$t2, paired = TRUE)\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal signed-rank test, examine the p-value from the test_result object:\n\n\nCode\ntest_result$p.value\n\n\n[1] 0.1735682\n\n\nThe p-value represents the probability of observing the data if there is no difference between the measurements at T1 and T2. If the p-value is less than a predetermined significance level (e.g., 0.05), we can reject the null hypothesis that there is no difference between the two time points and conclude that there is a significant difference in the measurements between T1 and T2."
  },
  {
    "objectID": "11_Tutorials_MultivariateLatentGrowthCurveModels.html",
    "href": "11_Tutorials_MultivariateLatentGrowthCurveModels.html",
    "title": "Multivariate Latent Growth Curves",
    "section": "",
    "text": "In this tutorial, we will introduce the Multivariate Latent Growth Curve Model (MLGCM), also known as Parallel Process Latent Growth Curve Model. These models allow us to analyze multiple growth processes simultaneously, examining the relationships between the initial levels and growth rates of multiple variables over time.\nWe will use the “lavaan” package in R to fit a MLGCM with two variables, each measured at three timepoints. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#overview",
    "href": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#overview",
    "title": "Multivariate Latent Growth Curves",
    "section": "",
    "text": "In this tutorial, we will introduce the Multivariate Latent Growth Curve Model (MLGCM), also known as Parallel Process Latent Growth Curve Model. These models allow us to analyze multiple growth processes simultaneously, examining the relationships between the initial levels and growth rates of multiple variables over time.\nWe will use the “lavaan” package in R to fit a MLGCM with two variables, each measured at three timepoints. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#basic-example",
    "href": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#basic-example",
    "title": "Multivariate Latent Growth Curves",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Load necessary packages\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nlibrary(lavaan)\n\n# Generate sample data\nset.seed(42)\nn &lt;- 250\ntime1_var1 &lt;- rnorm(n, mean = 10, sd = 3)\ntime2_var1 &lt;- time1_var1 + rnorm(n, mean = 2, sd = 2)\ntime3_var1 &lt;- time2_var1 + rnorm(n, mean = 2, sd = 2)\n\ntime1_var2 &lt;- rnorm(n, mean = 5, sd = 2)\ntime2_var2 &lt;- time1_var2 + rnorm(n, mean = 1, sd = 1)\ntime3_var2 &lt;- time2_var2 + rnorm(n, mean = 1, sd = 1)\n\n# Combine into a data frame\ndata &lt;- data.frame(time1_var1, time2_var1, time3_var1,\n                   time1_var2, time2_var2, time3_var2)\n\n\n\nModel Specification and Estimation\n\n\nCode\n# Specify the multivariate latent growth curve model\nmodel &lt;- '\n  # Intercept and slope factors for variable 1\n  i_var1 =~ 1*time1_var1 + 1*time2_var1 + 1*time3_var1\n  s_var1 =~ 0*time1_var1 + 1*time2_var1 + 2*time3_var1\n\n  # Intercept and slope factors for variable 2\n  i_var2 =~ 1*time1_var2 + 1*time2_var2 + 1*time3_var2\n  s_var2 =~ 0*time1_var2 + 1*time2_var2 + 2*time3_var2\n'\n\n\n\n\nCode\n# Estimate the model\nfit &lt;- lavaan::sem(model, data = data)\n\n\n\n\nCode\nsummary(fit, fit.measures = TRUE)\n\n\nlavaan 0.6-12 ended normally after 63 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 1.840\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.871\n\nModel Test Baseline Model:\n\n  Test statistic                              1631.463\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.006\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2900.271\n  Loglikelihood unrestricted model (H1)      -2899.351\n                                                      \n  Akaike (AIC)                                5832.542\n  Bayesian (BIC)                              5888.886\n  Sample-size adjusted Bayesian (BIC)         5838.164\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.045\n  P-value RMSEA &lt;= 0.05                          0.961\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.010\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i_var1 =~                                           \n    time1_var1        1.000                           \n    time2_var1        1.000                           \n    time3_var1        1.000                           \n  s_var1 =~                                           \n    time1_var1        0.000                           \n    time2_var1        1.000                           \n    time3_var1        2.000                           \n  i_var2 =~                                           \n    time1_var2        1.000                           \n    time2_var2        1.000                           \n    time3_var2        1.000                           \n  s_var2 =~                                           \n    time1_var2        0.000                           \n    time2_var2        1.000                           \n    time3_var2        2.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i_var1 ~~                                           \n    s_var1            0.240    0.365    0.658    0.511\n    i_var2           -0.157    0.394   -0.400    0.689\n    s_var2            0.015    0.123    0.121    0.904\n  s_var1 ~~                                           \n    i_var2           -0.057    0.183   -0.310    0.757\n    s_var2            0.102    0.058    1.771    0.077\n  i_var2 ~~                                           \n    s_var2           -0.185    0.127   -1.454    0.146\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .time1_var1       -0.101    0.520   -0.194    0.846\n   .time2_var1        1.999    0.344    5.807    0.000\n   .time3_var1        0.031    0.733    0.043    0.966\n   .time1_var2       -0.348    0.190   -1.826    0.068\n   .time2_var2        0.689    0.116    5.950    0.000\n   .time3_var2       -0.460    0.224   -2.055    0.040\n    i_var1            8.630    0.931    9.274    0.000\n    s_var1            1.866    0.336    5.557    0.000\n    i_var2            4.947    0.481   10.291    0.000\n    s_var2            0.647    0.108    5.979    0.000\n\n\n\n\nInterpreting the Results\nIn the output, you will see the estimates for the factor loadings, intercepts, and slopes for both variables. These estimates describe the initial levels and growth rates for each variable. You will also see the variances and covariances of the latent intercept and slope factors, which provide information about individual differences in initial levels and growth rates, as well as the relationships between the initial levels and growth rates across the two variables.\nPay attention to the model fit indices (e.g., CFI, TLI, RMSEA, and SRMR) to evaluate how well the model fits the data. Good model fit is indicated by CFI and TLI values close to or greater than 0.95, RMSEA values close to or smaller than 0.06, and SRMR values close to or smaller than xxx"
  },
  {
    "objectID": "6_Tutorials_GeneralizedEstimatingEquations.html",
    "href": "6_Tutorials_GeneralizedEstimatingEquations.html",
    "title": "Generalized Estimating Equations",
    "section": "",
    "text": "[*add diagrams/figures]"
  },
  {
    "objectID": "6_Tutorials_GeneralizedEstimatingEquations.html#overview",
    "href": "6_Tutorials_GeneralizedEstimatingEquations.html#overview",
    "title": "Generalized Estimating Equations",
    "section": "Overview",
    "text": "Overview\nGeneralized estimating equations (GEEs) are a statistical method used to analyze longitudinal or clustered data, while accounting for within-subject correlation. The goal GEEs are to make inferences about population-averaged effects (controlling for within-subject correlations), rather than individual subject-level effects. GEEs can handle a wide range of outcome distributions, including binary, count, and continuous data (Fitzmaurice et al., 2011; Hardin & Hilbe, 2012). This method is an extension of the generalized linear model (Diggle et al., 2002), shows good statistical power and efficiency, is robust to non-normality and non-constant variance and can handle unbalanced or unequally spaced data.\n\nWhen to use Longitudinal Generalized Estimating Equations (GEEs)?\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\nGetting Started with Longitudinal Generalized Estimating Equations (GEEs)\nIn this tutorial, we will introduce the concept of longitudinal generalized estimating equations (GEEs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GEEs.\nFit a GEE model using example data in R.\nInterpret the results of the model.\n\n\n\nBasic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\n\nModel Specification and Estimation\nWe will use the geepack package in R to fit a longitudinal GEE model. First, install and load the required package:\n\n\nCode\nif (!(\"geepack\" %in% installed.packages())) install.packages(\"geepack\")\nlibrary(geepack)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\n\nFit the longitudinal GEE model with a binary outcome using a logit link function and an exchangeable correlation structure:\n\n\nCode\nmodel &lt;- geeglm(outcome ~ time, data = data, id = subject_id, family = binomial(link = \"logit\"), corstr = \"exchangeable\")\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal GEE model, we can use the summary() function in R to display the estimated population-averaged effects:\n\n\nCode\nsummary(model)\n\n\n\nCall:\ngeeglm(formula = outcome ~ time, family = binomial(link = \"logit\"), \n    data = data, id = subject_id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err Wald Pr(&gt;|W|)\n(Intercept)   -43.54     NaN  NaN      NaN\ntime           82.78     NaN  NaN      NaN\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept) 2.22e-16     NaN\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha     -0.5     NaN\nNumber of clusters:   2  Maximum cluster size: 3 \n\n\nThe output will show the estimated effect of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level."
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html",
    "href": "14_Tutorials_StateTraitModels.html",
    "title": "State-Trait Models",
    "section": "",
    "text": "State-Trait Models are a type of statistical model used to separate the variance in a given variable into two components: a stable, trait-like component and a time-specific, state-like component. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a State-Trait Model using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including State-Trait Models."
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html#overview",
    "href": "14_Tutorials_StateTraitModels.html#overview",
    "title": "State-Trait Models",
    "section": "",
    "text": "State-Trait Models are a type of statistical model used to separate the variance in a given variable into two components: a stable, trait-like component and a time-specific, state-like component. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a State-Trait Model using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including State-Trait Models."
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html#basic-example",
    "href": "14_Tutorials_StateTraitModels.html#basic-example",
    "title": "State-Trait Models",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Install the lavaan package if not already installed\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html#simulating-the-data",
    "href": "14_Tutorials_StateTraitModels.html#simulating-the-data",
    "title": "State-Trait Models",
    "section": "Simulating the Data",
    "text": "Simulating the Data\nFor this tutorial, we will use a simulated dataset with 300 individuals, each measured at four time points. The dataset will contain a variable with both state-like and trait-like components.\n\n\nCode\nset.seed(123)\nn &lt;- 300\ntimepoints &lt;- 4\n\n# Simulate the trait-like component\ntrait &lt;- rnorm(n, mean = 100, sd = 10)\n\n# Simulate the state-like component\nstate &lt;- matrix(rnorm(n * timepoints, mean = 0, sd = 5), nrow = n, ncol = timepoints)\n\n# Combine trait and state components\ndata &lt;- data.frame(id = rep(1:n, each = timepoints),\n                   time = rep(1:timepoints, times = n),\n                   value = c(t(trait + state)))\n\n\n\nModel Specification and Estimation\nNow that we have our simulated data, we can fit a State-Trait Model using the lavaan package. The model will estimate the trait-like and state-like components for each individual.\n\n\nCode\n# Define the model\nmodel &lt;- '\n  # Trait component\n  trait =~ 1 * value_t1 + 1 * value_t2 + 1 * value_t3 + 1 * value_t4\n\n  # State component\n  state =~ value_t1 + value_t2 + value_t3 + value_t4\n\n  # Residual variances\n  value_t1 ~~ value_t1\n  value_t2 ~~ value_t2\n  value_t3 ~~ value_t3\n  value_t4 ~~ value_t4\n'\n\n\n\n\nCode\n# Reshape the data to wide format\ndata_wide &lt;- reshape(data, idvar = \"id\", timevar = \"time\", direction = \"wide\")\n\n\n\n\nCode\n# Fit the State-Trait Model\nfit &lt;- sem(model, data = data_wide)\n\n\n\n\nInterpreting the Results\nNow that we have estimated our State-Trait Model, we can interpret the results. The key parameters of interest in this model are the trait-like and state-like components, which are the variances attributed to each component.\n\n\nCode\n# Obtain the results\nsummary(fit)"
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "",
    "text": "Generalized linear mixed-effects models (GLMMs) are a statistical method used to analyze longitudinal or clustered data that accounts for within-subject correlation and allows for the estimation of subject-specific effects (Pinheiro & Bates, 2000; Fitzmaurice et al., 2011). This method extends the generalized linear mixed-effects model by modeling both fixed-effects (population-averaged effects) and random-effects (subject-specific deviations), while accounting for within-subject correlations. The method can handle unbalanced or unequally spaced data, and can accommodate various outcome distributions, including binary, count, and continuous data. GLMMs have been shown to have good statistical power and efficiency, and can be used to model complex data structures, including crossed and nested random effects. GLMMs have been shown to outperform other methods, such as GEE, in terms of statistical power and efficiency (Hardin & Hilbe, 2012).\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal generalized linear mixed effects models (GLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GLMMs.\nFit a GLMM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#overview",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#overview",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "",
    "text": "Generalized linear mixed-effects models (GLMMs) are a statistical method used to analyze longitudinal or clustered data that accounts for within-subject correlation and allows for the estimation of subject-specific effects (Pinheiro & Bates, 2000; Fitzmaurice et al., 2011). This method extends the generalized linear mixed-effects model by modeling both fixed-effects (population-averaged effects) and random-effects (subject-specific deviations), while accounting for within-subject correlations. The method can handle unbalanced or unequally spaced data, and can accommodate various outcome distributions, including binary, count, and continuous data. GLMMs have been shown to have good statistical power and efficiency, and can be used to model complex data structures, including crossed and nested random effects. GLMMs have been shown to outperform other methods, such as GEE, in terms of statistical power and efficiency (Hardin & Hilbe, 2012).\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal generalized linear mixed effects models (GLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GLMMs.\nFit a GLMM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#basic-example",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#basic-example",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\nModel Specification and Estimation\nWe will use the lme4 package in R to fit a longitudinal GLMM. First, install the required package, if not already installed:\n\n\nCode\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nlibrary(lme4)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = factor(c(1, 1, 1, 2, 2)),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\n\nFit the longitudinal GLMM with a binary outcome using a logit link function and random intercepts for each subject:\n\n\nCode\nmodel &lt;- glmer(outcome ~ time + (1 | subject_id), data = data, family = binomial(link = \"logit\"))\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal GLMM, we can use the summary() function in R to display the estimated fixed effects and random effects:\n\n\nCode\nsummary(model)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: outcome ~ time + (1 | subject_id)\n   Data: data\n\n     AIC      BIC   logLik deviance df.resid \n     6.0      4.8      0.0      0.0        2 \n\nScaled residuals: \n      Min        1Q    Median        3Q       Max \n-1.49e-08 -1.49e-08  1.49e-08  1.49e-08  1.49e-08 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n subject_id (Intercept) 0.36     0.6     \nNumber of obs: 5, groups:  subject_id, 2\n\nFixed effects:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept) -3.834e+01  4.393e+07       0        1\ntime         7.526e+01  4.011e+07       0        1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime -0.730\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nunable to evaluate scaled gradient\n Hessian is numerically singular: parameters are not uniquely determined\n\n\nThe output will show the estimated fixed effects of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level. Additionally, the output will display information about the random effects, such as the variance of the random intercepts for subjects."
  },
  {
    "objectID": "12_Tutorials_LatentTransitionAnalysis.html",
    "href": "12_Tutorials_LatentTransitionAnalysis.html",
    "title": "Latent Transition Analysis",
    "section": "",
    "text": "In this tutorial, we will introduce Latent Transition Analysis (LTA), a statistical method used to analyze the movement of individuals between latent (unobserved) statuses over time. LTA is particularly useful when dealing with categorical data and allows us to estimate the probabilities of transitioning between latent statuses.\nWe will use the “tidyLPA” package in R to fit a simple LTA model with four timepoints and three indicators per timepoint. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "12_Tutorials_LatentTransitionAnalysis.html#overview",
    "href": "12_Tutorials_LatentTransitionAnalysis.html#overview",
    "title": "Latent Transition Analysis",
    "section": "",
    "text": "In this tutorial, we will introduce Latent Transition Analysis (LTA), a statistical method used to analyze the movement of individuals between latent (unobserved) statuses over time. LTA is particularly useful when dealing with categorical data and allows us to estimate the probabilities of transitioning between latent statuses.\nWe will use the “tidyLPA” package in R to fit a simple LTA model with four timepoints and three indicators per timepoint. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "12_Tutorials_LatentTransitionAnalysis.html#basic-example",
    "href": "12_Tutorials_LatentTransitionAnalysis.html#basic-example",
    "title": "Latent Transition Analysis",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Load necessary packages\nif (!(\"tidyLPA\" %in% installed.packages())) install.packages(\"tidyLPA\")\nlibrary(tidyLPA)\n\n\n\n\nCode\nset.seed(42)\nn &lt;- 250\n\n# Generate three indicators for time 1\ntime1_ind1 &lt;- rbinom(n, size = 1, prob = 0.7)\ntime1_ind2 &lt;- rbinom(n, size = 1, prob = 0.6)\ntime1_ind3 &lt;- rbinom(n, size = 1, prob = 0.5)\n\n# Generate three indicators for time 2\ntime2_ind1 &lt;- rbinom(n, size = 1, prob = 0.6)\ntime2_ind2 &lt;- rbinom(n, size = 1, prob = 0.5)\ntime2_ind3 &lt;- rbinom(n, size = 1, prob = 0.4)\n\n# Generate three indicators for time 3\ntime3_ind1 &lt;- rbinom(n, size = 1, prob = 0.5)\ntime3_ind2 &lt;- rbinom(n, size = 1, prob = 0.4)\ntime3_ind3 &lt;- rbinom(n, size = 1, prob = 0.3)\n\n# Generate three indicators for time 4\ntime4_ind1 &lt;- rbinom(n, size = 1, prob = 0.4)\ntime4_ind2 &lt;- rbinom(n, size = 1, prob = 0.3)\ntime4_ind3 &lt;- rbinom(n, size = 1, prob = 0.2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Temporary Landing Page for Longitudinal Project",
    "section": "",
    "text": "This is github pages test site for the longitudinal analysis project. The information included within the site is for testing purposes only and contents may be inaccurate."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Sam Page Test"
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html",
    "href": "1_Tutorials_DifferenceScores.html",
    "title": "Difference Scores",
    "section": "",
    "text": "Difference scores are one of the earliest developed and commonly used statistical approaches to compare data collected from the same individual across two measurement occasions (castro-schilo2018?; jennings2016?). The difference between scores at the two time points is calculated for each individual and the resulting value is taken as a measure of change. It is common to then perform statistical tests on the difference scores, such as being included as an outcome in a GLM analysis to test for differences in patterns of change over time and between groups. For example, difference scores may be used in a paired-samples t-test to compare mean test scores of students before and after attending a math workshop, or in a simple regression analysis to assess the effectiveness of a weight loss program by calculating the difference in weight between between groups of interest, before and after the program.\n\n\n\nDifference Score 1_Tutorial\n\n\n\n\nYou should use difference scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will guide you through two simple examples of using difference scores. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of difference scores.\nCalculate difference scores using example data.\nInterpret the results of the difference scores analysis."
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html#overview",
    "href": "1_Tutorials_DifferenceScores.html#overview",
    "title": "Difference Scores",
    "section": "",
    "text": "Difference scores are one of the earliest developed and commonly used statistical approaches to compare data collected from the same individual across two measurement occasions (castro-schilo2018?; jennings2016?). The difference between scores at the two time points is calculated for each individual and the resulting value is taken as a measure of change. It is common to then perform statistical tests on the difference scores, such as being included as an outcome in a GLM analysis to test for differences in patterns of change over time and between groups. For example, difference scores may be used in a paired-samples t-test to compare mean test scores of students before and after attending a math workshop, or in a simple regression analysis to assess the effectiveness of a weight loss program by calculating the difference in weight between between groups of interest, before and after the program.\n\n\n\nDifference Score 1_Tutorial\n\n\n\n\nYou should use difference scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will guide you through two simple examples of using difference scores. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of difference scores.\nCalculate difference scores using example data.\nInterpret the results of the difference scores analysis."
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html#basic-example",
    "href": "1_Tutorials_DifferenceScores.html#basic-example",
    "title": "Difference Scores",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nTime point (T1, T2)\nJob satisfaction (independent variable)\nLife satisfaction (dependent variable)\n\n\n\n\nIndividual\nTime Point\nJob Satisfaction\nLife Satisfaction\n\n\n\n\nA\nT1\n7\n6\n\n\nA\nT2\n8\n7\n\n\nB\nT1\n6\n5\n\n\nB\nT2\n7\n6\n\n\n\nWe will then create a new variable, age_diff, that represents the difference in age between two time points:\n\n\nCode\n#titanic$age_diff &lt;- titanic$age - titanic$age[1]\n\n\n\nRepeated Measures Paired Samples T-test\nTo conduct a repeated measures paired samples t-test on age_diff, we will use the t.test() function in R:\n\n\nCode\n#t.test(titanic$age_diff, mu = 0, paired = TRUE)\\\n\n\nThe mu argument represents the hypothesized mean difference, which we have set to 0. The paired argument tells R that the samples are paired.\n\n\nInterpreting the Results\nThe output of the t.test() function includes several statistics, including the t-value, degrees of freedom, and p-value. The t-value represents the difference between the mean of age_diff and the hypothesized mean difference, divided by the standard error. The degrees of freedom represents the number of observations minus one. The p-value represents the probability of observing a t-value as extreme or more extreme than the one observed, assuming that the null hypothesis is true.\nIf the p-value is less than our chosen significance level (typically 0.05), we can reject the null hypothesis and conclude that there is a significant difference between the means of age_diff and the hypothesized mean difference. If the p-value is greater than our chosen significance level, we fail to reject the null hypothesis and conclude that there is insufficient evidence to suggest a difference between the means.\n\n\nConclusion\nIn this tutorial, we learned how to conduct a repeated measures paired samples t-test on a difference score using R. This statistical method is useful when we want to compare the means of two related variables that are measured at two different time points or under two different conditions. We also learned how to interpret the results of the t-test, including the t-value, degrees of freedom, and p-value.\n\n\nPaired Samples T-test Model Specification and Estimation\nTo calculate [xxxxx] scores, we will follow these steps:\n[two timepoints, t1 and t2, and we want to test whether there is a significant difference between the means of two variables measured at each timepoint. We can use a paired samples t-test to do this.]\nA paired samples t-test is used to determine whether there is a significant difference between two related variables. For example, you may be interested in whether there is a significant difference in anxiety levels between participants before and after an intervention. To conduct a paired samples t-test in R, we can use the t.test() function.\nLet’s use a hypothetical example to illustrate how to conduct a paired samples t-test in R. In this example, we have data from 30 participants who completed a pre-test and post-test on anxiety levels measured on a 10-point scale. We want to determine if there was a significant difference in anxiety levels before and after an intervention.\n\n\nCode\n# Generate example data\npre_test &lt;- rnorm(30, mean = 6, sd = 1)\npost_test &lt;- rnorm(30, mean = 4, sd = 1)\n\n\n\n\nCode\n# Conduct paired samples t-test\nt.test(pre_test, post_test, paired = TRUE)\n\n\n\n    Paired t-test\n\ndata:  pre_test and post_test\nt = 7.6083, df = 29, p-value = 2.18e-08\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.522869 2.642611\nsample estimates:\nmean difference \n        2.08274 \n\n\nThe t.test() function returns the t-value, degrees of freedom, and p-value for the paired samples t-test. In this example, the p-value is less than 0.05, indicating that there is a significant difference in anxiety levels before and after the intervention.\n\n\nSimple Regression on a Difference Score\nA simple regression on a difference score is used to determine the relationship between the difference scores of two related variables and a third variable. For example, you may be interested in whether there is a relationship between the difference in anxiety levels before and after an intervention and a participant’s age. To conduct a simple regression on a difference score in R, we can use the lm() function.\nLet’s continue with the hypothetical example from the paired samples t-test. We want to determine if there is a relationship between the difference in anxiety levels before and after the intervention and the participants’ age. We will create a new variable diff_score to represent the difference in anxiety levels.\n\n\nCode\n# Calculate difference score\ndiff_score &lt;- post_test - pre_test\n\n# Generate example age data\nage &lt;- rnorm(30, mean = 35, sd = 5)\n\n# Conduct simple regression on difference score and age\nmodel &lt;- lm(diff_score ~ age)\nsummary(model)\n\n\n\nCall:\nlm(formula = diff_score ~ age)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5068 -0.9876  0.3755  1.0985  2.7064 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -4.08802    2.29748  -1.779    0.086 .\nage          0.05783    0.06578   0.879    0.387  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.505 on 28 degrees of freedom\nMultiple R-squared:  0.02686,   Adjusted R-squared:  -0.007894 \nF-statistic: 0.7729 on 1 and 28 DF,  p-value: 0.3868\n\n\nThe lm() function returns the intercept, slope, and p-value for the simple regression on the difference score. In this example, the p-value is greater than 0.05, indicating that there is no significant relationship between the difference in anxiety levels and age.\n\nInterpreting the Results\nFor the paired samples t-test, the output from the t.test() function provides the t-value, degrees of freedom, and p-value. The t-value represents the size of the difference between the means of the two related variables relative to the variation within the data. The degrees of freedom represent the number of observations minus the number of variables being compared. The p-value represents the probability of obtaining a result as extreme as the one observed, assuming that the null hypothesis is true.\nFor the simple regression on the difference score, the output from the lm() function provides the intercept, slope,"
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html",
    "href": "3_Tutorials_LinearMixedModels.html",
    "title": "Linear Mixed Models",
    "section": "",
    "text": "Linear mixed models (LMMs) are a powerful statistical tool that allows the analysis of complex data structures that contain both fixed and random effects (West et al., 2015). LMMs are widely used in various fields, including social sciences, biology, and engineering, due to their ability to handle hierarchical data structures and account for within-subject correlations (Bates et al., 2015). LMMs are an extension of the general linear model (GLM), where both fixed and random effects can be included in the model, making them more flexible and robust (Pinheiro & Bates, 2000). These models are particularly useful when analyzing longitudinal data, where measurements are taken repeatedly over time, and correlations between observations must be accounted for (Singer & Willett, 2003). Specifically, the LMM framework accounts for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. This approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory. It is this “mixture” of fixed and random effects from which these models derive their name.\n[+add primary diagram/figure]\n\n\nYou should use LMMs in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal linear mixed models (LLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal linear mixed models.\nFit a longitudinal linear mixed model using example data in R.\nInterpret the results of the LLMM analysis."
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html#overview",
    "href": "3_Tutorials_LinearMixedModels.html#overview",
    "title": "Linear Mixed Models",
    "section": "",
    "text": "Linear mixed models (LMMs) are a powerful statistical tool that allows the analysis of complex data structures that contain both fixed and random effects (West et al., 2015). LMMs are widely used in various fields, including social sciences, biology, and engineering, due to their ability to handle hierarchical data structures and account for within-subject correlations (Bates et al., 2015). LMMs are an extension of the general linear model (GLM), where both fixed and random effects can be included in the model, making them more flexible and robust (Pinheiro & Bates, 2000). These models are particularly useful when analyzing longitudinal data, where measurements are taken repeatedly over time, and correlations between observations must be accounted for (Singer & Willett, 2003). Specifically, the LMM framework accounts for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. This approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory. It is this “mixture” of fixed and random effects from which these models derive their name.\n[+add primary diagram/figure]\n\n\nYou should use LMMs in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal linear mixed models (LLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal linear mixed models.\nFit a longitudinal linear mixed model using example data in R.\nInterpret the results of the LLMM analysis."
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html#basic-example",
    "href": "3_Tutorials_LinearMixedModels.html#basic-example",
    "title": "Linear Mixed Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nOutcome variable (e.g., a measure of cognitive performance)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n100\n\n\n1\n1\n105\n\n\n1\n2\n110\n\n\n2\n0\n95\n\n\n2\n1\n100\n\n\n\n\nModel Specification and Estimation\nWe will use the lme4 package in R to fit a longitudinal linear mixed model. First, install and load the required package:\n\n\nCode\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nlibrary(lme4)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(100, 105, 110, 95, 100)\n)\n\n\nFit the LLMM with a random intercept for each subject and a fixed effect of time:\n\n\nCode\nmodel &lt;- lmer(outcome ~ time + (1 | subject_id), data = data)\n\n\n\n\nInterpreting the Results\nTo interpret the results of the LLMM analysis, we can use the summary() function in R to display the estimated fixed effects and random effects:\n\n\nCode\nsummary(model)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ time + (1 | subject_id)\n   Data: data\n\nREML criterion at convergence: -44.7\n\nScaled residuals: \n       Min         1Q     Median         3Q        Max \n-1.141e-07 -5.704e-08  8.556e-08  1.426e-07  1.996e-07 \n\nRandom effects:\n Groups     Name        Variance  Std.Dev. \n subject_id (Intercept) 4.167e+00 2.041e+00\n Residual               2.483e-13 4.983e-07\nNumber of obs: 5, groups:  subject_id, 2\n\nFixed effects:\n             Estimate Std. Error   t value\n(Intercept) 9.750e+01  1.444e+00 6.751e+01\ntime        5.000e+00  3.151e-07 1.587e+07\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime 0.000 \noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00500608 (tol = 0.002, component 1)\n\n\nThe output will show the estimated fixed effect of time, which represents the average change in the outcome variable over time across subjects. The random effects estimates show the variation in the intercept (initial level) of the outcome variable across subjects. By examining the fixed and random effects, we can gain insights into how the outcome variable changes over time and how this change differs between subjects."
  },
  {
    "objectID": "9_Tutorials_LatentChangeScoresModels.html",
    "href": "9_Tutorials_LatentChangeScoresModels.html",
    "title": "Latent Change Score Models",
    "section": "",
    "text": "xxx In this tutorial, we’ll introduce Latent Change Score Models (LCSM), a powerful technique for analyzing longitudinal data. Latent Change Score Models allow researchers to examine individual differences in change over time, as well as the factors that might influence these changes. We’ll walk through an example using a dataset with three time points and a larger sample size of 250 participants. xxx\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "9_Tutorials_LatentChangeScoresModels.html#overview",
    "href": "9_Tutorials_LatentChangeScoresModels.html#overview",
    "title": "Latent Change Score Models",
    "section": "",
    "text": "xxx In this tutorial, we’ll introduce Latent Change Score Models (LCSM), a powerful technique for analyzing longitudinal data. Latent Change Score Models allow researchers to examine individual differences in change over time, as well as the factors that might influence these changes. We’ll walk through an example using a dataset with three time points and a larger sample size of 250 participants. xxx\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "9_Tutorials_LatentChangeScoresModels.html#basic-example",
    "href": "9_Tutorials_LatentChangeScoresModels.html#basic-example",
    "title": "Latent Change Score Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we’ll use a hypothetical dataset called “data” with the following variables:\nsubject_id: A unique identifier for each participant score_t1: The measurement of a variable of interest at Time 1 score_t2: The measurement of the same variable at Time 2 score_t3: The measurement of the same variable at Time 3 First, let’s load the “lavaan” package and create a larger dataset for this example:\n\n\nCode\nlibrary(lavaan)\n\n# Create a sample dataset with 250 participants\nset.seed(42) # For reproducibility\nsubject_id &lt;- 1:250\nscore_t1 &lt;- rnorm(250, mean = 20, sd = 5)\nscore_t2 &lt;- score_t1 + rnorm(250, mean = 2, sd = 3)\nscore_t3 &lt;- score_t2 + rnorm(250, mean = 3, sd = 4)\ndata &lt;- data.frame(subject_id, score_t1, score_t2, score_t3)\n\n\n\nModel Specification and Estimation\nNow, let’s specify the Latent Change Score Model. In this example, we’ll estimate the mean change in the variable of interest from Time 1 to Time 2 and from Time 2 to Time 3, as well as the variances of the change scores.\n\n::: {.cell hash='9_Tutorials_LatentChangeScoresModels_cache/html/unnamed-chunk-3_4c6ae3706e63906c93faa359ec254305'}\n\n```{.r .cell-code}\n# Define the Latent Change Score Model\nmodel &lt;- '\n  # Latent variables\n    delta12 =~ 1 * score_t2 - 1 * score_t1\n    delta23 =~ 1 * score_t3 - 1 * score_t2\n\n  # Means\n    delta12 ~ mu_delta12\n    delta23 ~ mu_delta23\n\n  # Variances\n    delta12 ~~ var_delta12 * delta12\n    delta23 ~~ var_delta23 * delta23\n`\n:::\n\n\nCode\n# Fit the model\nfit &lt;- sem(model, data = data, missing = \"FIML\")\n\n\n\n\nInterpreting the Results\nWe can now examine the results of our Latent Change Score Model. The main parameters of interest are:\nmu_delta12: The mean change in the variable of interest from Time 1 to Time 2 mu_delta23: The mean change in the variable of interest from Time 2 to Time 3 var_delta12: The variance of the change scores from Time 1 to Time 2, which reflects individual differences in change var_delta23: The variance of the change xxxx"
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html",
    "href": "2_Tutorials_ResidualizedChangeScores.html",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Residualized change scores are a statistical method used to assess the degree of change in a variable while controlling for its initial level. The approach involves calculating the residualized change scores by regressing post-treatment scores on pre-treatment scores and using the resulting residuals as the measure of change. This estimated change score adjusts for baseline scores while ignoring any prior group assignments/differences. The residualized change score is often included in subsequent analysis, such as an examination of intervention effects in pre-test/post-test designs (Kisbu-Sakarya2013?). This method is useful when there is a high correlation between the pre-treatment and post-treatment scores, which can make it difficult to determine the true degree of change. Research studies have shown that this method can provide more accurate and reliable results compared to other methods of measuring change, such as raw change scores or gain scores (Kenny, 1979; Rogosa & Willett, 1985).\nResidualized change scores are a method used to analyze change in a variable over time, while accounting for the initial level of that variable. By using residualized change scores, we can examine the extent to which changes in one variable are associated with changes in another variable, controlling for the initial level of the variables.\n\n\n\nResidualized Change Score 1_Tutorial\n\n\n\n\nYou should use residualized change scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of residualized change scores and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of residualized change scores.\nCalculate residualized change scores using example data.\nInterpret the results of the residualized change scores analysis."
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html#overview",
    "href": "2_Tutorials_ResidualizedChangeScores.html#overview",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Residualized change scores are a statistical method used to assess the degree of change in a variable while controlling for its initial level. The approach involves calculating the residualized change scores by regressing post-treatment scores on pre-treatment scores and using the resulting residuals as the measure of change. This estimated change score adjusts for baseline scores while ignoring any prior group assignments/differences. The residualized change score is often included in subsequent analysis, such as an examination of intervention effects in pre-test/post-test designs (Kisbu-Sakarya2013?). This method is useful when there is a high correlation between the pre-treatment and post-treatment scores, which can make it difficult to determine the true degree of change. Research studies have shown that this method can provide more accurate and reliable results compared to other methods of measuring change, such as raw change scores or gain scores (Kenny, 1979; Rogosa & Willett, 1985).\nResidualized change scores are a method used to analyze change in a variable over time, while accounting for the initial level of that variable. By using residualized change scores, we can examine the extent to which changes in one variable are associated with changes in another variable, controlling for the initial level of the variables.\n\n\n\nResidualized Change Score 1_Tutorial\n\n\n\n\nYou should use residualized change scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of residualized change scores and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of residualized change scores.\nCalculate residualized change scores using example data.\nInterpret the results of the residualized change scores analysis."
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html#basic-example",
    "href": "2_Tutorials_ResidualizedChangeScores.html#basic-example",
    "title": "Residualized Change Scores",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nTime point (T1, T2)\nJob satisfaction (independent variable)\nLife satisfaction (dependent variable)\n\n\n\n\nIndividual\nTime Point\nJob Satisfaction\nLife Satisfaction\n\n\n\n\nA\nT1\n7\n6\n\n\nA\nT2\n8\n7\n\n\nB\nT1\n6\n5\n\n\nB\nT2\n7\n6\n\n\n\n\nModel Specification and Estimation\nTo calculate residualized change scores, we will follow these steps:\n\nCalculate the raw change scores for each variable by subtracting the T1 value from the T2 value.\nFit a regression model with the change score of the dependent variable (life satisfaction) as the outcome and the change score of the independent variable (job satisfaction) and the initial level of the dependent variable (T1 life satisfaction) as predictors.\nExtract the residuals from the regression model. These residuals represent the residualized change scores.\n\nUsing the example dataset, we can calculate the residualized change scores for life satisfaction as follows:\n\nCalculate raw change scores:\n\n\n\nIndividual\nJob Satisfaction Change\nLife Satisfaction Change\n\n\n\n\nA\n1\n1\n\n\nB\n1\n1\n\n\n\nFit the regression model:\nLife Satisfaction Change = b0 + b1 * Job Satisfaction Change + b2 * T1 Life Satisfaction\nExtract residuals:\n\n\n\nIndividual\nResidualized Change Score\n\n\n\n\nA\ne1\n\n\nB\ne2\n\n\n\n\n\n\nInterpreting the Results\nResidualized change scores represent the change in the dependent variable (life satisfaction) after accounting for the initial level of that variable and the change in the independent variable (job satisfaction). By examining the association between the residualized change scores of two variables, we can gain insights into how changes in one variable are related to changes in another variable, controlling for initial levels."
  }
]
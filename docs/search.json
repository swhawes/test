[
  {
    "objectID": "5_Tutorials_MarginalModels.html",
    "href": "5_Tutorials_MarginalModels.html",
    "title": "Marginal Models",
    "section": "",
    "text": "Marginal models are a statistical method used to analyze longitudinal or clustered data. The marginal model estimates the average effect of the independent variables on the outcome while accounting for the within-subject correlation, and allows for the estimation of population-averaged effects, in contrast to subject-specific effects estimated by random-effects models (Verbeke & Molenberghs, 2000). The method is similar to the GEE approach but uses a different estimation technique and does not account for subject-specific effects. Marginal models have been shown to be robust to non-normality and non-constant variance, and can handle unbalanced or unequally spaced data (Fitzmaurice et al., 2011). The term marginal in this context is used to emphasize that the model for the mean response at each occasion depends only on the covariates of interest, and not on any random effects or previous responses.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal marginal models and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal marginal models.\nFit a longitudinal marginal model using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html#overview",
    "href": "5_Tutorials_MarginalModels.html#overview",
    "title": "Marginal Models",
    "section": "",
    "text": "Marginal models are a statistical method used to analyze longitudinal or clustered data. The marginal model estimates the average effect of the independent variables on the outcome while accounting for the within-subject correlation, and allows for the estimation of population-averaged effects, in contrast to subject-specific effects estimated by random-effects models (Verbeke & Molenberghs, 2000). The method is similar to the GEE approach but uses a different estimation technique and does not account for subject-specific effects. Marginal models have been shown to be robust to non-normality and non-constant variance, and can handle unbalanced or unequally spaced data (Fitzmaurice et al., 2011). The term marginal in this context is used to emphasize that the model for the mean response at each occasion depends only on the covariates of interest, and not on any random effects or previous responses.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal marginal models and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal marginal models.\nFit a longitudinal marginal model using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html#basic-example",
    "href": "5_Tutorials_MarginalModels.html#basic-example",
    "title": "Marginal Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\nModel Specification and Estimation\nWe will use the geepack package in R to fit a longitudinal marginal model. First, install and load the required package:\n\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"geepack\")\nlibrary(geepack)\n\nNext, create a data frame with the example data:\n\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\nFit the longitudinal marginal model with a binary outcome using a logit link function:\n\nmodel &lt;- geeglm(outcome ~ time, data = data, id = subject_id, family = binomial(link = \"logit\"), corstr = \"exchangeable\")\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal marginal model, we can use the summary() function in R to display the estimated population-averaged effects:\n\nsummary(model)\n\nWarning in sqrt(diag(covmat)): NaNs produced\n\n\nWarning in sqrt(diag(covmatgam)): NaNs produced\n\n\nWarning in sqrt(diag(covmatalpha)): NaNs produced\n\n\nWarning in sqrt(diag(object$vbeta)): NaNs produced\n\n\nWarning in sqrt(diag(object$valpha)): NaNs produced\n\n\nWarning in sqrt(diag(object$vgamma)): NaNs produced\n\n\n\nCall:\ngeeglm(formula = outcome ~ time, family = binomial(link = \"logit\"), \n    data = data, id = subject_id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err Wald Pr(&gt;|W|)\n(Intercept)   -43.54     NaN  NaN      NaN\ntime           82.78     NaN  NaN      NaN\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept) 2.22e-16     NaN\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha     -0.5     NaN\nNumber of clusters:   2  Maximum cluster size: 3 \n\n\nThe output will show the estimated effect of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level."
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html",
    "href": "4_Tutorials_SignedRankTest.html",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The longitudinal signed-rank test is a nonparametric alternative to the paired t-test and is appropriate when the data are not normally distributed or when the assumptions of the paired t-test are violated. The test is based on the signed-rank of the differences between the paired observations, and it tests the null hypothesis that the median of the differences is zero. The repeated-measures design allows for the assessment of within-subject changes over time or under different conditions. The signed-rank test is robust to outliers and does not assume a normal distribution of the differences. This method has been shown to have good statistical power and efficiency, particularly when the sample size is small or the distribution is heavily skewed (Erceg-Hurn & Mirosevich, 2008; Bakdash & Marusich, 2017; Garcia-Berthou & Alcaraz, 2004). The signed-rank test is a useful tool for analyzing paired data when the assumption of normality is violated or when the data is highly skewed or contains outliers.\n[+add diagrams/figures]\n\n\nYou should use a Wilcoxon Signed-Rank Test in the following scenario: 1. You want to know if two groups are different on your variable of interest 2. Your variable of interest is continuous 3. You have two and only two groups 4. You have independent samples 5. You have a skewed variable of interest\n\n\n\nIn this tutorial, we will introduce the concept of the longitudinal signed-rank test and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of the longitudinal signed-rank test.\nPerform a longitudinal signed-rank test using example data in R.\nInterpret the results of the test."
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html#overview",
    "href": "4_Tutorials_SignedRankTest.html#overview",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The longitudinal signed-rank test is a nonparametric alternative to the paired t-test and is appropriate when the data are not normally distributed or when the assumptions of the paired t-test are violated. The test is based on the signed-rank of the differences between the paired observations, and it tests the null hypothesis that the median of the differences is zero. The repeated-measures design allows for the assessment of within-subject changes over time or under different conditions. The signed-rank test is robust to outliers and does not assume a normal distribution of the differences. This method has been shown to have good statistical power and efficiency, particularly when the sample size is small or the distribution is heavily skewed (Erceg-Hurn & Mirosevich, 2008; Bakdash & Marusich, 2017; Garcia-Berthou & Alcaraz, 2004). The signed-rank test is a useful tool for analyzing paired data when the assumption of normality is violated or when the data is highly skewed or contains outliers.\n[+add diagrams/figures]\n\n\nYou should use a Wilcoxon Signed-Rank Test in the following scenario: 1. You want to know if two groups are different on your variable of interest 2. Your variable of interest is continuous 3. You have two and only two groups 4. You have independent samples 5. You have a skewed variable of interest\n\n\n\nIn this tutorial, we will introduce the concept of the longitudinal signed-rank test and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of the longitudinal signed-rank test.\nPerform a longitudinal signed-rank test using example data in R.\nInterpret the results of the test."
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html#basic-example",
    "href": "4_Tutorials_SignedRankTest.html#basic-example",
    "title": "Signed-Rank Test",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime point 1 (T1) measurement\nTime point 2 (T2) measurement\n\n\n\n\nSubject ID\nT1\nT2\n\n\n\n\n1\n100\n105\n\n\n2\n95\n100\n\n\n3\n110\n112\n\n\n\n\nModel Specification and Estimation\nWe will use the wilcox.test() function in R to perform a longitudinal signed-rank test. First, create a data frame with the example data:\n\ndata &lt;- data.frame(\n  subject_id = c(1, 2, 3),\n  t1 = c(100, 95, 110),\n  t2 = c(105, 100, 112)\n)\n\nPerform the longitudinal signed-rank test using the wilcox.test() function with the paired = TRUE argument:\n\ntest_result &lt;- wilcox.test(data$t1, data$t2, paired = TRUE)\n\nWarning in wilcox.test.default(data$t1, data$t2, paired = TRUE): cannot compute\nexact p-value with ties\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal signed-rank test, examine the p-value from the test_result object:\n\ntest_result$p.value\n\n[1] 0.1735682\n\n\nThe p-value represents the probability of observing the data if there is no difference between the measurements at T1 and T2. If the p-value is less than a predetermined significance level (e.g., 0.05), we can reject the null hypothesis that there is no difference between the two time points and conclude that there is a significant difference in the measurements between T1 and T2."
  },
  {
    "objectID": "6_Tutorials_GeneralizedEstimatingEquations.html",
    "href": "6_Tutorials_GeneralizedEstimatingEquations.html",
    "title": "Generalized Estimating Equations",
    "section": "",
    "text": "[*add diagrams/figures]"
  },
  {
    "objectID": "6_Tutorials_GeneralizedEstimatingEquations.html#overview",
    "href": "6_Tutorials_GeneralizedEstimatingEquations.html#overview",
    "title": "Generalized Estimating Equations",
    "section": "Overview",
    "text": "Overview\nGeneralized estimating equations (GEEs) are a statistical method used to analyze longitudinal or clustered data, while accounting for within-subject correlation. The goal GEEs are to make inferences about population-averaged effects (controlling for within-subject correlations), rather than individual subject-level effects. GEEs can handle a wide range of outcome distributions, including binary, count, and continuous data (Fitzmaurice et al., 2011; Hardin & Hilbe, 2012). This method is an extension of the generalized linear model (Diggle et al., 2002), shows good statistical power and efficiency, is robust to non-normality and non-constant variance and can handle unbalanced or unequally spaced data.\n\nWhen to use Longitudinal Generalized Estimating Equations (GEEs)?\nYou should use xxxxxxx in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\nGetting Started with Longitudinal Generalized Estimating Equations (GEEs)\nIn this tutorial, we will introduce the concept of longitudinal generalized estimating equations (GEEs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GEEs.\nFit a GEE model using example data in R.\nInterpret the results of the model.\n\n\n\nBasic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\n\nModel Specification and Estimation\nWe will use the geepack package in R to fit a longitudinal GEE model. First, install and load the required package:\n\nif (!(\"geepack\" %in% installed.packages())) install.packages(\"geepack\")\nlibrary(geepack)\n\nNext, create a data frame with the example data:\n\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\nFit the longitudinal GEE model with a binary outcome using a logit link function and an exchangeable correlation structure:\n\nmodel &lt;- geeglm(outcome ~ time, data = data, id = subject_id, family = binomial(link = \"logit\"), corstr = \"exchangeable\")\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal GEE model, we can use the summary() function in R to display the estimated population-averaged effects:\n\nsummary(model)\n\nWarning in sqrt(diag(covmat)): NaNs produced\n\n\nWarning in sqrt(diag(covmatgam)): NaNs produced\n\n\nWarning in sqrt(diag(covmatalpha)): NaNs produced\n\n\nWarning in sqrt(diag(object$vbeta)): NaNs produced\n\n\nWarning in sqrt(diag(object$valpha)): NaNs produced\n\n\nWarning in sqrt(diag(object$vgamma)): NaNs produced\n\n\n\nCall:\ngeeglm(formula = outcome ~ time, family = binomial(link = \"logit\"), \n    data = data, id = subject_id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err Wald Pr(&gt;|W|)\n(Intercept)   -43.54     NaN  NaN      NaN\ntime           82.78     NaN  NaN      NaN\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept) 2.22e-16     NaN\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha     -0.5     NaN\nNumber of clusters:   2  Maximum cluster size: 3 \n\n\nThe output will show the estimated effect of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level."
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "",
    "text": "Generalized linear mixed-effects models (GLMMs) are a statistical method used to analyze longitudinal or clustered data that accounts for within-subject correlation and allows for the estimation of subject-specific effects (Pinheiro & Bates, 2000; Fitzmaurice et al., 2011). This method extends the generalized linear mixed-effects model by modeling both fixed-effects (population-averaged effects) and random-effects (subject-specific deviations), while accounting for within-subject correlations. The method can handle unbalanced or unequally spaced data, and can accommodate various outcome distributions, including binary, count, and continuous data. GLMMs have been shown to have good statistical power and efficiency, and can be used to model complex data structures, including crossed and nested random effects. GLMMs have been shown to outperform other methods, such as GEE, in terms of statistical power and efficiency (Hardin & Hilbe, 2012).\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal generalized linear mixed effects models (GLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GLMMs.\nFit a GLMM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#overview",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#overview",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "",
    "text": "Generalized linear mixed-effects models (GLMMs) are a statistical method used to analyze longitudinal or clustered data that accounts for within-subject correlation and allows for the estimation of subject-specific effects (Pinheiro & Bates, 2000; Fitzmaurice et al., 2011). This method extends the generalized linear mixed-effects model by modeling both fixed-effects (population-averaged effects) and random-effects (subject-specific deviations), while accounting for within-subject correlations. The method can handle unbalanced or unequally spaced data, and can accommodate various outcome distributions, including binary, count, and continuous data. GLMMs have been shown to have good statistical power and efficiency, and can be used to model complex data structures, including crossed and nested random effects. GLMMs have been shown to outperform other methods, such as GEE, in terms of statistical power and efficiency (Hardin & Hilbe, 2012).\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal generalized linear mixed effects models (GLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GLMMs.\nFit a GLMM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#basic-example",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#basic-example",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\nModel Specification and Estimation\nWe will use the lme4 package in R to fit a longitudinal GLMM. First, install the required package, if not already installed:\n\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nlibrary(lme4)\n\nLoading required package: Matrix\n\n\nNext, create a data frame with the example data:\n\ndata &lt;- data.frame(\n  subject_id = factor(c(1, 1, 1, 2, 2)),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\nFit the longitudinal GLMM with a binary outcome using a logit link function and random intercepts for each subject:\n\nmodel &lt;- glmer(outcome ~ time + (1 | subject_id), data = data, family = binomial(link = \"logit\"))\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nHessian is numerically singular: parameters are not uniquely determined\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal GLMM, we can use the summary() function in R to display the estimated fixed effects and random effects:\n\nsummary(model)\n\nWarning in vcov.merMod(object, use.hessian = use.hessian): variance-covariance matrix computed from finite-difference Hessian is\nnot positive definite or contains NA values: falling back to var-cov estimated from RX\n\n\nWarning in vcov.merMod(object, correlation = correlation, sigm = sig): variance-covariance matrix computed from finite-difference Hessian is\nnot positive definite or contains NA values: falling back to var-cov estimated from RX\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: outcome ~ time + (1 | subject_id)\n   Data: data\n\n     AIC      BIC   logLik deviance df.resid \n     6.0      4.8      0.0      0.0        2 \n\nScaled residuals: \n      Min        1Q    Median        3Q       Max \n-1.49e-08 -1.49e-08  1.49e-08  1.49e-08  1.49e-08 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n subject_id (Intercept) 0.36     0.6     \nNumber of obs: 5, groups:  subject_id, 2\n\nFixed effects:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept) -3.834e+01  4.393e+07       0        1\ntime         7.526e+01  4.011e+07       0        1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime -0.730\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nunable to evaluate scaled gradient\n Hessian is numerically singular: parameters are not uniquely determined\n\n\nThe output will show the estimated fixed effects of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level. Additionally, the output will display information about the random effects, such as the variance of the random intercepts for subjects."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Temporary Landing Page for Longitudinal Project",
    "section": "",
    "text": "This is github pages test site for the longitudinal analysis project"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Sam Page Test"
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html",
    "href": "1_Tutorials_DifferenceScores.html",
    "title": "Difference Scores",
    "section": "",
    "text": "Difference scores are one of the earliest developed and commonly used statistical approaches to compare data collected from the same individual across two measurement occasions [@castro-schilo2018; @jennings2016]. The difference between scores at the two time points is calculated for each individual and the resulting value is taken as a measure of change. It is common to then perform statistical tests on the difference scores, such as being included as an outcome in a GLM analysis to test for differences in patterns of change over time and between groups. For example, difference scores may be used in a paired-samples t-test to compare mean test scores of students before and after attending a math workshop, or in a simple regression analysis to assess the effectiveness of a weight loss program by calculating the difference in weight between between groups of interest, before and after the program.\n\n\n\nDifference Score 1_Tutorial\n\n\n\n\nYou should use difference scores in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\n\nIn this tutorial, we will guide you through two simple examples of using difference scores. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of difference scores.\nCalculate difference scores using example data.\nInterpret the results of the difference scores analysis."
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html#overview",
    "href": "1_Tutorials_DifferenceScores.html#overview",
    "title": "Difference Scores",
    "section": "",
    "text": "Difference scores are one of the earliest developed and commonly used statistical approaches to compare data collected from the same individual across two measurement occasions [@castro-schilo2018; @jennings2016]. The difference between scores at the two time points is calculated for each individual and the resulting value is taken as a measure of change. It is common to then perform statistical tests on the difference scores, such as being included as an outcome in a GLM analysis to test for differences in patterns of change over time and between groups. For example, difference scores may be used in a paired-samples t-test to compare mean test scores of students before and after attending a math workshop, or in a simple regression analysis to assess the effectiveness of a weight loss program by calculating the difference in weight between between groups of interest, before and after the program.\n\n\n\nDifference Score 1_Tutorial\n\n\n\n\nYou should use difference scores in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\n\nIn this tutorial, we will guide you through two simple examples of using difference scores. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of difference scores.\nCalculate difference scores using example data.\nInterpret the results of the difference scores analysis."
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html#basic-example",
    "href": "1_Tutorials_DifferenceScores.html#basic-example",
    "title": "Difference Scores",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nTime point (T1, T2)\nJob satisfaction (independent variable)\nLife satisfaction (dependent variable)\n\n\n\n\nIndividual\nTime Point\nJob Satisfaction\nLife Satisfaction\n\n\n\n\nA\nT1\n7\n6\n\n\nA\nT2\n8\n7\n\n\nB\nT1\n6\n5\n\n\nB\nT2\n7\n6\n\n\n\nWe will then create a new variable, age_diff, that represents the difference in age between two time points:\n\n#titanic$age_diff &lt;- titanic$age - titanic$age[1]\n\n\nRepeated Measures Paired Samples T-test\nTo conduct a repeated measures paired samples t-test on age_diff, we will use the t.test() function in R:\n\n#t.test(titanic$age_diff, mu = 0, paired = TRUE)\\\n\nThe mu argument represents the hypothesized mean difference, which we have set to 0. The paired argument tells R that the samples are paired.\n\n\nInterpreting the Results\nThe output of the t.test() function includes several statistics, including the t-value, degrees of freedom, and p-value. The t-value represents the difference between the mean of age_diff and the hypothesized mean difference, divided by the standard error. The degrees of freedom represents the number of observations minus one. The p-value represents the probability of observing a t-value as extreme or more extreme than the one observed, assuming that the null hypothesis is true.\nIf the p-value is less than our chosen significance level (typically 0.05), we can reject the null hypothesis and conclude that there is a significant difference between the means of age_diff and the hypothesized mean difference. If the p-value is greater than our chosen significance level, we fail to reject the null hypothesis and conclude that there is insufficient evidence to suggest a difference between the means.\n\n\nConclusion\nIn this tutorial, we learned how to conduct a repeated measures paired samples t-test on a difference score using R. This statistical method is useful when we want to compare the means of two related variables that are measured at two different time points or under two different conditions. We also learned how to interpret the results of the t-test, including the t-value, degrees of freedom, and p-value.\n\n\nPaired Samples T-test Model Specification and Estimation\nTo calculate [xxxxx] scores, we will follow these steps:\n[two timepoints, t1 and t2, and we want to test whether there is a significant difference between the means of two variables measured at each timepoint. We can use a paired samples t-test to do this.]\nA paired samples t-test is used to determine whether there is a significant difference between two related variables. For example, you may be interested in whether there is a significant difference in anxiety levels between participants before and after an intervention. To conduct a paired samples t-test in R, we can use the t.test() function.\nLet’s use a hypothetical example to illustrate how to conduct a paired samples t-test in R. In this example, we have data from 30 participants who completed a pre-test and post-test on anxiety levels measured on a 10-point scale. We want to determine if there was a significant difference in anxiety levels before and after an intervention.\n\n# Generate example data\npre_test &lt;- rnorm(30, mean = 6, sd = 1)\npost_test &lt;- rnorm(30, mean = 4, sd = 1)\n\n\n# Conduct paired samples t-test\nt.test(pre_test, post_test, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  pre_test and post_test\nt = 11.449, df = 29, p-value = 2.811e-12\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.865985 2.677617\nsample estimates:\nmean difference \n       2.271801 \n\n\nThe t.test() function returns the t-value, degrees of freedom, and p-value for the paired samples t-test. In this example, the p-value is less than 0.05, indicating that there is a significant difference in anxiety levels before and after the intervention.\n\n\nSimple Regression on a Difference Score\nA simple regression on a difference score is used to determine the relationship between the difference scores of two related variables and a third variable. For example, you may be interested in whether there is a relationship between the difference in anxiety levels before and after an intervention and a participant’s age. To conduct a simple regression on a difference score in R, we can use the lm() function.\nLet’s continue with the hypothetical example from the paired samples t-test. We want to determine if there is a relationship between the difference in anxiety levels before and after the intervention and the participants’ age. We will create a new variable diff_score to represent the difference in anxiety levels.\n\n# Calculate difference score\ndiff_score &lt;- post_test - pre_test\n\n# Generate example age data\nage &lt;- rnorm(30, mean = 35, sd = 5)\n\n# Conduct simple regression on difference score and age\nmodel &lt;- lm(diff_score ~ age)\nsummary(model)\n\n\nCall:\nlm(formula = diff_score ~ age)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.09980 -0.90347  0.04307  0.85440  2.01291 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -2.93792    1.43852  -2.042   0.0506 .\nage          0.01923    0.04112   0.468   0.6437  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.102 on 28 degrees of freedom\nMultiple R-squared:  0.00775,   Adjusted R-squared:  -0.02769 \nF-statistic: 0.2187 on 1 and 28 DF,  p-value: 0.6437\n\n\nThe lm() function returns the intercept, slope, and p-value for the simple regression on the difference score. In this example, the p-value is greater than 0.05, indicating that there is no significant relationship between the difference in anxiety levels and age.\n\nInterpreting the Results\nFor the paired samples t-test, the output from the t.test() function provides the t-value, degrees of freedom, and p-value. The t-value represents the size of the difference between the means of the two related variables relative to the variation within the data. The degrees of freedom represent the number of observations minus the number of variables being compared. The p-value represents the probability of obtaining a result as extreme as the one observed, assuming that the null hypothesis is true.\nFor the simple regression on the difference score, the output from the lm() function provides the intercept, slope,"
  },
  {
    "objectID": "2b_Residualized Change Score multiple regression_HowTo.html",
    "href": "2b_Residualized Change Score multiple regression_HowTo.html",
    "title": "Residualized Change Score Example",
    "section": "",
    "text": "testing testing testing\n\n\n\ninsert text"
  },
  {
    "objectID": "2b_Residualized Change Score multiple regression_HowTo.html#overview",
    "href": "2b_Residualized Change Score multiple regression_HowTo.html#overview",
    "title": "Residualized Change Score Example",
    "section": "",
    "text": "insert text"
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html",
    "href": "3_Tutorials_LinearMixedModels.html",
    "title": "Linear Mixed Models",
    "section": "",
    "text": "Linear mixed models (LMMs) are a powerful statistical tool that allows the analysis of complex data structures that contain both fixed and random effects (West et al., 2015). LMMs are widely used in various fields, including social sciences, biology, and engineering, due to their ability to handle hierarchical data structures and account for within-subject correlations (Bates et al., 2015). LMMs are an extension of the general linear model (GLM), where both fixed and random effects can be included in the model, making them more flexible and robust (Pinheiro & Bates, 2000). These models are particularly useful when analyzing longitudinal data, where measurements are taken repeatedly over time, and correlations between observations must be accounted for (Singer & Willett, 2003). Specifically, the LMM framework accounts for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. This approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory. It is this “mixture” of fixed and random effects from which these models derive their name.\n[+add primary diagram/figure]\n\n\nYou should use LMMs in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal linear mixed models (LLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal linear mixed models.\nFit a longitudinal linear mixed model using example data in R.\nInterpret the results of the LLMM analysis."
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html#overview",
    "href": "3_Tutorials_LinearMixedModels.html#overview",
    "title": "Linear Mixed Models",
    "section": "",
    "text": "Linear mixed models (LMMs) are a powerful statistical tool that allows the analysis of complex data structures that contain both fixed and random effects (West et al., 2015). LMMs are widely used in various fields, including social sciences, biology, and engineering, due to their ability to handle hierarchical data structures and account for within-subject correlations (Bates et al., 2015). LMMs are an extension of the general linear model (GLM), where both fixed and random effects can be included in the model, making them more flexible and robust (Pinheiro & Bates, 2000). These models are particularly useful when analyzing longitudinal data, where measurements are taken repeatedly over time, and correlations between observations must be accounted for (Singer & Willett, 2003). Specifically, the LMM framework accounts for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. This approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory. It is this “mixture” of fixed and random effects from which these models derive their name.\n[+add primary diagram/figure]\n\n\nYou should use LMMs in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal linear mixed models (LLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal linear mixed models.\nFit a longitudinal linear mixed model using example data in R.\nInterpret the results of the LLMM analysis."
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html#basic-example",
    "href": "3_Tutorials_LinearMixedModels.html#basic-example",
    "title": "Linear Mixed Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nOutcome variable (e.g., a measure of cognitive performance)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n100\n\n\n1\n1\n105\n\n\n1\n2\n110\n\n\n2\n0\n95\n\n\n2\n1\n100\n\n\n\n\nModel Specification and Estimation\nWe will use the lme4 package in R to fit a longitudinal linear mixed model. First, install and load the required package:\n\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nlibrary(lme4)\n\nLoading required package: Matrix\n\n\nNext, create a data frame with the example data:\n\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(100, 105, 110, 95, 100)\n)\n\nFit the LLMM with a random intercept for each subject and a fixed effect of time:\n\nmodel &lt;- lmer(outcome ~ time + (1 | subject_id), data = data)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00500608 (tol = 0.002, component 1)\n\n\n\n\nInterpreting the Results\nTo interpret the results of the LLMM analysis, we can use the summary() function in R to display the estimated fixed effects and random effects:\n\nsummary(model)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ time + (1 | subject_id)\n   Data: data\n\nREML criterion at convergence: -44.7\n\nScaled residuals: \n       Min         1Q     Median         3Q        Max \n-1.141e-07 -5.704e-08  8.556e-08  1.426e-07  1.996e-07 \n\nRandom effects:\n Groups     Name        Variance  Std.Dev. \n subject_id (Intercept) 4.167e+00 2.041e+00\n Residual               2.483e-13 4.983e-07\nNumber of obs: 5, groups:  subject_id, 2\n\nFixed effects:\n             Estimate Std. Error   t value\n(Intercept) 9.750e+01  1.444e+00 6.751e+01\ntime        5.000e+00  3.151e-07 1.587e+07\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime 0.000 \noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00500608 (tol = 0.002, component 1)\n\n\nThe output will show the estimated fixed effect of time, which represents the average change in the outcome variable over time across subjects. The random effects estimates show the variation in the intercept (initial level) of the outcome variable across subjects. By examining the fixed and random effects, we can gain insights into how the outcome variable changes over time and how this change differs between subjects."
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html",
    "href": "2_Tutorials_ResidualizedChangeScores.html",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Residualized change scores are a statistical method used to assess the degree of change in a variable while controlling for its initial level. The approach involves calculating the residualized change scores by regressing post-treatment scores on pre-treatment scores and using the resulting residuals as the measure of change. This estimated change score adjusts for baseline scores while ignoring any prior group assignments/differences. The residualized change score is often included in subsequent analysis, such as an examination of intervention effects in pre-test/post-test designs [@Kisbu-Sakarya2013]. This method is useful when there is a high correlation between the pre-treatment and post-treatment scores, which can make it difficult to determine the true degree of change. Research studies have shown that this method can provide more accurate and reliable results compared to other methods of measuring change, such as raw change scores or gain scores (Kenny, 1979; Rogosa & Willett, 1985).\nResidualized change scores are a method used to analyze change in a variable over time, while accounting for the initial level of that variable. By using residualized change scores, we can examine the extent to which changes in one variable are associated with changes in another variable, controlling for the initial level of the variables.\n\n\n\nResidualized Change Score 1_Tutorial\n\n\nxxxxxx ### When to use Residualized Change Score Models? You should use residualized change scores in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\nIn this tutorial, we will introduce the concept of residualized change scores and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of residualized change scores.\nCalculate residualized change scores using example data.\nInterpret the results of the residualized change scores analysis."
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html#overview",
    "href": "2_Tutorials_ResidualizedChangeScores.html#overview",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Residualized change scores are a statistical method used to assess the degree of change in a variable while controlling for its initial level. The approach involves calculating the residualized change scores by regressing post-treatment scores on pre-treatment scores and using the resulting residuals as the measure of change. This estimated change score adjusts for baseline scores while ignoring any prior group assignments/differences. The residualized change score is often included in subsequent analysis, such as an examination of intervention effects in pre-test/post-test designs [@Kisbu-Sakarya2013]. This method is useful when there is a high correlation between the pre-treatment and post-treatment scores, which can make it difficult to determine the true degree of change. Research studies have shown that this method can provide more accurate and reliable results compared to other methods of measuring change, such as raw change scores or gain scores (Kenny, 1979; Rogosa & Willett, 1985).\nResidualized change scores are a method used to analyze change in a variable over time, while accounting for the initial level of that variable. By using residualized change scores, we can examine the extent to which changes in one variable are associated with changes in another variable, controlling for the initial level of the variables.\n\n\n\nResidualized Change Score 1_Tutorial\n\n\nxxxxxx ### When to use Residualized Change Score Models? You should use residualized change scores in the following scenario: 1. You want to know xxxxx 2. Your variable xxxxx 3. You have xxxxx\n\n\nIn this tutorial, we will introduce the concept of residualized change scores and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of residualized change scores.\nCalculate residualized change scores using example data.\nInterpret the results of the residualized change scores analysis."
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html#basic-example",
    "href": "2_Tutorials_ResidualizedChangeScores.html#basic-example",
    "title": "Residualized Change Scores",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nTime point (T1, T2)\nJob satisfaction (independent variable)\nLife satisfaction (dependent variable)\n\n\n\n\nIndividual\nTime Point\nJob Satisfaction\nLife Satisfaction\n\n\n\n\nA\nT1\n7\n6\n\n\nA\nT2\n8\n7\n\n\nB\nT1\n6\n5\n\n\nB\nT2\n7\n6\n\n\n\n\nModel Specification and Estimation\nTo calculate residualized change scores, we will follow these steps:\n\nCalculate the raw change scores for each variable by subtracting the T1 value from the T2 value.\nFit a regression model with the change score of the dependent variable (life satisfaction) as the outcome and the change score of the independent variable (job satisfaction) and the initial level of the dependent variable (T1 life satisfaction) as predictors.\nExtract the residuals from the regression model. These residuals represent the residualized change scores.\n\nUsing the example dataset, we can calculate the residualized change scores for life satisfaction as follows:\n\nCalculate raw change scores:\n\n\n\nIndividual\nJob Satisfaction Change\nLife Satisfaction Change\n\n\n\n\nA\n1\n1\n\n\nB\n1\n1\n\n\n\nFit the regression model:\nLife Satisfaction Change = b0 + b1 * Job Satisfaction Change + b2 * T1 Life Satisfaction\nExtract residuals:\n\n\n\nIndividual\nResidualized Change Score\n\n\n\n\nA\ne1\n\n\nB\ne2\n\n\n\n\n\n\nInterpreting the Results\nResidualized change scores represent the change in the dependent variable (life satisfaction) after accounting for the initial level of that variable and the change in the independent variable (job satisfaction). By examining the association between the residualized change scores of two variables, we can gain insights into how changes in one variable are related to changes in another variable, controlling for initial levels."
  }
]
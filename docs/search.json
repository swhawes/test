[
  {
    "objectID": "13_Tutorials_GrowthMixtureModels.html",
    "href": "13_Tutorials_GrowthMixtureModels.html",
    "title": "Growth Mixture Models",
    "section": "",
    "text": "Growth Mixture Models (GMMs) are a type of statistical model that aims to identify distinct subgroups or classes within a population based on their growth trajectories. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a Growth Mixture Model using the lcmm package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lcmm package, which provides functions for fitting Growth Mixture Models."
  },
  {
    "objectID": "13_Tutorials_GrowthMixtureModels.html#overview",
    "href": "13_Tutorials_GrowthMixtureModels.html#overview",
    "title": "Growth Mixture Models",
    "section": "",
    "text": "Growth Mixture Models (GMMs) are a type of statistical model that aims to identify distinct subgroups or classes within a population based on their growth trajectories. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a Growth Mixture Model using the lcmm package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lcmm package, which provides functions for fitting Growth Mixture Models."
  },
  {
    "objectID": "13_Tutorials_GrowthMixtureModels.html#basic-example",
    "href": "13_Tutorials_GrowthMixtureModels.html#basic-example",
    "title": "Growth Mixture Models",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Install the lcmm package if not already installed\nif (!(\"lcmm\" %in% installed.packages())) {\n  install.packages(\"lcmm\")\n}\n\n\nLoad the lcmm package\n\n\nCode\nlibrary(lcmm)\n\n\nSimulating the Data For this tutorial, we will use a simulated dataset with three growth trajectory classes, where each class represents a different pattern of change over time. The dataset will consist of 300 individuals with four repeated measurements (time points) for each individual.\n\n\nCode\nset.seed(123)\nn &lt;- 300\ntimepoints &lt;- 4\n\n# Simulate the data for each class\nclass1 &lt;- data.frame(id = 1:(n / 3),\n                     time = rep(1:timepoints, each = n / 3),\n                     class = 1,\n                     value = rnorm(n * timepoints / 3, mean = 1 + 0.5 * (1:timepoints), sd = 0.5))\n\nclass2 &lt;- data.frame(id = (n / 3 + 1):(2 * n / 3),\n                     time = rep(1:timepoints, each = n / 3),\n                     class = 2,\n                     value = rnorm(n * timepoints / 3, mean = 2 - 0.3 * (1:timepoints), sd = 0.5))\n\nclass3 &lt;- data.frame(id = (2 * n / 3 + 1):n,\n                     time = rep(1:timepoints, each = n / 3),\n                     class = 3,\n                     value = rnorm(n * timepoints / 3, mean = 3 + 0.1 * (1:timepoints), sd = 0.5))\n\n\n\n\nCode\n# Combine the data from all classes\ndata &lt;- rbind(class1, class2, class3)\n\n\n\nModel Specification and Estimation\nNow that we have our simulated data, we can fit a Growth Mixture Model. In this example, we will assume that there are three latent classes. However, in practice, the number of classes is usually unknown and must be determined through model comparisons or other methods.\n\n\nCode\n# Fit the Growth Mixture Model\ngmm &lt;- hlme(value ~ time,\n            random = ~ time,\n            subject = \"id\",\n            mixture = ~ time,\n            data = data,\n            ng = 3,\n            B = list(value = c(1, 0, 0, 0)\n\n\n\n\nInterpreting the Results\nxxxxxx"
  },
  {
    "objectID": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html",
    "href": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "",
    "text": "Random-Intercept Cross-Lagged Panel Models (RI-CLPM) are a type of structural equation model used to analyze longitudinal data with repeated measures of multiple variables. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a RI-CLPM using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including RI-CLPMs.\n\n\nCode\n# Install the lavaan package if not already installed\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}\n# Load the lavaan package\nlibrary(lavaan)"
  },
  {
    "objectID": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#overview",
    "href": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#overview",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "",
    "text": "Random-Intercept Cross-Lagged Panel Models (RI-CLPM) are a type of structural equation model used to analyze longitudinal data with repeated measures of multiple variables. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a RI-CLPM using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including RI-CLPMs.\n\n\nCode\n# Install the lavaan package if not already installed\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}\n# Load the lavaan package\nlibrary(lavaan)"
  },
  {
    "objectID": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#basic-example",
    "href": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#basic-example",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "Basic Example",
    "text": "Basic Example\nSimulating the Data For this tutorial, we will use a simulated dataset with 500 individuals, each measured at five time points. The dataset will contain two variables, X and Y, with cross-lagged effects.\n\n\nCode\nset.seed(123)\nn &lt;- 500\ntimepoints &lt;- 5\n\n# Simulate the data\ndata &lt;- data.frame(id = rep(1:n, each = timepoints),\n                   time = rep(1:timepoints, times = n),\n                   X = rnorm(n * timepoints, mean = 0, sd = 1),\n                   Y = rnorm(n * timepoints, mean = 0, sd = 1))\n\n# Introduce cross-lagged effects\nfor (i in 2:timepoints) {\n  data$X[data$time == i] &lt;- 0.3 * data$Y[data$time == (i - 1)] + data$X[data$time == i]\n  data$Y[data$time == i] &lt;- 0.2 * data$X[data$time == (i - 1)] + data$Y[data$time == i]\n}\n\n\n\nModel Specification and Estimation\nNow that we have our simulated data, we can fit a Random-Intercept Cross-Lagged Panel Model using the lavaan package.\n\n\nCode\n# Define the model\nmodel &lt;- '\n  # Random intercepts\n  i_X =~ 1 * X_t1 + 1 * X_t2 + 1 * X_t3 + 1 * X_t4 + 1 * X_t5\n  i_Y =~ 1 * Y_t1 + 1 * Y_t2 + 1 * Y_t3 + 1 * Y_t4 + 1 * Y_t5\n\n  # Cross-lagged effects\n  Y_t2 ~ beta_YX * X_t1\n  Y_t3 ~ beta_YX * X_t2\n  Y_t4 ~ beta_YX * X_t3\n  Y_t5 ~ beta_YX * X_t4\n\n  X_t2 ~ beta_XY * Y_t1\n  X_t3 ~ beta_XY *\n\n\n\n\nInterpreting the Results\nxxxxxx"
  },
  {
    "objectID": "blank.html",
    "href": "blank.html",
    "title": "Blank Test Page",
    "section": "",
    "text": "Blank Blank Blank"
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html",
    "href": "5_Tutorials_MarginalModels.html",
    "title": "Marginal Models",
    "section": "",
    "text": "Marginal models are a statistical method used to analyze longitudinal or clustered data. The marginal model estimates the average effect of the independent variables on the outcome while accounting for the within-subject correlation, and allows for the estimation of population-averaged effects, in contrast to subject-specific effects estimated by random-effects models (Verbeke & Molenberghs, 2000). The method is similar to the GEE approach but uses a different estimation technique and does not account for subject-specific effects. Marginal models have been shown to be robust to non-normality and non-constant variance, and can handle unbalanced or unequally spaced data (Fitzmaurice et al., 2011). The term marginal in this context is used to emphasize that the model for the mean response at each occasion depends only on the covariates of interest, and not on any random effects or previous responses.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal marginal models and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal marginal models.\nFit a longitudinal marginal model using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html#overview",
    "href": "5_Tutorials_MarginalModels.html#overview",
    "title": "Marginal Models",
    "section": "",
    "text": "Marginal models are a statistical method used to analyze longitudinal or clustered data. The marginal model estimates the average effect of the independent variables on the outcome while accounting for the within-subject correlation, and allows for the estimation of population-averaged effects, in contrast to subject-specific effects estimated by random-effects models (Verbeke & Molenberghs, 2000). The method is similar to the GEE approach but uses a different estimation technique and does not account for subject-specific effects. Marginal models have been shown to be robust to non-normality and non-constant variance, and can handle unbalanced or unequally spaced data (Fitzmaurice et al., 2011). The term marginal in this context is used to emphasize that the model for the mean response at each occasion depends only on the covariates of interest, and not on any random effects or previous responses.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal marginal models and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal marginal models.\nFit a longitudinal marginal model using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html#basic-example",
    "href": "5_Tutorials_MarginalModels.html#basic-example",
    "title": "Marginal Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\nModel Specification and Estimation\nWe will use the geepack package in R to fit a longitudinal marginal model. First, install and load the required package:\n\n\nCode\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"geepack\")\nlibrary(geepack)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\n\nFit the longitudinal marginal model with a binary outcome using a logit link function:\n\n\nCode\nmodel &lt;- geeglm(outcome ~ time, data = data, id = subject_id, family = binomial(link = \"logit\"), corstr = \"exchangeable\")\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal marginal model, we can use the summary() function in R to display the estimated population-averaged effects:\n\n\nCode\nsummary(model)\n\n\n\nCall:\ngeeglm(formula = outcome ~ time, family = binomial(link = \"logit\"), \n    data = data, id = subject_id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err Wald Pr(&gt;|W|)\n(Intercept)   -43.54     NaN  NaN      NaN\ntime           82.78     NaN  NaN      NaN\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept) 2.22e-16     NaN\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha     -0.5     NaN\nNumber of clusters:   2  Maximum cluster size: 3 \n\n\nThe output will show the estimated effect of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level."
  },
  {
    "objectID": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html",
    "href": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "",
    "text": "xxxx Autoregressive cross-lagged panel models (ACPMs) are a type of statistical model used to analyze longitudinal data and examine the temporal relationships between two or more variables over time. These models help to disentangle within-person effects from between-person effects and can estimate both autoregressive effects (influence of a variable on itself over time) and cross-lagged effects (influence of one variable on another variable over time).\nautoregressive cross-lagged panel models, commonly known as CLPMs. CLPMs are a statistical method used to analyze longitudinal data, particularly when we want to examine the reciprocal relationships between two or more variables over time. In essence, CLPMs allow us to investigate whether one variable at an earlier time point can predict another variable at a later time point, and vice versa.\nCLPMs are useful when we want to go beyond simple correlations between variables at different time points and instead model the dynamic interplay between them. Specifically, CLPMs account for the possibility that the relationship between two variables at one time point may influence their relationship at a subsequent time point. These models can also account for autocorrelation, meaning that the same variable measured over time is correlated with itself.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of autoregressive cross-lagged panel models (ACPMs) and guide you through a simple example using a larger dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of ACPMs.\nFit an ACPM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#overview",
    "href": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#overview",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "",
    "text": "xxxx Autoregressive cross-lagged panel models (ACPMs) are a type of statistical model used to analyze longitudinal data and examine the temporal relationships between two or more variables over time. These models help to disentangle within-person effects from between-person effects and can estimate both autoregressive effects (influence of a variable on itself over time) and cross-lagged effects (influence of one variable on another variable over time).\nautoregressive cross-lagged panel models, commonly known as CLPMs. CLPMs are a statistical method used to analyze longitudinal data, particularly when we want to examine the reciprocal relationships between two or more variables over time. In essence, CLPMs allow us to investigate whether one variable at an earlier time point can predict another variable at a later time point, and vice versa.\nCLPMs are useful when we want to go beyond simple correlations between variables at different time points and instead model the dynamic interplay between them. Specifically, CLPMs account for the possibility that the relationship between two variables at one time point may influence their relationship at a subsequent time point. These models can also account for autocorrelation, meaning that the same variable measured over time is correlated with itself.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of autoregressive cross-lagged panel models (ACPMs) and guide you through a simple example using a larger dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of ACPMs.\nFit an ACPM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#basic-example",
    "href": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#basic-example",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simulated dataset containing the following information for a group of 100 individuals:\n\nSubject ID\nTime (in years)\nVariable 1 (e.g., stress level)\nVariable 2 (e.g., job satisfaction)\n\n\n\nCode\nset.seed(123)  # For reproducibility\nn_subjects &lt;- 100\nn_timepoints &lt;- 3\nsubject_ids &lt;- factor(rep(1:n_subjects, each = n_timepoints))\ntime &lt;- rep(0:(n_timepoints - 1), times = n_subjects)\nvariable1 &lt;- rnorm(n_subjects * n_timepoints, mean = 3, sd = 1)\nvariable2 &lt;- rnorm(n_subjects * n_timepoints, mean = 3, sd = 1)\n\ndata &lt;- data.frame(subject_id = subject_ids, time = time, variable1 = variable1, variable2 = variable2)\n\n\n\nModel Specification and Estimation\nWe will use the lavaan package in R to fit an ACPM. First, install the required package, if not already installed:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nlibrary(lavaan)\n\n\nDefine the ACPM with three timepoints:\n\n\nCode\nmodel &lt;- \n  # Autoregressive paths\n  variable1_t2 ~ a1 * variable1_t1\n  variable1_t1 ~ a2 * variable1_t0\n\n\nvariable1_t1 ~ a2 * variable1_t0\n\n\nCode\n  variable2_t2 ~ a3 * variable2_t1\n\n\nvariable2_t2 ~ a3 * variable2_t1\n\n\nCode\n  variable2_t1 ~ a4 * variable2_t0\n\n\nvariable2_t1 ~ a4 * variable2_t0\n\n\nCode\n  # Cross-lagged paths\n  variable1_t2 ~ b1 * variable2_t1\n\n\nvariable1_t2 ~ b1 * variable2_t1\n\n\nCode\n  variable1_t1 ~ b2 * variable2_t0\n\n\nvariable1_t1 ~ b2 * variable2_t0\n\n\nCode\n  variable2_t2 ~ b3 * variable1_t1\n\n\nvariable2_t2 ~ b3 * variable1_t1\n\n\nCode\n  variable2_t1 ~ b4 * variable1_t0\n\n\nvariable2_t1 ~ b4 * variable1_t0\n\n\nFit the ACPM using the lavaan function:\n\n\nCode\n#fit &lt;- lavaan(model, data = data, missing = )\n\n\n\n\nInterpreting the Results\nxxxxxxxx"
  },
  {
    "objectID": "16_Tutorials_LatentCurveModelsStructuredResiduals.html",
    "href": "16_Tutorials_LatentCurveModelsStructuredResiduals.html",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "",
    "text": "In this tutorial, we will explore Latent Curve Models with Structured Residuals (LCM-SR). LCM-SR allows for the separation of between-person and within-person components of individual change over time. By using structured residuals, we can account for time-varying covariates and interactions between variables at both the within-person and between-person levels.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nYou need to have the lavaan and semTools packages installed in R to perform LCM-SR. Install them using the following commands:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nif (!(\"semTools\" %in% installed.packages())) install.packages(\"semTools\")"
  },
  {
    "objectID": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#overview",
    "href": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#overview",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "",
    "text": "In this tutorial, we will explore Latent Curve Models with Structured Residuals (LCM-SR). LCM-SR allows for the separation of between-person and within-person components of individual change over time. By using structured residuals, we can account for time-varying covariates and interactions between variables at both the within-person and between-person levels.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nYou need to have the lavaan and semTools packages installed in R to perform LCM-SR. Install them using the following commands:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nif (!(\"semTools\" %in% installed.packages())) install.packages(\"semTools\")"
  },
  {
    "objectID": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#basic-example",
    "href": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#basic-example",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use simulated data with 500 individuals and 5 timepoints. The data will include a time-varying covariate, covariate, and an outcome variable, outcome.\n\n\nCode\nset.seed(123)\nlibrary(lavaan)\nlibrary(semTools)\n\n# Simulate data\nn &lt;- 500\ntimepoints &lt;- 5\n\nid &lt;- rep(1:n, each = timepoints)\ntime &lt;- rep(1:timepoints, n)\n\ncovariate &lt;- rnorm(n * timepoints, mean = 0, sd = 1)\noutcome &lt;- rnorm(n * timepoints, mean = 0, sd = 1)\n\ndata &lt;- data.frame(id, time, covariate, outcome)\n\n\n\nModel Specification and Estimation\nTo specify an LCM-SR, we will use the lavaan syntax to define the measurement model and the structural model. We will model the linear growth of the outcome variable while accounting for the effect of the time-varying covariate.\n\n\nCode\nmodel &lt;- '\n  # Latent variables\n  intercept =~ 1 * outcome_t1 + 1 * outcome_t2 + 1 * outcome_t3 + 1 * outcome_t4 + 1 * outcome_t5\n  slope =~ 0 * outcome_t1 + 1 * outcome_t2 + 2 * outcome_t3 + 3 * outcome_t4 + 4 * outcome_t5\n\n  # Time-varying covariate effect on outcome\n  outcome_t1 ~ c1 * covariate_t1\n  outcome_t2 ~ c2 * covariate_t2\n  outcome_t3 ~ c3 * covariate_t3\n  outcome_t4 ~ c4 * covariate_t4\n  outcome_t5 ~ c5 * covariate_t5\n\n  # Residual variances and covariances\n  outcome_t1 ~~ r1 * outcome_t1\n  outcome_t2 ~~ r2 * outcome_t2\n  outcome_t3 ~~ r3 * outcome_t3\n  outcome_t4 ~~ r4 * outcome_t4\n  outcome_t5 ~~ r5 * outcome_t5\n\n  # Latent variable variances\n  intercept ~~ i_var * intercept\n  slope ~~ s_var * slope\n\n  # Latent variable covariances\n  intercept ~~ i_s_cov * slope\n'\n\n\nModel Estimation Now we will estimate the model using the lavaan function sem().\n\n\nCode\n# Reshape data to wide format\nwide_data &lt;- spread(data, key = time, value = outcome, sep\n\n\n\n\nInterpreting the Results\nxxxxx"
  },
  {
    "objectID": "reference.html",
    "href": "reference.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "10_Tutorials_LatentGrowthCurveModels.html",
    "href": "10_Tutorials_LatentGrowthCurveModels.html",
    "title": "Latent Growth Curve Models",
    "section": "",
    "text": "In this tutorial, we’ll introduce Latent Growth Curve Models (LGCM), a powerful technique for analyzing longitudinal data. Latent Growth Curve Models allow researchers to examine individual differences in growth trajectories and the factors that might influence these trajectories. We’ll walk through an example using a dataset with three time points and a sample size of 250 participants.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "10_Tutorials_LatentGrowthCurveModels.html#overview",
    "href": "10_Tutorials_LatentGrowthCurveModels.html#overview",
    "title": "Latent Growth Curve Models",
    "section": "",
    "text": "In this tutorial, we’ll introduce Latent Growth Curve Models (LGCM), a powerful technique for analyzing longitudinal data. Latent Growth Curve Models allow researchers to examine individual differences in growth trajectories and the factors that might influence these trajectories. We’ll walk through an example using a dataset with three time points and a sample size of 250 participants.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "10_Tutorials_LatentGrowthCurveModels.html#basic-example",
    "href": "10_Tutorials_LatentGrowthCurveModels.html#basic-example",
    "title": "Latent Growth Curve Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we’ll use a hypothetical dataset called “data” with the following variables:\nsubject_id: A unique identifier for each participant score_t1: The measurement of a variable of interest at Time 1 score_t2: The measurement of the same variable at Time 2 score_t3: The measurement of the same variable at Time 3 First, let’s load the “lavaan” package and create a dataset for this example:\n\n\nCode\nlibrary(lavaan)\n\n# Create a sample dataset with 250 participants\nset.seed(42) # For reproducibility\nsubject_id &lt;- 1:250\nscore_t1 &lt;- rnorm(250, mean = 20, sd = 5)\nscore_t2 &lt;- score_t1 + rnorm(250, mean = 2, sd = 3)\nscore_t3 &lt;- score_t2 + rnorm(250, mean = 3, sd = 4)\ndata &lt;- data.frame(subject_id, score_t1, score_t2, score_t3)\n\n\n\nModel Specification and Estimation\nNow, let’s specify the Latent Growth Curve Model. In this example, we’ll estimate the intercept (initial level) and slope (rate of change) for the variable of interest, as well as the variances of the intercept and slope.\n\n\nCode\n# Define the Latent Growth Curve Model\nmodel &lt;- '\n  # Latent variables\n    i =~ 1 * score_t1 + 1 * score_t2 + 1 * score_t3\n    s =~ 0 * score_t1 + 1 * score_t2 + 2 * score_t3\n\n  # Means\n    i ~ mu_i\n    s ~ mu_s\n\n  # Variances\n    i ~~ var_i * i\n    s ~~ var_s * s\n\n  # Covariance\n    i ~~ cov_is * s\n'\n\n\n\n\nCode\n# Fit the model\nfit &lt;- sem(model, data = data, missing = \"FIML\")\n\n\n\n\nInterpreting the Results\nWe can now examine the results of our Latent Growth Curve Model. The main parameters of interest are:\nmu_i: The mean intercept (initial level) of the variable of interest mu_s: The mean slope (rate of change) of the variable of interest var_i: The variance of the intercept, which reflects individual differences in initial levels var_s: The variance of the slope, which reflects individual differences in rates"
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html",
    "href": "4_Tutorials_SignedRankTest.html",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The longitudinal signed-rank test is a nonparametric alternative to the paired t-test and is appropriate when the data are not normally distributed or when the assumptions of the paired t-test are violated. The test is based on the signed-rank of the differences between the paired observations, and it tests the null hypothesis that the median of the differences is zero. The repeated-measures design allows for the assessment of within-subject changes over time or under different conditions. The signed-rank test is robust to outliers and does not assume a normal distribution of the differences. This method has been shown to have good statistical power and efficiency, particularly when the sample size is small or the distribution is heavily skewed (Erceg-Hurn & Mirosevich, 2008; Bakdash & Marusich, 2017; Garcia-Berthou & Alcaraz, 2004). The signed-rank test is a useful tool for analyzing paired data when the assumption of normality is violated or when the data is highly skewed or contains outliers.\n[+add diagrams/figures]\n\n\nYou should use a Wilcoxon Signed-Rank Test in the following scenario:\n\nYou want to know if two groups are different on your variable of interest\nYour variable of interest is continuous\nYou have two and only two groups\nYou have independent samples\nYou have a skewed variable of interest\n\n\n\n\nIn this tutorial, we will introduce the concept of the longitudinal signed-rank test and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of the longitudinal signed-rank test.\nPerform a longitudinal signed-rank test using example data in R.\nInterpret the results of the test."
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html#overview",
    "href": "4_Tutorials_SignedRankTest.html#overview",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The longitudinal signed-rank test is a nonparametric alternative to the paired t-test and is appropriate when the data are not normally distributed or when the assumptions of the paired t-test are violated. The test is based on the signed-rank of the differences between the paired observations, and it tests the null hypothesis that the median of the differences is zero. The repeated-measures design allows for the assessment of within-subject changes over time or under different conditions. The signed-rank test is robust to outliers and does not assume a normal distribution of the differences. This method has been shown to have good statistical power and efficiency, particularly when the sample size is small or the distribution is heavily skewed (Erceg-Hurn & Mirosevich, 2008; Bakdash & Marusich, 2017; Garcia-Berthou & Alcaraz, 2004). The signed-rank test is a useful tool for analyzing paired data when the assumption of normality is violated or when the data is highly skewed or contains outliers.\n[+add diagrams/figures]\n\n\nYou should use a Wilcoxon Signed-Rank Test in the following scenario:\n\nYou want to know if two groups are different on your variable of interest\nYour variable of interest is continuous\nYou have two and only two groups\nYou have independent samples\nYou have a skewed variable of interest\n\n\n\n\nIn this tutorial, we will introduce the concept of the longitudinal signed-rank test and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of the longitudinal signed-rank test.\nPerform a longitudinal signed-rank test using example data in R.\nInterpret the results of the test."
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html#basic-example",
    "href": "4_Tutorials_SignedRankTest.html#basic-example",
    "title": "Signed-Rank Test",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime point 1 (T1) measurement\nTime point 2 (T2) measurement\n\n\n\n\nSubject ID\nT1\nT2\n\n\n\n\n1\n100\n105\n\n\n2\n95\n100\n\n\n3\n110\n112\n\n\n\n\nModel Specification and Estimation\nWe will use the wilcox.test() function in R to perform a longitudinal signed-rank test. First, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 2, 3),\n  t1 = c(100, 95, 110),\n  t2 = c(105, 100, 112)\n)\n\n\nPerform the longitudinal signed-rank test using the wilcox.test() function with the paired = TRUE argument:\n\n\nCode\ntest_result &lt;- wilcox.test(data$t1, data$t2, paired = TRUE)\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal signed-rank test, examine the p-value from the test_result object:\n\n\nCode\ntest_result$p.value\n\n\n[1] 0.1735682\n\n\nThe p-value represents the probability of observing the data if there is no difference between the measurements at T1 and T2. If the p-value is less than a predetermined significance level (e.g., 0.05), we can reject the null hypothesis that there is no difference between the two time points and conclude that there is a significant difference in the measurements between T1 and T2."
  },
  {
    "objectID": "11_Tutorials_MultivariateLatentGrowthCurveModels.html",
    "href": "11_Tutorials_MultivariateLatentGrowthCurveModels.html",
    "title": "Multivariate Latent Growth Curves",
    "section": "",
    "text": "In this tutorial, we will introduce the Multivariate Latent Growth Curve Model (MLGCM), also known as Parallel Process Latent Growth Curve Model. These models allow us to analyze multiple growth processes simultaneously, examining the relationships between the initial levels and growth rates of multiple variables over time.\nWe will use the “lavaan” package in R to fit a MLGCM with two variables, each measured at three timepoints. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#overview",
    "href": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#overview",
    "title": "Multivariate Latent Growth Curves",
    "section": "",
    "text": "In this tutorial, we will introduce the Multivariate Latent Growth Curve Model (MLGCM), also known as Parallel Process Latent Growth Curve Model. These models allow us to analyze multiple growth processes simultaneously, examining the relationships between the initial levels and growth rates of multiple variables over time.\nWe will use the “lavaan” package in R to fit a MLGCM with two variables, each measured at three timepoints. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#basic-example",
    "href": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#basic-example",
    "title": "Multivariate Latent Growth Curves",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Load necessary packages\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nlibrary(lavaan)\n\n# Generate sample data\nset.seed(42)\nn &lt;- 250\ntime1_var1 &lt;- rnorm(n, mean = 10, sd = 3)\ntime2_var1 &lt;- time1_var1 + rnorm(n, mean = 2, sd = 2)\ntime3_var1 &lt;- time2_var1 + rnorm(n, mean = 2, sd = 2)\n\ntime1_var2 &lt;- rnorm(n, mean = 5, sd = 2)\ntime2_var2 &lt;- time1_var2 + rnorm(n, mean = 1, sd = 1)\ntime3_var2 &lt;- time2_var2 + rnorm(n, mean = 1, sd = 1)\n\n# Combine into a data frame\ndata &lt;- data.frame(time1_var1, time2_var1, time3_var1,\n                   time1_var2, time2_var2, time3_var2)\n\n\n\nModel Specification and Estimation\n\n\nCode\n# Specify the multivariate latent growth curve model\nmodel &lt;- '\n  # Intercept and slope factors for variable 1\n  i_var1 =~ 1*time1_var1 + 1*time2_var1 + 1*time3_var1\n  s_var1 =~ 0*time1_var1 + 1*time2_var1 + 2*time3_var1\n\n  # Intercept and slope factors for variable 2\n  i_var2 =~ 1*time1_var2 + 1*time2_var2 + 1*time3_var2\n  s_var2 =~ 0*time1_var2 + 1*time2_var2 + 2*time3_var2\n'\n\n\n\n\nCode\n# Estimate the model\nfit &lt;- lavaan::sem(model, data = data)\n\n\n\n\nCode\nsummary(fit, fit.measures = TRUE)\n\n\nlavaan 0.6-12 ended normally after 63 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 1.840\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.871\n\nModel Test Baseline Model:\n\n  Test statistic                              1631.463\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.006\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2900.271\n  Loglikelihood unrestricted model (H1)      -2899.351\n                                                      \n  Akaike (AIC)                                5832.542\n  Bayesian (BIC)                              5888.886\n  Sample-size adjusted Bayesian (BIC)         5838.164\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.045\n  P-value RMSEA &lt;= 0.05                          0.961\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.010\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i_var1 =~                                           \n    time1_var1        1.000                           \n    time2_var1        1.000                           \n    time3_var1        1.000                           \n  s_var1 =~                                           \n    time1_var1        0.000                           \n    time2_var1        1.000                           \n    time3_var1        2.000                           \n  i_var2 =~                                           \n    time1_var2        1.000                           \n    time2_var2        1.000                           \n    time3_var2        1.000                           \n  s_var2 =~                                           \n    time1_var2        0.000                           \n    time2_var2        1.000                           \n    time3_var2        2.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i_var1 ~~                                           \n    s_var1            0.240    0.365    0.658    0.511\n    i_var2           -0.157    0.394   -0.400    0.689\n    s_var2            0.015    0.123    0.121    0.904\n  s_var1 ~~                                           \n    i_var2           -0.057    0.183   -0.310    0.757\n    s_var2            0.102    0.058    1.771    0.077\n  i_var2 ~~                                           \n    s_var2           -0.185    0.127   -1.454    0.146\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .time1_var1       -0.101    0.520   -0.194    0.846\n   .time2_var1        1.999    0.344    5.807    0.000\n   .time3_var1        0.031    0.733    0.043    0.966\n   .time1_var2       -0.348    0.190   -1.826    0.068\n   .time2_var2        0.689    0.116    5.950    0.000\n   .time3_var2       -0.460    0.224   -2.055    0.040\n    i_var1            8.630    0.931    9.274    0.000\n    s_var1            1.866    0.336    5.557    0.000\n    i_var2            4.947    0.481   10.291    0.000\n    s_var2            0.647    0.108    5.979    0.000\n\n\n\n\nInterpreting the Results\nIn the output, you will see the estimates for the factor loadings, intercepts, and slopes for both variables. These estimates describe the initial levels and growth rates for each variable. You will also see the variances and covariances of the latent intercept and slope factors, which provide information about individual differences in initial levels and growth rates, as well as the relationships between the initial levels and growth rates across the two variables.\nPay attention to the model fit indices (e.g., CFI, TLI, RMSEA, and SRMR) to evaluate how well the model fits the data. Good model fit is indicated by CFI and TLI values close to or greater than 0.95, RMSEA values close to or smaller than 0.06, and SRMR values close to or smaller than xxx"
  },
  {
    "objectID": "6_Tutorials_GeneralizedEstimatingEquations.html",
    "href": "6_Tutorials_GeneralizedEstimatingEquations.html",
    "title": "Generalized Estimating Equations",
    "section": "",
    "text": "[*add diagrams/figures]"
  },
  {
    "objectID": "6_Tutorials_GeneralizedEstimatingEquations.html#overview",
    "href": "6_Tutorials_GeneralizedEstimatingEquations.html#overview",
    "title": "Generalized Estimating Equations",
    "section": "Overview",
    "text": "Overview\nGeneralized estimating equations (GEEs) are a statistical method used to analyze longitudinal or clustered data, while accounting for within-subject correlation. The goal GEEs are to make inferences about population-averaged effects (controlling for within-subject correlations), rather than individual subject-level effects. GEEs can handle a wide range of outcome distributions, including binary, count, and continuous data (Fitzmaurice et al., 2011; Hardin & Hilbe, 2012). This method is an extension of the generalized linear model (Diggle et al., 2002), shows good statistical power and efficiency, is robust to non-normality and non-constant variance and can handle unbalanced or unequally spaced data.\n\nWhen to use Longitudinal Generalized Estimating Equations (GEEs)?\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\nGetting Started with Longitudinal Generalized Estimating Equations (GEEs)\nIn this tutorial, we will introduce the concept of longitudinal generalized estimating equations (GEEs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GEEs.\nFit a GEE model using example data in R.\nInterpret the results of the model.\n\n\n\nBasic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\n\nModel Specification and Estimation\nWe will use the geepack package in R to fit a longitudinal GEE model. First, install and load the required package:\n\n\nCode\nif (!(\"geepack\" %in% installed.packages())) install.packages(\"geepack\")\nlibrary(geepack)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\n\nFit the longitudinal GEE model with a binary outcome using a logit link function and an exchangeable correlation structure:\n\n\nCode\nmodel &lt;- geeglm(outcome ~ time, data = data, id = subject_id, family = binomial(link = \"logit\"), corstr = \"exchangeable\")\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal GEE model, we can use the summary() function in R to display the estimated population-averaged effects:\n\n\nCode\nsummary(model)\n\n\n\nCall:\ngeeglm(formula = outcome ~ time, family = binomial(link = \"logit\"), \n    data = data, id = subject_id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err Wald Pr(&gt;|W|)\n(Intercept)   -43.54     NaN  NaN      NaN\ntime           82.78     NaN  NaN      NaN\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept) 2.22e-16     NaN\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha     -0.5     NaN\nNumber of clusters:   2  Maximum cluster size: 3 \n\n\nThe output will show the estimated effect of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level."
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html",
    "href": "14_Tutorials_StateTraitModels.html",
    "title": "State-Trait Models",
    "section": "",
    "text": "State-Trait Models are a type of statistical model used to separate the variance in a given variable into two components: a stable, trait-like component and a time-specific, state-like component. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a State-Trait Model using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including State-Trait Models."
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html#overview",
    "href": "14_Tutorials_StateTraitModels.html#overview",
    "title": "State-Trait Models",
    "section": "",
    "text": "State-Trait Models are a type of statistical model used to separate the variance in a given variable into two components: a stable, trait-like component and a time-specific, state-like component. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a State-Trait Model using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including State-Trait Models."
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html#basic-example",
    "href": "14_Tutorials_StateTraitModels.html#basic-example",
    "title": "State-Trait Models",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Install the lavaan package if not already installed\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html#simulating-the-data",
    "href": "14_Tutorials_StateTraitModels.html#simulating-the-data",
    "title": "State-Trait Models",
    "section": "Simulating the Data",
    "text": "Simulating the Data\nFor this tutorial, we will use a simulated dataset with 300 individuals, each measured at four time points. The dataset will contain a variable with both state-like and trait-like components.\n\n\nCode\nset.seed(123)\nn &lt;- 300\ntimepoints &lt;- 4\n\n# Simulate the trait-like component\ntrait &lt;- rnorm(n, mean = 100, sd = 10)\n\n# Simulate the state-like component\nstate &lt;- matrix(rnorm(n * timepoints, mean = 0, sd = 5), nrow = n, ncol = timepoints)\n\n# Combine trait and state components\ndata &lt;- data.frame(id = rep(1:n, each = timepoints),\n                   time = rep(1:timepoints, times = n),\n                   value = c(t(trait + state)))\n\n\n\nModel Specification and Estimation\nNow that we have our simulated data, we can fit a State-Trait Model using the lavaan package. The model will estimate the trait-like and state-like components for each individual.\n\n\nCode\n# Define the model\nmodel &lt;- '\n  # Trait component\n  trait =~ 1 * value_t1 + 1 * value_t2 + 1 * value_t3 + 1 * value_t4\n\n  # State component\n  state =~ value_t1 + value_t2 + value_t3 + value_t4\n\n  # Residual variances\n  value_t1 ~~ value_t1\n  value_t2 ~~ value_t2\n  value_t3 ~~ value_t3\n  value_t4 ~~ value_t4\n'\n\n\n\n\nCode\n# Reshape the data to wide format\ndata_wide &lt;- reshape(data, idvar = \"id\", timevar = \"time\", direction = \"wide\")\n\n\n\n\nCode\n# Fit the State-Trait Model\nfit &lt;- sem(model, data = data_wide)\n\n\n\n\nInterpreting the Results\nNow that we have estimated our State-Trait Model, we can interpret the results. The key parameters of interest in this model are the trait-like and state-like components, which are the variances attributed to each component.\n\n\nCode\n# Obtain the results\nsummary(fit)"
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "",
    "text": "Generalized linear mixed-effects models (GLMMs) are a statistical method used to analyze longitudinal or clustered data that accounts for within-subject correlation and allows for the estimation of subject-specific effects (Pinheiro & Bates, 2000; Fitzmaurice et al., 2011). This method extends the generalized linear mixed-effects model by modeling both fixed-effects (population-averaged effects) and random-effects (subject-specific deviations), while accounting for within-subject correlations. The method can handle unbalanced or unequally spaced data, and can accommodate various outcome distributions, including binary, count, and continuous data. GLMMs have been shown to have good statistical power and efficiency, and can be used to model complex data structures, including crossed and nested random effects. GLMMs have been shown to outperform other methods, such as GEE, in terms of statistical power and efficiency (Hardin & Hilbe, 2012).\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal generalized linear mixed effects models (GLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GLMMs.\nFit a GLMM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#overview",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#overview",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "",
    "text": "Generalized linear mixed-effects models (GLMMs) are a statistical method used to analyze longitudinal or clustered data that accounts for within-subject correlation and allows for the estimation of subject-specific effects (Pinheiro & Bates, 2000; Fitzmaurice et al., 2011). This method extends the generalized linear mixed-effects model by modeling both fixed-effects (population-averaged effects) and random-effects (subject-specific deviations), while accounting for within-subject correlations. The method can handle unbalanced or unequally spaced data, and can accommodate various outcome distributions, including binary, count, and continuous data. GLMMs have been shown to have good statistical power and efficiency, and can be used to model complex data structures, including crossed and nested random effects. GLMMs have been shown to outperform other methods, such as GEE, in terms of statistical power and efficiency (Hardin & Hilbe, 2012).\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal generalized linear mixed effects models (GLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GLMMs.\nFit a GLMM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#basic-example",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#basic-example",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\nModel Specification and Estimation\nWe will use the lme4 package in R to fit a longitudinal GLMM. First, install the required package, if not already installed:\n\n\nCode\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nlibrary(lme4)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = factor(c(1, 1, 1, 2, 2)),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\n\nFit the longitudinal GLMM with a binary outcome using a logit link function and random intercepts for each subject:\n\n\nCode\nmodel &lt;- glmer(outcome ~ time + (1 | subject_id), data = data, family = binomial(link = \"logit\"))\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal GLMM, we can use the summary() function in R to display the estimated fixed effects and random effects:\n\n\nCode\nsummary(model)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: outcome ~ time + (1 | subject_id)\n   Data: data\n\n     AIC      BIC   logLik deviance df.resid \n     6.0      4.8      0.0      0.0        2 \n\nScaled residuals: \n      Min        1Q    Median        3Q       Max \n-1.49e-08 -1.49e-08  1.49e-08  1.49e-08  1.49e-08 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n subject_id (Intercept) 0.36     0.6     \nNumber of obs: 5, groups:  subject_id, 2\n\nFixed effects:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept) -3.834e+01  4.393e+07       0        1\ntime         7.526e+01  4.011e+07       0        1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime -0.730\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nunable to evaluate scaled gradient\n Hessian is numerically singular: parameters are not uniquely determined\n\n\nThe output will show the estimated fixed effects of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level. Additionally, the output will display information about the random effects, such as the variance of the random intercepts for subjects."
  },
  {
    "objectID": "12_Tutorials_LatentTransitionAnalysis.html",
    "href": "12_Tutorials_LatentTransitionAnalysis.html",
    "title": "Latent Transition Analysis",
    "section": "",
    "text": "In this tutorial, we will introduce Latent Transition Analysis (LTA), a statistical method used to analyze the movement of individuals between latent (unobserved) statuses over time. LTA is particularly useful when dealing with categorical data and allows us to estimate the probabilities of transitioning between latent statuses.\nWe will use the “tidyLPA” package in R to fit a simple LTA model with four timepoints and three indicators per timepoint. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "12_Tutorials_LatentTransitionAnalysis.html#overview",
    "href": "12_Tutorials_LatentTransitionAnalysis.html#overview",
    "title": "Latent Transition Analysis",
    "section": "",
    "text": "In this tutorial, we will introduce Latent Transition Analysis (LTA), a statistical method used to analyze the movement of individuals between latent (unobserved) statuses over time. LTA is particularly useful when dealing with categorical data and allows us to estimate the probabilities of transitioning between latent statuses.\nWe will use the “tidyLPA” package in R to fit a simple LTA model with four timepoints and three indicators per timepoint. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "12_Tutorials_LatentTransitionAnalysis.html#basic-example",
    "href": "12_Tutorials_LatentTransitionAnalysis.html#basic-example",
    "title": "Latent Transition Analysis",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Load necessary packages\nif (!(\"tidyLPA\" %in% installed.packages())) install.packages(\"tidyLPA\")\nlibrary(tidyLPA)\n\n\n\n\nCode\nset.seed(42)\nn &lt;- 250\n\n# Generate three indicators for time 1\ntime1_ind1 &lt;- rbinom(n, size = 1, prob = 0.7)\ntime1_ind2 &lt;- rbinom(n, size = 1, prob = 0.6)\ntime1_ind3 &lt;- rbinom(n, size = 1, prob = 0.5)\n\n# Generate three indicators for time 2\ntime2_ind1 &lt;- rbinom(n, size = 1, prob = 0.6)\ntime2_ind2 &lt;- rbinom(n, size = 1, prob = 0.5)\ntime2_ind3 &lt;- rbinom(n, size = 1, prob = 0.4)\n\n# Generate three indicators for time 3\ntime3_ind1 &lt;- rbinom(n, size = 1, prob = 0.5)\ntime3_ind2 &lt;- rbinom(n, size = 1, prob = 0.4)\ntime3_ind3 &lt;- rbinom(n, size = 1, prob = 0.3)\n\n# Generate three indicators for time 4\ntime4_ind1 &lt;- rbinom(n, size = 1, prob = 0.4)\ntime4_ind2 &lt;- rbinom(n, size = 1, prob = 0.3)\ntime4_ind3 &lt;- rbinom(n, size = 1, prob = 0.2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Temporary Landing Page for Longitudinal Project",
    "section": "",
    "text": "This is github pages test site for the longitudinal analysis project. The information included within the site is for testing purposes only and contents may be inaccurate."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Sam Page Test"
  },
  {
    "objectID": "howto.html",
    "href": "howto.html",
    "title": "How-To’s: A Brief Overview",
    "section": "",
    "text": "[Section in progress…]"
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials: A Brief Overview",
    "section": "",
    "text": "[Section in progress…]"
  },
  {
    "objectID": "manuscript.html",
    "href": "manuscript.html",
    "title": "",
    "section": "",
    "text": "Code\ntitle: Manuscript Working Draft\nformat: pdf: geometry: - top=20mm - left=20mm docx: default prefer-html: true"
  },
  {
    "objectID": "manuscript.html#the-abcd-study-data",
    "href": "manuscript.html#the-abcd-study-data",
    "title": "",
    "section": "The ABCD Study® Data",
    "text": "The ABCD Study® Data\nParticipants enrolled in the ABCD Study include a large cohort of youth (n=11880) aged 9-10 years at baseline and their parents/guardians. The study sample was recruited from household populations in defined catchment areas for each of the 21 study sites across the United States (information regarding funding agencies, recruitment sites, investigators, and project organization can be obtained at the ABCD Study website). The ABCD Study is collecting longitudinal data on a rich variety of outcomes that will enable the construction of realistically-complex etiological models by incorporating factors from many domains simultaneously. Each new wave of data collection provides the building blocks for conducting probing longitudinal analyses that allow us to characterize normative development, identify variables that presage deviations from prototypic development, and assess a range of outcomes associated with variables of interest. This data includes a neurocognitive battery (Luciana et al. 2018; Thompson et al. 2019), mental and physical health assessments (Barch et al. 2018), measures of culture and environment (Zucker et al. 2018), substance use [add citation], biospecimens (Uban et al. 2018), structural and functional brain imaging (Casey et al. 2018; Hagler et al. 2019), geolocation-based environmental exposure data, wearables, and mobile technology (Bagot et al. 2018), and whole genome genotyping (Loughnan et al. 2020). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual telephone interviews between in-person visits. Data are publicly released on an annual basis through the NIMH Data Archive. By necessity, the study’s earliest data releases were cross-sectional (i.e., the baseline data), however, the most recent public data release (NDA Release 4.0) contains data collected across three annual assessments, including two imaging assessments (baseline and year 2 follow-up visits)."
  },
  {
    "objectID": "manuscript.html#organization-of-current-manuscript",
    "href": "manuscript.html#organization-of-current-manuscript",
    "title": "",
    "section": "Organization of current manuscript",
    "text": "Organization of current manuscript\nThe rich longitudinal nature of the ABCD Study dataset will allow researchers to perform analyses of both methodological and substantive interest. This report describes methods for longitudinal analyses of ABCD Study data that can address its fundamental scientific aims, as well as challenges inherent in a large population-based long-term study of adolescents. The manuscript is organized as follows:\n[section still be developed…]"
  },
  {
    "objectID": "manuscript.html#modeling-data-across-two-time-points-versus-three-or-more-time-points.",
    "href": "manuscript.html#modeling-data-across-two-time-points-versus-three-or-more-time-points.",
    "title": "",
    "section": "Modeling Data Across Two Time Points versus Three or More Time Points.",
    "text": "Modeling Data Across Two Time Points versus Three or More Time Points.\nAlthough the clear leap to the realm of longitudinal data involves going from one assessment to two or more assessments, there are also notable distinctions in designs based on two-assessment points versus three or more measurement occasions. Just as cross-sectional data can be informative in some situations, two waves of data can be beneficial in contexts such as when experimental manipulation is involved (e.g., pre/post tests), or if the central goal is prediction (e.g., trying to predict scores on Variable A at time T as a function of prior scores on Variable A and Variable B at time T-1). At the same time, data based on two assessments are inherently limited on multiple fronts. As (Rogosa, Brandt, and Zimowski 1982) noted approximately forty years ago, “Two waves of data are better than one, but maybe not much better”. These sentiments are reflected in more contemporary recommendations regarding best-practice guidelines for prospective data, which increasingly emphasize the benefits of additional measurement occasions for model identification and accurate parameter estimation. It is also consistent with research recommending that developmental studies include three or more assessment points, given it is impossible for data based on two-time points to determine the shape of development (since linear, straight line change is the only possible form, given two assessments; see (Duncan and Duncan 2009)). Research designs that include three or more time points allow for increasingly nuanced analyses that more adequately tease apart sources of variation and covariation among the repeated assessments (King et al. 2018)– a key aspect of inferential research. To illustrate, developmental theories are typically interested in understanding patterns of within-individual change over time (discussed in further detail, below); however, two data points provide meager information on change at the person level. This point is further underscored in a recent review of statistical models commonly touted as distinguishing within-individual vs between-individual sources of variance in which the study authors concluded “… researchers are limited when attempting to differentiate these sources of variation in psychological phenomenon when using two waves of data” and perhaps more concerning, “…the models discussed here do not offer a feasible way to overcome these inherent limitations” Littlefield et al. (n.d.). It is important to note, however, that despite the current focus on two-wave designs versus three or more assessment waves, garnering three assessment points is not a panacea for longitudinal modeling. Indeed, several contemporary longitudinal models designed to isolate within-individual variability [e.g., the Latent Curve Model with Structured Residuals; Curran et al. (2014)] require at least four assessments to parameterize fully and, more generally, increasingly accurate parameter estimates are obtained as more assessment occasions are used (Duncan and Duncan 2009)."
  },
  {
    "objectID": "manuscript.html#types-of-stability-and-change",
    "href": "manuscript.html#types-of-stability-and-change",
    "title": "",
    "section": "Types of stability and change",
    "text": "Types of stability and change\nIf one were to try to sum up what development in a living organism is exactly, one could plausibly argue it’s the characterization of stability and change as the organism traverses the life course. There are a few different ways to think of stability (and change). Consider we measure the height of all youth in a 6th-grade class, once in the fall at the beginning of the school year and once again in the spring at the end of the school year. A common first step may be to compare the class’s average height values obtained at these two different measurement occasions. This comparison of the average scores for the same group of individuals at multiple time points is referred to as “mean-level” stability as it provides information about continuity and change in the group level of an outcome of interest (e.g., height) over time. Another type of stability involves calculating the correlation between the values obtained at different time points (e.g., ‘height in the fall’ with ‘height in the spring’). This type of “rank-order” stability evaluates between-individual change by focusing on the degree to which individuals retain their relative placement in a group across time. Consider, someone who is the shortest person in their class in 6th grade may grow considerably over the school year (i.e., exhibit mean level change), but remain the shortest person among their classmates. That is, the individual is manifesting a type of rank-order stability. Both types of stability and change are important. Mean-level change in certain traits might help to explain why, in general, individuals are particularly vulnerable to social influences at some ages more than others; rank order change might help to quantify the extent to which certain characteristics of the individual are more trait-like. For example, in some areas of development, there is considerable mean-level change that occurs over time (e.g., changes in Big 5 personality traits), but relatively high rank-order stability. Despite the useful information afforded by examining mean-level and rank-order change, these approaches are limited in that they provide little information about patterns of “within-individual” change and, in turn, can result in fundamental misinterpretations about substantial or meaningful changes in an outcome of interest.\nThere is growing recognition that statistical models commonly applied to longitudinal data often fail to comport with the developmental theory they are being used to assess (e.g., Curran, Lee, Howard, Lane, & MacCallum, 2012; Hoffman, 2015; Littlefield et al., 2021. Specifically, developmental studies typically involve the use of prospective data to inform theories that are concerned with clear within-person (i.e., intraindividual) processes (e.g., how phenotypes change or remain stable within individuals over time) (e.g., see Curran and Bauer 2011). Despite this, methods generally unsuited for disaggregating between- and within-person effects (e.g., cross-lagged panel models [CLPM]) remain common within various extant literatures. As a result, experts increasingly caution about the need to xxxxxxxx [add citation]. Fortunately, there exists a range of models that have been proposed to tease apart between- and within-person sources of variance across time (see Littlefield et al. n.d.; Orth et al. 2021). Most of these contemporary alternatives incorporate time-specific latent variables to capture between-person sources of variance and model within-person deviations around an individual’s mean (or trait) level across time (e.g., RI-CLPM, Hamaker, Kuiper, and Grasman 2015; LCM-SR, Curran et al. 2014). It is important to note however that these models require multiple assessments waves (e.g., four or more to fully specify the LCM-SR), additional expertise to overcome issues with model convergence, and appreciation of modeling assumptions when attempting to adjudicate among potential models in each research context (see Littlefield et al. n.d., for further discussion)."
  },
  {
    "objectID": "manuscript.html#model-assumptions",
    "href": "manuscript.html#model-assumptions",
    "title": "",
    "section": "Model Assumptions",
    "text": "Model Assumptions\nMany statistical models assume certain characteristics about the data to which they are being applied. As an example, common assumptions of parametric statistical models include normality, linearity, and equality of variances. These assumptions must be carefully considered before conducting analysis so that valid inferences can be made from the data; that is, violation of a model’s assumptions can substantively alter the interpretation of results. Similarly, statistical models employed in the analyses of longitudinal data often entail a range of assumptions that must be closely inspected. One central issue for repeated measurements on an individual is how to account for the correlated nature of the data; another common feature of longitudinal data is heterogeneous variability; that is, the variance of the response changes over the duration of the study. Traditional techniques, such as a standard regression or ANOVA model, assume residuals are independent and thus are inappropriate for designs that assess (for example) the same individuals across time. That is, given the residuals are no longer independent, the standard errors from the models are biased and can produce misleading inferential results. Although there are formal tests of independence for time series data (e.g., the Durbin-Watson statistic; Durbin & Watson, 1950), more commonly independence is assumed to be violated in study designs with repeated assessments. Therefore, an initial question to be addressed by a researcher analyzing prospective data is how to best model the covariance structure of said data."
  },
  {
    "objectID": "manuscript.html#covariance-structures",
    "href": "manuscript.html#covariance-structures",
    "title": "",
    "section": "Covariance Structures",
    "text": "Covariance Structures\nStatistical models for longitudinal data include two main components to account for assumptions that are commonly violated when working with repeated measures data: a model for the covariance among repeated measures (both the correlations among pairs of repeated measures on an individual and the variability of the responses on different occasions), coupled with a model for the mean response and its dependence on covariates (eg, treatment group in the context of clinical trials). This allows for the specification of a range of so-called covariance structures, each with its own set of tradeoffs between model fit and parsimony (e.g., see Kincaid 2005)."
  },
  {
    "objectID": "manuscript.html#accounting-for-correlated-data",
    "href": "manuscript.html#accounting-for-correlated-data",
    "title": "",
    "section": "Accounting for Correlated Data",
    "text": "Accounting for Correlated Data\nAs an example, one alternative structure that attempts to handle the reality that correlations between repeated assessments tend to diminish across time is the autoregressive design. As the name implies, the structure assumes a subsequent measurement occasion (e.g., assessment at Wave 2) is regressed onto (that is, is predicted by) a prior measurement occasion (e.g., assessment at Wave 1). The most common type of autoregressive design is the AR(1), where assessments at time T + 1 are regressed on assessments at Time T. Identical to compound symmetry, this model assumes the variances are homogenous across time. Diverting from compound symmetry, this model assumes the correlations between repeated assessments decline exponentially across time rather than remaining constant. For example, per the AR(1) structure, if the correlation between Time 1 and Time 2 data is thought to be .5, then the correlation between Time 1 and Time 3 data would be assumed to be .5.5 = .25, and the correlation between Time 1 and Time 4 data would be assumed to be .5.5*.5 = .125. As with compound symmetry, the basic AR(1) model is parsimonious in that it only requires two parameters (the variance of the assessments and the autoregressive coefficient). Notably, the assumption of constant autoregressive relations between assessments is often relaxed in commonly employed designs that use autoregressive modeling (e.g., cross-lagged panel models [CLPM]). These designs still typically assume an AR(1) process (e.g., it is sufficient to regress the Time 3 assessment onto the Time 2 assessment and is not necessary to also regress the Time 3 assessment onto the Time 1 assessment, which would result in an AR(2) process). However, the magnitude of these relations is often allowed to differ across different AR(1) pairs of assessment (e.g., the relation between Time 1 and Time 2 can be different from the relation between Time 2 and Time 3). These more commonly employed models also often relax the assumption of equal variances of the repeated assessments. Although the AR(1) structure may involve a more realistic set of assumptions compared to compound symmetry, in that the AR(1) model allows for diminishing correlations across time, the basic AR(1) model, as well as autoregressive models more generally, can also suffer from several limitations in contexts that are common in prospective designs. In particular, recent work demonstrates that if a construct being assessed prospectively across time is trait-like in nature, then autoregressive relations fail to adequately account for this trait-like structure, with the downstream consequence that estimates derived from models based on AR structures (such as the CLPM) can be misleading and fail to adequately demarcate between- vs. within-person sources of variance (Hamaker, Kuiper, and Grasman 2015)."
  },
  {
    "objectID": "manuscript.html#linear-vs-non-linear-models",
    "href": "manuscript.html#linear-vs-non-linear-models",
    "title": "",
    "section": "Linear vs non-linear models",
    "text": "Linear vs non-linear models\nIdentification of optimal statistical models and appropriate mathematical functions requires an understanding of the type of data being used. Repeated assessments can be based on either continuous or discrete measures. Examples of discrete measures include repeated assessments of binary variables (e.g., past 12-month alcohol use disorder status measured across ten years), ordinal variables (e.g., a single item measuring the level of agreement to a statement on a three-point scale including the categories of “disagree”, “neutral”, and “agree” in an ecological momentary assessment study that involves multiple daily assessments), and count variables (e.g., number of cigarettes smoked per day across a daily diary study). In many ways, the distributional assumptions of indicators used in longitudinal designs mirror the decision points and considerations when delineating across different types of discrete outcome variables, a topic that spans entire textbooks (e.g., see Lenz 2016). For example, the Mplus manual (Muthén 2017) includes examples of a) censored and censored-inflated models, b) linear growth models for binary or ordinal variables, c) linear growth models for a count outcome assuming a Poisson model, d) linear growth models for a count outcome assuming a zero-inflated Poisson model and e) discrete- and continuous-time survival analysis for a binary outcome. Beyond these highlighted examples, other distributions (e.g., negative binomial) can be assumed for the indicators when modeling longitudinal data. These models can account for issues that can occur when working with discrete outcomes, including overdispersion (when the variance is higher than would be expected based on a given distribution) and zero-inflation [when more zeros occur than is expected based on a given distribution; see Lenz (2016)]. Models involving zero-inflation parameters are referred to as two-part models, given one part of the model predicts the zero-inflation whereas the other part of the model predicts outcomes consistent with a given distribution [e.g., Poisson distribution; see Farewell et al. (2017), for a review of two-part models for longitudinal data]. Although there exist several alternative models for discrete indicators, some more recent models that have been proposed for prospective data are only feasible in cases where indicators are assumed to be continuous rather than discrete [e.g., LCM-SR; Curran et al. (2014)]. Given the sheer breadth of issues relevant to determining better models for discrete outcomes, it is not uncommon for texts on longitudinal data analysis to only cover models and approaches that assume continuous indicators (e.g., Little 2013). However, some textbooks on categorical data analysis provide more detailed coverage of the myriad issues and modeling choices to consider when working with discrete outcomes [e.g., Lenz (2016), Chapter 11 for matched pair/two-assessment designs; Chapter 12 for marginal and transitional models for repeated designs, such as generalized estimating equations, and Chapter 13 for random effects models for discrete outcomes]."
  },
  {
    "objectID": "manuscript.html#missing-dataattrition",
    "href": "manuscript.html#missing-dataattrition",
    "title": "",
    "section": "Missing Data/Attrition",
    "text": "Missing Data/Attrition\nAs recently reviewed by Littlefield (in press), investigators of prospective data are confronted with study attrition (i.e., participants may not provide data at a given wave of assessment) and thus approaches are needed to confront the issue of missing data. Three models of missingness are typically considered in the literature (see LITTLE and RUBIN 1989). These three models are data: a) missing completely at random (MCAR), b) missing at random (MAR), and c) missing not at random (MNAR). Data that are MCAR means missing data is a random sample of all the types of participants (e.g., males) in a given dataset. MAR suggests conditionally missing at random (see Graham 2009). That is, MAR implies missingness is completely random (i.e., does not hinge on some unmeasured variables) once missingness has been adjusted by all available variables in a dataset (e.g., biological sex). Data that are MNAR are missing as a function of unobserved variables. Graham (2009) provides an excellent and easy-to-digest overview of further details involving missing data considerations.\nMultiple approaches have been posited to handle missing data. Before the advent of more contemporary approaches, common methods included several ad hoc procedures. These include eliminating the data of participants with missing data (e.g., listwise or pairwise deletion) or using mean imputation (i.e., replacing the missing value with the mean score of the sample that did participate). However, these methods are not recommended because they can contribute to biased parameter estimates and research conclusions (see Graham 2009). More specifically, the last observation carried forward (LOCF) is a common approach to imputing missing data. LOCF replaces a participant’s missing values after dropout with the last available measurement (Molnar, Hutton, and Fergusson 2008). This approach assumes stability (i.e., a given participant’s score is not anticipated to increase or decline after study dropout) and that the data are MCA R. However, as described by Molnar, Hutton, and Fergusson (2008), it is common for treatment groups to show higher attrition compared to control groups in studies of dementia drugs. Given that dementia worsens over time, using LOCF biases the results in favor of the treatment group (see Molnar, Hutton, and Fergusson 2008, for more details).\nMore modern approaches, such as using maximum likelihood or multiple imputation to estimate missing data, are thought to avoid some of the biases of older approaches (see Enders 2010; Graham 2009). Graham (2009) noted several “myths” regarding missing data. For example, Graham notes many assume the data must be minimally MAR to permit estimating procedures (such as maximum likelihood or multiple imputation) compared to other, more traditional approaches (e.g., using only complete case data). Violations of MAR impact both traditional and more modern data estimation procedures, though as noted by Graham, violations of MAR tend to have a greater effect on older methods. Graham thus suggests that estimating missing data is a better approach compared to the older procedures in most circumstances, regardless of the model of missingness [i.e., MCAR, MAR, MNAR; see Graham (2009)].\nAttrition from a longitudinal panel study such as ABCD is inevitable and represents a threat to the validity of longitudinal analyses and cross-sectional analyses conducted at later time points, especially since attrition can only be expected to grow over time. While, to date, attrition in ABCD has been minimal (some cite here), it remains an important focus for longitudinal analysis and its significance is likely to only grow as the cohort ages. Ideally, one tries to minimize attrition through good retention practices from the outset via strategies designed to maintain engagement in the project (Cotter et al. 2005; Hill et al. 2016; Watson et al. 2018). However, even the best-executed studies need to anticipate growing attrition over the length of the study and implement analytic strategies designed to provide the most valid inferences. Perhaps the most key concern when dealing with data that is missing due to attrition is determining the degree of bias in retained variables that is a consequence of attrition. Assuming that the data are not missing completely at random, attention to the nature of the missingness and employing techniques designed to mitigate attrition-related biases need to be considered in all longitudinal analyses. Several different approaches can be considered and employed depending upon the nature of the intended analyses, the degree of missingness, and data available to help estimate missing and unobserved values."
  },
  {
    "objectID": "manuscript.html#quantifying-effect-sizes-longitudinally",
    "href": "manuscript.html#quantifying-effect-sizes-longitudinally",
    "title": "",
    "section": "Quantifying effect sizes longitudinally",
    "text": "Quantifying effect sizes longitudinally\nGiven longitudinal data involve different sources of variance, quantifying effect sizes longitudinally is a more difficult task compared to deriving such estimates from cross-sectional data. Effect size can be defined as, “a population parameter (estimated in a sample) encapsulating the practical or clinical importance of a phenomenon under study.” (Kraemer 2014). Common effect size metrics include r (i.e., the standardized covariance, or correlation, between two variables) and Cohen’s d (Cohen 1988). Adjustments to common effect size calculations, such as Cohen’s d, are required even when only two time points are considered (e.g., see Morris and DeShon 2002). Wang et al. (2019) note there are multiple approaches to obtaining standardized within-person effects, and that commonly suggested approaches (e.g., global standardization) can be problematic (see Wang et al. 2019, for more details). Thus, obtaining effect size metrics based on standardized estimates that are relatively simple in cross-sectional data (such as r) becomes more complex in the context of prospective data. Feingold (2009) noted that equations for effects sizes used in studies involving growth modeling analysis (e.g., latent growth curve modeling) were not mathematically equivalent, and the effect sizes were not in the same metric as effect sizes from traditional analysis (see Feingold 2009, for more details). Given this issue, there have been various proposals for adjusting effect size measures in repeated assessments. Feingold (2019) reviews the approach for effect size metrics for analyses based on growth modeling, including when considering linear and non-linear (i.e., quadratic) growth factors. Morris and DeShon (2002) review various equations for effect size calculations relevant to when combining estimates in meta-analysis with repeated measures and independent-groups designs. Other approaches to quantifying effect sizes longitudinally may be based on standardized estimates from models that more optimally disentangle between- and within-person sources of variance (as reviewed above). As an example, within a RI-CLPM framework, standardized estimates between random intercepts (i.e., the correlation between two random intercepts for two different constructs assessed repeatedly) could be used to index the between-person relation, whereas standardized estimates among the structured residuals could be used as informing the effect sizes of within-person relations.\n\n\nReferences\n\n\nBagot, K. S., S. A. Matthews, M. Mason, Lindsay M. Squeglia, J. Fowler, K. Gray, M. Herting, A. May, Ian Colrain, and J. Godino. 2018. “Current, Future and Potential Use of Mobile and Wearable Technologies and Social Media Data in the ABCD Study to Increase Understanding of Contributors to Child Health.” Developmental Cognitive Neuroscience 32: 121–29.\n\n\nBarch, Deanna M., Matthew D. Albaugh, Shelli Avenevoli, Linda Chang, Duncan B. Clark, Meyer D. Glantz, James J. Hudziak, Terry L. Jernigan, Susan F. Tapert, and Debbie Yurgelun-Todd. 2018. “Demographic, Physical and Mental Health Assessments in the Adolescent Brain and Cognitive Development Study: Rationale and Description.” Developmental Cognitive Neuroscience 32: 55–66.\n\n\nBeck, Aaron T., Calvin H. Ward, Mock Mendelson, Jeremiah Mock, and John Erbaugh. 1961. “An Inventory for Measuring Depression.” Archives of General Psychiatry 4 (6): 561–71.\n\n\nCasey, B. J., Tariq Cannonier, May I. Conley, Alexandra O. Cohen, Deanna M. Barch, Mary M. Heitzeg, Mary E. Soules, et al. 2018. “The Adolescent Brain Cognitive Development (ABCD) Study: Imaging Acquisition Across 21 Sites.” Developmental Cognitive Neuroscience, The Adolescent Brain Cognitive Development (ABCD) Consortium: Rationale, Aims, and Assessment Strategy, 32 (August): 43–54. https://doi.org/10.1016/j.dcn.2018.03.001.\n\n\nCohen, Jacob. 1988. “Statistical Power.” Analysis for the Behavioral Sciences, 273–406.\n\n\nCotter, Robert B., Jeffrey D. Burke, Magda Stouthamer-Loeber, and Rolf Loeber. 2005. “Contacting Participants for Follow-up: How Much Effort Is Required to Retain Participants in Longitudinal Studies?” Evaluation and Program Planning 28 (1): 15–21.\n\n\nCurran, Patrick J., and Daniel J. Bauer. 2011. “The Disaggregation of Within-Person and Between-Person Effects in Longitudinal Models of Change.” Annual Review of Psychology 62: 583–619.\n\n\nCurran, Patrick J., Andrea L. Howard, Sierra Bainter, Stephanie T. Lane, and James S. McGinley. 2014. “The Separation of Between-Person and Within-Person Components of Individual Change Over Time: A Latent Curve Model with Structured Residuals.” J Consult Clin Psychol 82 (5): 879–94. https://doi.org/10.1037/a0035297.\n\n\nDuncan, Terry E., and Susan C. Duncan. 2009. “The ABC’s of LGM: An Introductory Guide to Latent Variable Growth Curve Modeling.” Social and Personality Psychology Compass 3 (6): 979–91. https://doi.org/10.1111/j.1751-9004.2009.00224.x.\n\n\nEnders, Craig K. 2010. Applied Missing Data Analysis. Guilford Press.\n\n\nFarewell, V. T., D. L. Long, B. D. M. Tom, S. Yiu, and L. Su. 2017. “Two-Part and Related Regression Models for Longitudinal Data.” Annual Review of Statistics and Its Application 4 (1): 283–315. https://doi.org/10.1146/annurev-statistics-060116-054131.\n\n\nFeingold, Alan. 2009. “Effect Sizes for Growth-Modeling Analysis for Controlled Clinical Trials in the Same Metric as for Classical Analysis.” Psychological Methods 14 (1): 43.\n\n\n———. 2019. “Time-Varying Effect Sizes for Quadratic Growth Models in Multilevel and Latent Growth Modeling.” Structural Equation Modeling: A Multidisciplinary Journal 26 (3): 418–29.\n\n\nFrench, David P., and Stephen Sutton. 2010. “Reactivity of Measurement in Health Psychology: How Much of a Problem Is It? What Can Be Done about It?” British Journal of Health Psychology 15 (3): 453–68.\n\n\nGraham, John W. 2009. “Missing Data Analysis: Making It Work in the Real World.” Annual Review of Psychology 60 (1): 549–76. https://doi.org/10.1146/annurev.psych.58.110405.085530.\n\n\nHagler, Donald J., SeanN. Hatton, M. Daniela Cornejo, Carolina Makowski, Damien A. Fair, Anthony Steven Dick, Matthew T. Sutherland, et al. 2019. “Image Processing and Analysis Methods for the Adolescent Brain Cognitive Development Study.” NeuroImage 202 (November): 116091. https://doi.org/10.1016/j.neuroimage.2019.116091.\n\n\nHamaker, Ellen L., Rebecca M. Kuiper, and Raoul P. P. P. Grasman. 2015. “A Critique of the Cross-Lagged Panel Model.” Psychological Methods 20 (1): 102–16. https://doi.org/10.1037/a0038889.\n\n\nHill, Karl G., Danielle Woodward, Tiffany Woelfel, J. David Hawkins, and Sara Green. 2016. “Planning for Long-Term Follow-up: Strategies Learned from Longitudinal Studies.” Prevention Science 17 (7): 806–18.\n\n\nKincaid, C. 2005. “Guidelines for Selecting the Covariance Structure in Mixed Model Analysis, Paper 198-30 in Proceedings of the Thirtieth Annual SAS Users Group Conference.” Inc., Cary, North Carolina.\n\n\nKing, Kevin M., Andrew K. Littlefield, Connor J. McCabe, Kathryn L. Mills, John Flournoy, and Laurie Chassin. 2018. “Longitudinal Modeling in Developmental Neuroimaging Research: Common Challenges, and Solutions from Developmental Psychology.” Developmental Cognitive Neuroscience, Methodological Challenges in Developmental Neuroimaging: Contemporary Approaches and Solutions, 33 (October): 54–72. https://doi.org/10.1016/j.dcn.2017.11.009.\n\n\nKraemer, Helena Chmura. 2014. “Effect Size.” The Encyclopedia of Clinical Psychology, 1–3.\n\n\nLenz, Sylvia Tamara. 2016. “Alan Agresti (2013): Categorical Data Analysis.” Statistical Papers 57 (3): 849.\n\n\nLITTLE, RODERICK J. A., and DONALD B. RUBIN. 1989. “The Analysis of Social Science Data with Missing Values.” Sociological Methods & Research 18 (2-3): 292–326. https://doi.org/10.1177/0049124189018002004.\n\n\nLittle, Todd D. 2013. The Oxford Handbook of Quantitative Methods, Vol. 2: Statistical Analysis. Oxford University Press.\n\n\nLittlefield, Andrew K., Kevin M. King, Samuel F. Acuff, Katherine T. Foster, James G. Murphy, and Katie Witkiewitz. n.d. “Limitations of Cross-Lagged Panel Models in Addiction Research and Alternative Models: An Empirical Example Using Project MATCH.” Psychology of Addictive Behaviors. Accessed October 31, 2021. https://doi.org/10.1037/adb0000750.\n\n\nLoughnan, Robert J., Clare E. Palmer, Wesley K. Thompson, Anders M. Dale, Terry L. Jernigan, and Chun Chieh Fan. 2020. “Polygenic Score of Intelligence Is More Predictive of Crystallized Than Fluid Performance Among Children.” bioRxiv, 637512.\n\n\nLuciana, M., J. M. Bjork, B. J. Nagel, D. M. Barch, R. Gonzalez, S. J. Nixon, and M. T. Banich. 2018. “Adolescent Neurocognitive Development and Impacts of Substance Use: Overview of the Adolescent Brain Cognitive Development (ABCD) Baseline Neurocognition Battery.” Developmental Cognitive Neuroscience 32: 67–79.\n\n\nMolnar, Frank J., Brian Hutton, and Dean Fergusson. 2008. “Does Analysis Using ‘Last Observation Carried Forward’ Introduce Bias in Dementia Research?” Cmaj 179 (8): 751–53.\n\n\nMorris, Scott B., and Richard P. DeShon. 2002. “Combining Effect Size Estimates in Meta-Analysis with Repeated Measures and Independent-Groups Designs.” Psychological Methods 7 (1): 105.\n\n\nMuthén, L. K. 2017. “Mplus User’s Guide. Los Angeles: Muthén & Muthén; 1998.”\n\n\nOrth, Ulrich, D. Angus Clark, M. Brent Donnellan, and Richard W. Robins. 2021. “Testing Prospective Effects in Longitudinal Research: Comparing Seven Competing Cross-Lagged Models.” Journal of Personality and Social Psychology 120 (4): 1013.\n\n\nRobins, Lee. 1985. “Epidemiology: Reflections on Testing the Validity of Psychiatric Interviews  JAMA Psychiatry  JAMA Network.” https://jamanetwork.com/journals/jamapsychiatry/article-abstract/493658.\n\n\nRogosa, David, David Brandt, and Michele Zimowski. 1982. “A Growth Curve Approach to the Measurement of Change.” Psychological Bulletin 92 (3): 726.\n\n\nSalthouse, Timothy A. 2014. “Why Are There Different Age Relations in Cross-Sectional and Longitudinal Comparisons of Cognitive Functioning?” Current Directions in Psychological Science 23 (4): 252–56.\n\n\nShrout, Patrick E., Gertraud Stadler, Sean P. Lane, M. Joy McClure, Grace L. Jackson, Frederick D. Clavél, Masumi Iida, Marci E. J. Gleason, Joy H. Xu, and Niall Bolger. 2018. “Initial Elevation Bias in Subjective Reports.” PNAS 115 (1): E15–23. https://doi.org/10.1073/pnas.1712277115.\n\n\nSullivan, Edith V., Ty Brumback, Susan F. Tapert, Devin Prouty, Rosemary Fama, Wesley K. Thompson, Sandra A. Brown, Kevin Cummins, Ian M. Colrain, and Fiona C. Baker. 2017. “Effects of Prior Testing Lasting a Full Year in NCANDA Adolescents: Contributions from Age, Sex, Socioeconomic Status, Ethnicity, Site, Family History of Alcohol or Drug Abuse, and Baseline Performance.” Developmental Cognitive Neuroscience 24: 72–83.\n\n\nThompson, Wesley K., Deanna M. Barch, James M. Bjork, Raul Gonzalez, Bonnie J. Nagel, Sara Jo Nixon, and Monica Luciana. 2019. “The Structure of Cognition in 9 and 10 Year-Old Children and Associations with Problem Behaviors: Findings from the ABCD Study’s Baseline Neurocognitive Battery.” Developmental Cognitive Neuroscience 36: 100606.\n\n\nUban, Kristina A., Megan K. Horton, Joanna Jacobus, Charles Heyser, Wesley K. Thompson, Susan F. Tapert, Pamela A. F. Madden, and Elizabeth R. Sowell. 2018. “Biospecimens and the ABCD Study: Rationale, Methods of Collection, Measurement and Early Data.” Developmental Cognitive Neuroscience, The Adolescent Brain Cognitive Development (ABCD) Consortium: Rationale, Aims, and Assessment Strategy, 32 (August): 97–106. https://doi.org/10.1016/j.dcn.2018.03.005.\n\n\nVolkow, Nora D., George F. Koob, Robert T. Croyle, Diana W. Bianchi, Joshua A. Gordon, Walter J. Koroshetz, Eliseo J. Pérez-Stable, et al. 2018. “The Conception of the ABCD Study: From Substance Use to a Broad NIH Collaboration.” Developmental Cognitive Neuroscience, The Adolescent Brain Cognitive Development (ABCD) Consortium: Rationale, Aims, and Assessment Strategy, 32 (August): 4–7. https://doi.org/10.1016/j.dcn.2017.10.002.\n\n\nWang, Lijuan, Qian Zhang, Scott E. Maxwell, and C. S. Bergeman. 2019. “On Standardizing Within-Person Effects: Potential Problems of Global Standardization.” Multivariate Behavioral Research 54 (3): 382–403.\n\n\nWatson, Nicole, Eva Leissou, Heidi Guyer, and Mark Wooden. 2018. “Best Practices for Panel Maintenance and Retention.” In Advances in Comparative Survey Methods, 597–622. John Wiley & Sons, Ltd. https://doi.org/10.1002/9781118884997.ch29.\n\n\nZucker, Robert A., Raul Gonzalez, Sarah W. Feldstein Ewing, Martin P. Paulus, Judith Arroyo, Andrew Fuligni, Amanda Sheffield Morris, Mariana Sanchez, and Thomas Wills. 2018. “Assessment of Culture and Environment in the Adolescent Brain and Cognitive Development Study: Rationale, Description of Measures, and Early Data.” Developmental Cognitive Neuroscience 32: 107–20."
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html",
    "href": "1_Tutorials_DifferenceScores.html",
    "title": "Difference Scores",
    "section": "",
    "text": "Difference scores are one of the earliest developed and commonly used statistical approaches to compare data collected from the same individual across two measurement occasions (Castro-Schilo and Grimm 2018; Jennings and Cribbie 2016). The difference between scores at the two time points is calculated for each individual and the resulting value is taken as a measure of change. It is common to then perform statistical tests on the difference scores, such as being included as an outcome in a GLM analysis to test for differences in patterns of change over time and between groups. For example, difference scores may be used in a paired-samples t-test to compare mean test scores of students before and after attending a math workshop, or in a simple regression analysis to assess the effectiveness of a weight loss program by calculating the difference in weight between between groups of interest, before and after the program.\n\n\n\nDifference Score 1_Tutorial\n\n\n\n\nYou should use difference scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will guide you through two simple examples of using difference scores. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of difference scores.\nCalculate difference scores using example data.\nInterpret the results of the difference scores analysis."
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html#overview",
    "href": "1_Tutorials_DifferenceScores.html#overview",
    "title": "Difference Scores",
    "section": "",
    "text": "Difference scores are one of the earliest developed and commonly used statistical approaches to compare data collected from the same individual across two measurement occasions (Castro-Schilo and Grimm 2018; Jennings and Cribbie 2016). The difference between scores at the two time points is calculated for each individual and the resulting value is taken as a measure of change. It is common to then perform statistical tests on the difference scores, such as being included as an outcome in a GLM analysis to test for differences in patterns of change over time and between groups. For example, difference scores may be used in a paired-samples t-test to compare mean test scores of students before and after attending a math workshop, or in a simple regression analysis to assess the effectiveness of a weight loss program by calculating the difference in weight between between groups of interest, before and after the program.\n\n\n\nDifference Score 1_Tutorial\n\n\n\n\nYou should use difference scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will guide you through two simple examples of using difference scores. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of difference scores.\nCalculate difference scores using example data.\nInterpret the results of the difference scores analysis."
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html#basic-example",
    "href": "1_Tutorials_DifferenceScores.html#basic-example",
    "title": "Difference Scores",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nTime point (T1, T2)\nJob satisfaction (independent variable)\nLife satisfaction (dependent variable)\n\n\n\n\nIndividual\nTime Point\nJob Satisfaction\nLife Satisfaction\n\n\n\n\nA\nT1\n7\n6\n\n\nA\nT2\n8\n7\n\n\nB\nT1\n6\n5\n\n\nB\nT2\n7\n6\n\n\n\nWe will then create a new variable, age_diff, that represents the difference in age between two time points:\n\n\nCode\n#titanic$age_diff &lt;- titanic$age - titanic$age[1]\n\n\n\nRepeated Measures Paired Samples T-test\nTo conduct a repeated measures paired samples t-test on age_diff, we will use the t.test() function in R:\n\n\nCode\n#t.test(titanic$age_diff, mu = 0, paired = TRUE)\\\n\n\nThe mu argument represents the hypothesized mean difference, which we have set to 0. The paired argument tells R that the samples are paired.\n\n\nInterpreting the Results\nThe output of the t.test() function includes several statistics, including the t-value, degrees of freedom, and p-value. The t-value represents the difference between the mean of age_diff and the hypothesized mean difference, divided by the standard error. The degrees of freedom represents the number of observations minus one. The p-value represents the probability of observing a t-value as extreme or more extreme than the one observed, assuming that the null hypothesis is true.\nIf the p-value is less than our chosen significance level (typically 0.05), we can reject the null hypothesis and conclude that there is a significant difference between the means of age_diff and the hypothesized mean difference. If the p-value is greater than our chosen significance level, we fail to reject the null hypothesis and conclude that there is insufficient evidence to suggest a difference between the means.\n\n\nConclusion\nIn this tutorial, we learned how to conduct a repeated measures paired samples t-test on a difference score using R. This statistical method is useful when we want to compare the means of two related variables that are measured at two different time points or under two different conditions. We also learned how to interpret the results of the t-test, including the t-value, degrees of freedom, and p-value.\n\n\nPaired Samples T-test Model Specification and Estimation\nTo calculate [xxxxx] scores, we will follow these steps:\n[two timepoints, t1 and t2, and we want to test whether there is a significant difference between the means of two variables measured at each timepoint. We can use a paired samples t-test to do this.]\nA paired samples t-test is used to determine whether there is a significant difference between two related variables. For example, you may be interested in whether there is a significant difference in anxiety levels between participants before and after an intervention. To conduct a paired samples t-test in R, we can use the t.test() function.\nLet’s use a hypothetical example to illustrate how to conduct a paired samples t-test in R. In this example, we have data from 30 participants who completed a pre-test and post-test on anxiety levels measured on a 10-point scale. We want to determine if there was a significant difference in anxiety levels before and after an intervention.\n\n\nCode\n# Generate example data\npre_test &lt;- rnorm(30, mean = 6, sd = 1)\npost_test &lt;- rnorm(30, mean = 4, sd = 1)\n\n\n\n\nCode\n# Conduct paired samples t-test\nt.test(pre_test, post_test, paired = TRUE)\n\n\n\n    Paired t-test\n\ndata:  pre_test and post_test\nt = 7.6083, df = 29, p-value = 2.18e-08\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.522869 2.642611\nsample estimates:\nmean difference \n        2.08274 \n\n\nThe t.test() function returns the t-value, degrees of freedom, and p-value for the paired samples t-test. In this example, the p-value is less than 0.05, indicating that there is a significant difference in anxiety levels before and after the intervention.\n\n\nSimple Regression on a Difference Score\nA simple regression on a difference score is used to determine the relationship between the difference scores of two related variables and a third variable. For example, you may be interested in whether there is a relationship between the difference in anxiety levels before and after an intervention and a participant’s age. To conduct a simple regression on a difference score in R, we can use the lm() function.\nLet’s continue with the hypothetical example from the paired samples t-test. We want to determine if there is a relationship between the difference in anxiety levels before and after the intervention and the participants’ age. We will create a new variable diff_score to represent the difference in anxiety levels.\n\n\nCode\n# Calculate difference score\ndiff_score &lt;- post_test - pre_test\n\n# Generate example age data\nage &lt;- rnorm(30, mean = 35, sd = 5)\n\n# Conduct simple regression on difference score and age\nmodel &lt;- lm(diff_score ~ age)\nsummary(model)\n\n\n\nCall:\nlm(formula = diff_score ~ age)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5068 -0.9876  0.3755  1.0985  2.7064 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -4.08802    2.29748  -1.779    0.086 .\nage          0.05783    0.06578   0.879    0.387  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.505 on 28 degrees of freedom\nMultiple R-squared:  0.02686,   Adjusted R-squared:  -0.007894 \nF-statistic: 0.7729 on 1 and 28 DF,  p-value: 0.3868\n\n\nThe lm() function returns the intercept, slope, and p-value for the simple regression on the difference score. In this example, the p-value is greater than 0.05, indicating that there is no significant relationship between the difference in anxiety levels and age.\n\nInterpreting the Results\nFor the paired samples t-test, the output from the t.test() function provides the t-value, degrees of freedom, and p-value. The t-value represents the size of the difference between the means of the two related variables relative to the variation within the data. The degrees of freedom represent the number of observations minus the number of variables being compared. The p-value represents the probability of obtaining a result as extreme as the one observed, assuming that the null hypothesis is true.\nFor the simple regression on the difference score, the output from the lm() function provides the intercept, slope,"
  },
  {
    "objectID": "fundamentals.html",
    "href": "fundamentals.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html",
    "href": "3_Tutorials_LinearMixedModels.html",
    "title": "Linear Mixed Models",
    "section": "",
    "text": "Linear mixed models (LMMs) are a powerful statistical tool that allows the analysis of complex data structures that contain both fixed and random effects (West et al., 2015). LMMs are widely used in various fields, including social sciences, biology, and engineering, due to their ability to handle hierarchical data structures and account for within-subject correlations (Bates et al., 2015). LMMs are an extension of the general linear model (GLM), where both fixed and random effects can be included in the model, making them more flexible and robust (Pinheiro & Bates, 2000). These models are particularly useful when analyzing longitudinal data, where measurements are taken repeatedly over time, and correlations between observations must be accounted for (Singer & Willett, 2003). Specifically, the LMM framework accounts for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. This approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory. It is this “mixture” of fixed and random effects from which these models derive their name.\n[+add primary diagram/figure]\n\n\nYou should use LMMs in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal linear mixed models (LLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal linear mixed models.\nFit a longitudinal linear mixed model using example data in R.\nInterpret the results of the LLMM analysis."
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html#overview",
    "href": "3_Tutorials_LinearMixedModels.html#overview",
    "title": "Linear Mixed Models",
    "section": "",
    "text": "Linear mixed models (LMMs) are a powerful statistical tool that allows the analysis of complex data structures that contain both fixed and random effects (West et al., 2015). LMMs are widely used in various fields, including social sciences, biology, and engineering, due to their ability to handle hierarchical data structures and account for within-subject correlations (Bates et al., 2015). LMMs are an extension of the general linear model (GLM), where both fixed and random effects can be included in the model, making them more flexible and robust (Pinheiro & Bates, 2000). These models are particularly useful when analyzing longitudinal data, where measurements are taken repeatedly over time, and correlations between observations must be accounted for (Singer & Willett, 2003). Specifically, the LMM framework accounts for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. This approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory. It is this “mixture” of fixed and random effects from which these models derive their name.\n[+add primary diagram/figure]\n\n\nYou should use LMMs in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal linear mixed models (LLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal linear mixed models.\nFit a longitudinal linear mixed model using example data in R.\nInterpret the results of the LLMM analysis."
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html#basic-example",
    "href": "3_Tutorials_LinearMixedModels.html#basic-example",
    "title": "Linear Mixed Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nOutcome variable (e.g., a measure of cognitive performance)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n100\n\n\n1\n1\n105\n\n\n1\n2\n110\n\n\n2\n0\n95\n\n\n2\n1\n100\n\n\n\n\nModel Specification and Estimation\nWe will use the lme4 package in R to fit a longitudinal linear mixed model. First, install and load the required package:\n\n\nCode\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nlibrary(lme4)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(100, 105, 110, 95, 100)\n)\n\n\nFit the LLMM with a random intercept for each subject and a fixed effect of time:\n\n\nCode\nmodel &lt;- lmer(outcome ~ time + (1 | subject_id), data = data)\n\n\n\n\nInterpreting the Results\nTo interpret the results of the LLMM analysis, we can use the summary() function in R to display the estimated fixed effects and random effects:\n\n\nCode\nsummary(model)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ time + (1 | subject_id)\n   Data: data\n\nREML criterion at convergence: -44.7\n\nScaled residuals: \n       Min         1Q     Median         3Q        Max \n-1.141e-07 -5.704e-08  8.556e-08  1.426e-07  1.996e-07 \n\nRandom effects:\n Groups     Name        Variance  Std.Dev. \n subject_id (Intercept) 4.167e+00 2.041e+00\n Residual               2.483e-13 4.983e-07\nNumber of obs: 5, groups:  subject_id, 2\n\nFixed effects:\n             Estimate Std. Error   t value\n(Intercept) 9.750e+01  1.444e+00 6.751e+01\ntime        5.000e+00  3.151e-07 1.587e+07\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime 0.000 \noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00500608 (tol = 0.002, component 1)\n\n\nThe output will show the estimated fixed effect of time, which represents the average change in the outcome variable over time across subjects. The random effects estimates show the variation in the intercept (initial level) of the outcome variable across subjects. By examining the fixed and random effects, we can gain insights into how the outcome variable changes over time and how this change differs between subjects."
  },
  {
    "objectID": "9_Tutorials_LatentChangeScoresModels.html",
    "href": "9_Tutorials_LatentChangeScoresModels.html",
    "title": "Latent Change Score Models",
    "section": "",
    "text": "xxx In this tutorial, we’ll introduce Latent Change Score Models (LCSM), a powerful technique for analyzing longitudinal data. Latent Change Score Models allow researchers to examine individual differences in change over time, as well as the factors that might influence these changes. We’ll walk through an example using a dataset with three time points and a larger sample size of 250 participants. xxx\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "9_Tutorials_LatentChangeScoresModels.html#overview",
    "href": "9_Tutorials_LatentChangeScoresModels.html#overview",
    "title": "Latent Change Score Models",
    "section": "",
    "text": "xxx In this tutorial, we’ll introduce Latent Change Score Models (LCSM), a powerful technique for analyzing longitudinal data. Latent Change Score Models allow researchers to examine individual differences in change over time, as well as the factors that might influence these changes. We’ll walk through an example using a dataset with three time points and a larger sample size of 250 participants. xxx\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "9_Tutorials_LatentChangeScoresModels.html#basic-example",
    "href": "9_Tutorials_LatentChangeScoresModels.html#basic-example",
    "title": "Latent Change Score Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we’ll use a hypothetical dataset called “data” with the following variables:\nsubject_id: A unique identifier for each participant score_t1: The measurement of a variable of interest at Time 1 score_t2: The measurement of the same variable at Time 2 score_t3: The measurement of the same variable at Time 3 First, let’s load the “lavaan” package and create a larger dataset for this example:\n\n\nCode\nlibrary(lavaan)\n\n# Create a sample dataset with 250 participants\nset.seed(42) # For reproducibility\nsubject_id &lt;- 1:250\nscore_t1 &lt;- rnorm(250, mean = 20, sd = 5)\nscore_t2 &lt;- score_t1 + rnorm(250, mean = 2, sd = 3)\nscore_t3 &lt;- score_t2 + rnorm(250, mean = 3, sd = 4)\ndata &lt;- data.frame(subject_id, score_t1, score_t2, score_t3)\n\n\n\nModel Specification and Estimation\nNow, let’s specify the Latent Change Score Model. In this example, we’ll estimate the mean change in the variable of interest from Time 1 to Time 2 and from Time 2 to Time 3, as well as the variances of the change scores.\n\n::: {.cell hash='9_Tutorials_LatentChangeScoresModels_cache/html/unnamed-chunk-3_4c6ae3706e63906c93faa359ec254305'}\n\n```{.r .cell-code}\n# Define the Latent Change Score Model\nmodel &lt;- '\n  # Latent variables\n    delta12 =~ 1 * score_t2 - 1 * score_t1\n    delta23 =~ 1 * score_t3 - 1 * score_t2\n\n  # Means\n    delta12 ~ mu_delta12\n    delta23 ~ mu_delta23\n\n  # Variances\n    delta12 ~~ var_delta12 * delta12\n    delta23 ~~ var_delta23 * delta23\n`\n:::\n\n\nCode\n# Fit the model\nfit &lt;- sem(model, data = data, missing = \"FIML\")\n\n\n\n\nInterpreting the Results\nWe can now examine the results of our Latent Change Score Model. The main parameters of interest are:\nmu_delta12: The mean change in the variable of interest from Time 1 to Time 2 mu_delta23: The mean change in the variable of interest from Time 2 to Time 3 var_delta12: The variance of the change scores from Time 1 to Time 2, which reflects individual differences in change var_delta23: The variance of the change xxxx"
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html",
    "href": "2_Tutorials_ResidualizedChangeScores.html",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Residualized change scores are a statistical method used to assess the degree of change in a variable while controlling for its initial level. The approach involves calculating the residualized change scores by regressing post-treatment scores on pre-treatment scores and using the resulting residuals as the measure of change. This estimated change score adjusts for baseline scores while ignoring any prior group assignments/differences. The residualized change score is often included in subsequent analysis, such as an examination of intervention effects in pre-test/post-test designs (Kisbu-Sakarya2013?). This method is useful when there is a high correlation between the pre-treatment and post-treatment scores, which can make it difficult to determine the true degree of change. Research studies have shown that this method can provide more accurate and reliable results compared to other methods of measuring change, such as raw change scores or gain scores (Kenny, 1979; Rogosa & Willett, 1985).\nResidualized change scores are a method used to analyze change in a variable over time, while accounting for the initial level of that variable. By using residualized change scores, we can examine the extent to which changes in one variable are associated with changes in another variable, controlling for the initial level of the variables.\n\n\n\nResidualized Change Score 1_Tutorial\n\n\n\n\nYou should use residualized change scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of residualized change scores and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of residualized change scores.\nCalculate residualized change scores using example data.\nInterpret the results of the residualized change scores analysis."
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html#overview",
    "href": "2_Tutorials_ResidualizedChangeScores.html#overview",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Residualized change scores are a statistical method used to assess the degree of change in a variable while controlling for its initial level. The approach involves calculating the residualized change scores by regressing post-treatment scores on pre-treatment scores and using the resulting residuals as the measure of change. This estimated change score adjusts for baseline scores while ignoring any prior group assignments/differences. The residualized change score is often included in subsequent analysis, such as an examination of intervention effects in pre-test/post-test designs (Kisbu-Sakarya2013?). This method is useful when there is a high correlation between the pre-treatment and post-treatment scores, which can make it difficult to determine the true degree of change. Research studies have shown that this method can provide more accurate and reliable results compared to other methods of measuring change, such as raw change scores or gain scores (Kenny, 1979; Rogosa & Willett, 1985).\nResidualized change scores are a method used to analyze change in a variable over time, while accounting for the initial level of that variable. By using residualized change scores, we can examine the extent to which changes in one variable are associated with changes in another variable, controlling for the initial level of the variables.\n\n\n\nResidualized Change Score 1_Tutorial\n\n\n\n\nYou should use residualized change scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of residualized change scores and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of residualized change scores.\nCalculate residualized change scores using example data.\nInterpret the results of the residualized change scores analysis."
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html#basic-example",
    "href": "2_Tutorials_ResidualizedChangeScores.html#basic-example",
    "title": "Residualized Change Scores",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nTime point (T1, T2)\nJob satisfaction (independent variable)\nLife satisfaction (dependent variable)\n\n\n\n\nIndividual\nTime Point\nJob Satisfaction\nLife Satisfaction\n\n\n\n\nA\nT1\n7\n6\n\n\nA\nT2\n8\n7\n\n\nB\nT1\n6\n5\n\n\nB\nT2\n7\n6\n\n\n\n\nModel Specification and Estimation\nTo calculate residualized change scores, we will follow these steps:\n\nCalculate the raw change scores for each variable by subtracting the T1 value from the T2 value.\nFit a regression model with the change score of the dependent variable (life satisfaction) as the outcome and the change score of the independent variable (job satisfaction) and the initial level of the dependent variable (T1 life satisfaction) as predictors.\nExtract the residuals from the regression model. These residuals represent the residualized change scores.\n\nUsing the example dataset, we can calculate the residualized change scores for life satisfaction as follows:\n\nCalculate raw change scores:\n\n\n\nIndividual\nJob Satisfaction Change\nLife Satisfaction Change\n\n\n\n\nA\n1\n1\n\n\nB\n1\n1\n\n\n\nFit the regression model:\nLife Satisfaction Change = b0 + b1 * Job Satisfaction Change + b2 * T1 Life Satisfaction\nExtract residuals:\n\n\n\nIndividual\nResidualized Change Score\n\n\n\n\nA\ne1\n\n\nB\ne2\n\n\n\n\n\n\nInterpreting the Results\nResidualized change scores represent the change in the dependent variable (life satisfaction) after accounting for the initial level of that variable and the change in the independent variable (job satisfaction). By examining the association between the residualized change scores of two variables, we can gain insights into how changes in one variable are related to changes in another variable, controlling for initial levels."
  }
]
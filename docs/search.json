[
  {
    "objectID": "13_Tutorials_GrowthMixtureModels.html",
    "href": "13_Tutorials_GrowthMixtureModels.html",
    "title": "Growth Mixture Models",
    "section": "",
    "text": "Growth Mixture Models (GMMs) are a type of statistical model that aims to identify distinct subgroups or classes within a population based on their growth trajectories. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a Growth Mixture Model using the lcmm package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lcmm package, which provides functions for fitting Growth Mixture Models."
  },
  {
    "objectID": "13_Tutorials_GrowthMixtureModels.html#overview",
    "href": "13_Tutorials_GrowthMixtureModels.html#overview",
    "title": "Growth Mixture Models",
    "section": "",
    "text": "Growth Mixture Models (GMMs) are a type of statistical model that aims to identify distinct subgroups or classes within a population based on their growth trajectories. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a Growth Mixture Model using the lcmm package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lcmm package, which provides functions for fitting Growth Mixture Models."
  },
  {
    "objectID": "13_Tutorials_GrowthMixtureModels.html#basic-example",
    "href": "13_Tutorials_GrowthMixtureModels.html#basic-example",
    "title": "Growth Mixture Models",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Install the lcmm package if not already installed\nif (!(\"lcmm\" %in% installed.packages())) {\n  install.packages(\"lcmm\")\n}\n\n\nLoad the lcmm package\n\n\nCode\nlibrary(lcmm)\n\n\nSimulating the Data For this tutorial, we will use a simulated dataset with three growth trajectory classes, where each class represents a different pattern of change over time. The dataset will consist of 300 individuals with four repeated measurements (time points) for each individual.\n\n\nCode\nset.seed(123)\nn &lt;- 300\ntimepoints &lt;- 4\n\n# Simulate the data for each class\nclass1 &lt;- data.frame(id = 1:(n / 3),\n                     time = rep(1:timepoints, each = n / 3),\n                     class = 1,\n                     value = rnorm(n * timepoints / 3, mean = 1 + 0.5 * (1:timepoints), sd = 0.5))\n\nclass2 &lt;- data.frame(id = (n / 3 + 1):(2 * n / 3),\n                     time = rep(1:timepoints, each = n / 3),\n                     class = 2,\n                     value = rnorm(n * timepoints / 3, mean = 2 - 0.3 * (1:timepoints), sd = 0.5))\n\nclass3 &lt;- data.frame(id = (2 * n / 3 + 1):n,\n                     time = rep(1:timepoints, each = n / 3),\n                     class = 3,\n                     value = rnorm(n * timepoints / 3, mean = 3 + 0.1 * (1:timepoints), sd = 0.5))\n\n\n\n\nCode\n# Combine the data from all classes\ndata &lt;- rbind(class1, class2, class3)\n\n\n\nModel Specification and Estimation\nNow that we have our simulated data, we can fit a Growth Mixture Model. In this example, we will assume that there are three latent classes. However, in practice, the number of classes is usually unknown and must be determined through model comparisons or other methods.\n\n\nCode\n# Fit the Growth Mixture Model\ngmm &lt;- hlme(value ~ time,\n            random = ~ time,\n            subject = \"id\",\n            mixture = ~ time,\n            data = data,\n            ng = 3,\n            B = list(value = c(1, 0, 0, 0)\n\n\n\n\nInterpreting the Results\nxxxxxx"
  },
  {
    "objectID": "8_HowTos_AutoregressiveCrosslaggedPanelModels.html",
    "href": "8_HowTos_AutoregressiveCrosslaggedPanelModels.html",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "",
    "text": "test page for clpm howtos"
  },
  {
    "objectID": "4_HowTos_SignedRankTest.html",
    "href": "4_HowTos_SignedRankTest.html",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "Signed-Rank Test test page"
  },
  {
    "objectID": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html",
    "href": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "",
    "text": "Random-Intercept Cross-Lagged Panel Models (RI-CLPM) are a type of structural equation model used to analyze longitudinal data with repeated measures of multiple variables. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a RI-CLPM using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including RI-CLPMs.\n\n\nCode\n# Install the lavaan package if not already installed\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}\n# Load the lavaan package\nlibrary(lavaan)"
  },
  {
    "objectID": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#overview",
    "href": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#overview",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "",
    "text": "Random-Intercept Cross-Lagged Panel Models (RI-CLPM) are a type of structural equation model used to analyze longitudinal data with repeated measures of multiple variables. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a RI-CLPM using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including RI-CLPMs.\n\n\nCode\n# Install the lavaan package if not already installed\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}\n# Load the lavaan package\nlibrary(lavaan)"
  },
  {
    "objectID": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#basic-example",
    "href": "15_Tutorials_RandomInterceptCrosslaggedPanelModels.html#basic-example",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "Basic Example",
    "text": "Basic Example\nSimulating the Data For this tutorial, we will use a simulated dataset with 500 individuals, each measured at five time points. The dataset will contain two variables, X and Y, with cross-lagged effects.\n\n\nCode\nset.seed(123)\nn &lt;- 500\ntimepoints &lt;- 5\n\n# Simulate the data\ndata &lt;- data.frame(id = rep(1:n, each = timepoints),\n                   time = rep(1:timepoints, times = n),\n                   X = rnorm(n * timepoints, mean = 0, sd = 1),\n                   Y = rnorm(n * timepoints, mean = 0, sd = 1))\n\n# Introduce cross-lagged effects\nfor (i in 2:timepoints) {\n  data$X[data$time == i] &lt;- 0.3 * data$Y[data$time == (i - 1)] + data$X[data$time == i]\n  data$Y[data$time == i] &lt;- 0.2 * data$X[data$time == (i - 1)] + data$Y[data$time == i]\n}\n\n\n\nModel Specification and Estimation\nNow that we have our simulated data, we can fit a Random-Intercept Cross-Lagged Panel Model using the lavaan package.\n\n\nCode\n# Define the model\nmodel &lt;- '\n  # Random intercepts\n  i_X =~ 1 * X_t1 + 1 * X_t2 + 1 * X_t3 + 1 * X_t4 + 1 * X_t5\n  i_Y =~ 1 * Y_t1 + 1 * Y_t2 + 1 * Y_t3 + 1 * Y_t4 + 1 * Y_t5\n\n  # Cross-lagged effects\n  Y_t2 ~ beta_YX * X_t1\n  Y_t3 ~ beta_YX * X_t2\n  Y_t4 ~ beta_YX * X_t3\n  Y_t5 ~ beta_YX * X_t4\n\n  X_t2 ~ beta_XY * Y_t1\n  X_t3 ~ beta_XY *\n\n\n\n\nInterpreting the Results\nxxxxxx"
  },
  {
    "objectID": "15_HowTos_RandomInterceptCrosslaggedPanelModels.html",
    "href": "15_HowTos_RandomInterceptCrosslaggedPanelModels.html",
    "title": "Random-Intercept Crosslagged Panel Models",
    "section": "",
    "text": "test page for ri-clpm howtos"
  },
  {
    "objectID": "blank.html",
    "href": "blank.html",
    "title": "Blank Test Page",
    "section": "",
    "text": "Blank Blank Blank"
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html",
    "href": "5_Tutorials_MarginalModels.html",
    "title": "Marginal Models",
    "section": "",
    "text": "xxxxxxxxx\nCode\ngraph LR\nA(( )) -- Intercept --&gt; B(( ))\nB -- Slope --&gt; C(( ))\nC -- Quadratic --&gt; D(( ))\n\nB -- Y1 --&gt; E[square]\nC -- Y2 --&gt; F[square]\nD -- Y3 --&gt; G[square]\n\n\n\n\ngraph LR\nA(( )) -- Intercept --&gt; B(( ))\nB -- Slope --&gt; C(( ))\nC -- Quadratic --&gt; D(( ))\n\nB -- Y1 --&gt; E[square]\nC -- Y2 --&gt; F[square]\nD -- Y3 --&gt; G[square]\nxxxxxxxx"
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html#overview",
    "href": "5_Tutorials_MarginalModels.html#overview",
    "title": "Marginal Models",
    "section": "Overview",
    "text": "Overview\nMarginal models are a statistical method used to analyze longitudinal or clustered data. The marginal model estimates the average effect of the independent variables on the outcome while accounting for the within-subject correlation, and allows for the estimation of population-averaged effects, in contrast to subject-specific effects estimated by random-effects models (Verbeke & Molenberghs, 2000). The method is similar to the GEE approach but uses a different estimation technique and does not account for subject-specific effects. Marginal models have been shown to be robust to non-normality and non-constant variance, and can handle unbalanced or unequally spaced data (Fitzmaurice et al., 2011). The term marginal in this context is used to emphasize that the model for the mean response at each occasion depends only on the covariates of interest, and not on any random effects or previous responses.\n[+add diagrams/figures]\n\nWhen to use Longitudinal Marginal Models\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\nGetting Started with Longitudinal Marginal Models\nIn this tutorial, we will introduce the concept of longitudinal marginal models and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal marginal models.\nFit a longitudinal marginal model using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "5_Tutorials_MarginalModels.html#basic-example",
    "href": "5_Tutorials_MarginalModels.html#basic-example",
    "title": "Marginal Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\nModel Specification and Estimation\nWe will use the geepack package in R to fit a longitudinal marginal model. First, install and load the required package:\n\n\nCode\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"geepack\")\nlibrary(geepack)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\n\nFit the longitudinal marginal model with a binary outcome using a logit link function:\n\n\nCode\nmodel &lt;- geeglm(outcome ~ time, data = data, id = subject_id, family = binomial(link = \"logit\"), corstr = \"exchangeable\")\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal marginal model, we can use the summary() function in R to display the estimated population-averaged effects:\n\n\nCode\nsummary(model)\n\n\n\nCall:\ngeeglm(formula = outcome ~ time, family = binomial(link = \"logit\"), \n    data = data, id = subject_id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err Wald Pr(&gt;|W|)\n(Intercept)   -43.54     NaN  NaN      NaN\ntime           82.78     NaN  NaN      NaN\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept) 2.22e-16     NaN\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha     -0.5     NaN\nNumber of clusters:   2  Maximum cluster size: 3 \n\n\nThe output will show the estimated effect of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level."
  },
  {
    "objectID": "TailwindTest2.html",
    "href": "TailwindTest2.html",
    "title": "TailwindTest2",
    "section": "",
    "text": "This is github pages test site for the longitudinal analysis project. The information included within the site is for testing purposes only and contents may be inaccurate.\n\n\n\nThis column takes 1/3 of the page\n\n\nThis column takes 2/3 of the page \n\n\nzzzzzzzzz\n\n\n\n\n\nThis is the temporary landing page for the Longitudinal Analysis Project.  The site is currently under construction and used for testing purposes only.  Contents may be inaccurate."
  },
  {
    "objectID": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html",
    "href": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "",
    "text": "xxxx Autoregressive cross-lagged panel models (ACPMs) are a type of statistical model used to analyze longitudinal data and examine the temporal relationships between two or more variables over time. These models help to disentangle within-person effects from between-person effects and can estimate both autoregressive effects (influence of a variable on itself over time) and cross-lagged effects (influence of one variable on another variable over time).\nautoregressive cross-lagged panel models, commonly known as CLPMs. CLPMs are a statistical method used to analyze longitudinal data, particularly when we want to examine the reciprocal relationships between two or more variables over time. In essence, CLPMs allow us to investigate whether one variable at an earlier time point can predict another variable at a later time point, and vice versa.\nCLPMs are useful when we want to go beyond simple correlations between variables at different time points and instead model the dynamic interplay between them. Specifically, CLPMs account for the possibility that the relationship between two variables at one time point may influence their relationship at a subsequent time point. These models can also account for autocorrelation, meaning that the same variable measured over time is correlated with itself.\n\n\n\nAutoregressive Crosslagged Panel 1_Tutorial\n\n\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of autoregressive cross-lagged panel models (ACPMs) and guide you through a simple example using a larger dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of ACPMs.\nFit an ACPM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#overview",
    "href": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#overview",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "",
    "text": "xxxx Autoregressive cross-lagged panel models (ACPMs) are a type of statistical model used to analyze longitudinal data and examine the temporal relationships between two or more variables over time. These models help to disentangle within-person effects from between-person effects and can estimate both autoregressive effects (influence of a variable on itself over time) and cross-lagged effects (influence of one variable on another variable over time).\nautoregressive cross-lagged panel models, commonly known as CLPMs. CLPMs are a statistical method used to analyze longitudinal data, particularly when we want to examine the reciprocal relationships between two or more variables over time. In essence, CLPMs allow us to investigate whether one variable at an earlier time point can predict another variable at a later time point, and vice versa.\nCLPMs are useful when we want to go beyond simple correlations between variables at different time points and instead model the dynamic interplay between them. Specifically, CLPMs account for the possibility that the relationship between two variables at one time point may influence their relationship at a subsequent time point. These models can also account for autocorrelation, meaning that the same variable measured over time is correlated with itself.\n\n\n\nAutoregressive Crosslagged Panel 1_Tutorial\n\n\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of autoregressive cross-lagged panel models (ACPMs) and guide you through a simple example using a larger dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of ACPMs.\nFit an ACPM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#basic-example",
    "href": "8_Tutorials_AutoregressiveCrosslaggedPanelModels.html#basic-example",
    "title": "Autoregressive Crosslagged Panel Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simulated dataset containing the following information for a group of 100 individuals:\n\nSubject ID\nTime (in years)\nVariable 1 (e.g., stress level)\nVariable 2 (e.g., job satisfaction)\n\n\n\nCode\nset.seed(123)  # For reproducibility\nn_subjects &lt;- 100\nn_timepoints &lt;- 3\nsubject_ids &lt;- factor(rep(1:n_subjects, each = n_timepoints))\ntime &lt;- rep(0:(n_timepoints - 1), times = n_subjects)\nvariable1 &lt;- rnorm(n_subjects * n_timepoints, mean = 3, sd = 1)\nvariable2 &lt;- rnorm(n_subjects * n_timepoints, mean = 3, sd = 1)\n\ndata &lt;- data.frame(subject_id = subject_ids, time = time, variable1 = variable1, variable2 = variable2)\n\n\n\nModel Specification and Estimation\nWe will use the lavaan package in R to fit an ACPM. First, install the required package, if not already installed:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nlibrary(lavaan)\n\n\nDefine the ACPM with three timepoints:\n\n\nCode\nmodel &lt;- \n  # Autoregressive paths\n  variable1_t2 ~ a1 * variable1_t1\n  variable1_t1 ~ a2 * variable1_t0\n\n\nvariable1_t1 ~ a2 * variable1_t0\n\n\nCode\n  variable2_t2 ~ a3 * variable2_t1\n\n\nvariable2_t2 ~ a3 * variable2_t1\n\n\nCode\n  variable2_t1 ~ a4 * variable2_t0\n\n\nvariable2_t1 ~ a4 * variable2_t0\n\n\nCode\n  # Cross-lagged paths\n  variable1_t2 ~ b1 * variable2_t1\n\n\nvariable1_t2 ~ b1 * variable2_t1\n\n\nCode\n  variable1_t1 ~ b2 * variable2_t0\n\n\nvariable1_t1 ~ b2 * variable2_t0\n\n\nCode\n  variable2_t2 ~ b3 * variable1_t1\n\n\nvariable2_t2 ~ b3 * variable1_t1\n\n\nCode\n  variable2_t1 ~ b4 * variable1_t0\n\n\nvariable2_t1 ~ b4 * variable1_t0\n\n\nFit the ACPM using the lavaan function:\n\n\nCode\n#fit &lt;- lavaan(model, data = data, missing = )\n\n\n\n\nInterpreting the Results\nxxxxxxxx"
  },
  {
    "objectID": "16_Tutorials_LatentCurveModelsStructuredResiduals.html",
    "href": "16_Tutorials_LatentCurveModelsStructuredResiduals.html",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "",
    "text": "In this tutorial, we will explore Latent Curve Models with Structured Residuals (LCM-SR). LCM-SR allows for the separation of between-person and within-person components of individual change over time. By using structured residuals, we can account for time-varying covariates and interactions between variables at both the within-person and between-person levels.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nYou need to have the lavaan and semTools packages installed in R to perform LCM-SR. Install them using the following commands:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nif (!(\"semTools\" %in% installed.packages())) install.packages(\"semTools\")"
  },
  {
    "objectID": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#overview",
    "href": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#overview",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "",
    "text": "In this tutorial, we will explore Latent Curve Models with Structured Residuals (LCM-SR). LCM-SR allows for the separation of between-person and within-person components of individual change over time. By using structured residuals, we can account for time-varying covariates and interactions between variables at both the within-person and between-person levels.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nYou need to have the lavaan and semTools packages installed in R to perform LCM-SR. Install them using the following commands:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nif (!(\"semTools\" %in% installed.packages())) install.packages(\"semTools\")"
  },
  {
    "objectID": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#basic-example",
    "href": "16_Tutorials_LatentCurveModelsStructuredResiduals.html#basic-example",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use simulated data with 500 individuals and 5 timepoints. The data will include a time-varying covariate, covariate, and an outcome variable, outcome.\n\n\nCode\nset.seed(123)\nlibrary(lavaan)\nlibrary(semTools)\n\n# Simulate data\nn &lt;- 500\ntimepoints &lt;- 5\n\nid &lt;- rep(1:n, each = timepoints)\ntime &lt;- rep(1:timepoints, n)\n\ncovariate &lt;- rnorm(n * timepoints, mean = 0, sd = 1)\noutcome &lt;- rnorm(n * timepoints, mean = 0, sd = 1)\n\ndata &lt;- data.frame(id, time, covariate, outcome)\n\n\n\nModel Specification and Estimation\nTo specify an LCM-SR, we will use the lavaan syntax to define the measurement model and the structural model. We will model the linear growth of the outcome variable while accounting for the effect of the time-varying covariate.\n\n\nCode\nmodel &lt;- '\n  # Latent variables\n  intercept =~ 1 * outcome_t1 + 1 * outcome_t2 + 1 * outcome_t3 + 1 * outcome_t4 + 1 * outcome_t5\n  slope =~ 0 * outcome_t1 + 1 * outcome_t2 + 2 * outcome_t3 + 3 * outcome_t4 + 4 * outcome_t5\n\n  # Time-varying covariate effect on outcome\n  outcome_t1 ~ c1 * covariate_t1\n  outcome_t2 ~ c2 * covariate_t2\n  outcome_t3 ~ c3 * covariate_t3\n  outcome_t4 ~ c4 * covariate_t4\n  outcome_t5 ~ c5 * covariate_t5\n\n  # Residual variances and covariances\n  outcome_t1 ~~ r1 * outcome_t1\n  outcome_t2 ~~ r2 * outcome_t2\n  outcome_t3 ~~ r3 * outcome_t3\n  outcome_t4 ~~ r4 * outcome_t4\n  outcome_t5 ~~ r5 * outcome_t5\n\n  # Latent variable variances\n  intercept ~~ i_var * intercept\n  slope ~~ s_var * slope\n\n  # Latent variable covariances\n  intercept ~~ i_s_cov * slope\n'\n\n\nModel Estimation Now we will estimate the model using the lavaan function sem().\n\n\nCode\n# Reshape data to wide format\nwide_data &lt;- spread(data, key = time, value = outcome, sep\n\n\n\n\nInterpreting the Results\nxxxxx"
  },
  {
    "objectID": "6_HowTos_GeneralizedEstimatingEquations.html",
    "href": "6_HowTos_GeneralizedEstimatingEquations.html",
    "title": "Generalized Estimating Equations",
    "section": "",
    "text": "GEE howtos test page"
  },
  {
    "objectID": "reference.html",
    "href": "reference.html",
    "title": "References: A Brief Overview",
    "section": "",
    "text": "The primary goal of the “Reference” section is on providing accurate, concise, and structured information about specific components, functions, or features of a method, analysis, or framework. Unlike tutorials, how-to guides, and explanations, which aim to teach, solve problems, and provide context, respectively, reference materials serve as a quick lookup resource for users to find the exact information they need. By following these principles, the reference section aims to create a reliable, user-friendly, and easily searchable resource that provides users with the specific information they need to effectively use and understand the method, analysis, or framework.\n\n\nThe reference section should:\n\nBe comprehensive: Reference materials should cover all relevant aspects of the method, analysis, or framework, including components, functions, features, and configurations. The goal is to provide users with a complete and authoritative source of information.\nBe accurate: The information in the reference section should be precise and up-to-date, ensuring that users can rely on it for their projects. This may involve regular updates and checks to maintain accuracy.\nBe concise: Reference materials should be brief and to the point, providing just enough information for users to understand and use the specific analysis or method. This means avoiding unnecessary explanations, examples, or background information.\nFollow a consistent format: The reference section should use a consistent format and structure, making it easy for users to locate and access the information they need. This may involve using templates, standardized headings, or other organizational tools.\nBe easily searchable: Reference materials should be designed with searchability in mind, enabling users to quickly find the information they need. This may involve using clear and descriptive titles, headings, and keywords, as well as implementing search functionality or indexing.\nCross-reference other resources: The reference section should link to other relevant documentation, such as tutorials, how-to guides, or explanations, for users who may require additional information or a deeper understanding of the topic.\n\n\nFor additional information, see [https://documentation.divio.com/]"
  },
  {
    "objectID": "reference.html#what-are-references",
    "href": "reference.html#what-are-references",
    "title": "References: A Brief Overview",
    "section": "",
    "text": "The primary goal of the “Reference” section is on providing accurate, concise, and structured information about specific components, functions, or features of a method, analysis, or framework. Unlike tutorials, how-to guides, and explanations, which aim to teach, solve problems, and provide context, respectively, reference materials serve as a quick lookup resource for users to find the exact information they need. By following these principles, the reference section aims to create a reliable, user-friendly, and easily searchable resource that provides users with the specific information they need to effectively use and understand the method, analysis, or framework.\n\n\nThe reference section should:\n\nBe comprehensive: Reference materials should cover all relevant aspects of the method, analysis, or framework, including components, functions, features, and configurations. The goal is to provide users with a complete and authoritative source of information.\nBe accurate: The information in the reference section should be precise and up-to-date, ensuring that users can rely on it for their projects. This may involve regular updates and checks to maintain accuracy.\nBe concise: Reference materials should be brief and to the point, providing just enough information for users to understand and use the specific analysis or method. This means avoiding unnecessary explanations, examples, or background information.\nFollow a consistent format: The reference section should use a consistent format and structure, making it easy for users to locate and access the information they need. This may involve using templates, standardized headings, or other organizational tools.\nBe easily searchable: Reference materials should be designed with searchability in mind, enabling users to quickly find the information they need. This may involve using clear and descriptive titles, headings, and keywords, as well as implementing search functionality or indexing.\nCross-reference other resources: The reference section should link to other relevant documentation, such as tutorials, how-to guides, or explanations, for users who may require additional information or a deeper understanding of the topic.\n\n\nFor additional information, see [https://documentation.divio.com/]"
  },
  {
    "objectID": "10_Tutorials_LatentGrowthCurveModels.html",
    "href": "10_Tutorials_LatentGrowthCurveModels.html",
    "title": "Latent Growth Curve Models",
    "section": "",
    "text": "In this tutorial, we’ll introduce Latent Growth Curve Models (LGCM), a powerful technique for analyzing longitudinal data. Latent Growth Curve Models allow researchers to examine individual differences in growth trajectories and the factors that might influence these trajectories. We’ll walk through an example using a dataset with three time points and a sample size of 250 participants.\n\n\n\nLatent Growth Curve Model 1_Tutorial\n\n\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "10_Tutorials_LatentGrowthCurveModels.html#overview",
    "href": "10_Tutorials_LatentGrowthCurveModels.html#overview",
    "title": "Latent Growth Curve Models",
    "section": "",
    "text": "In this tutorial, we’ll introduce Latent Growth Curve Models (LGCM), a powerful technique for analyzing longitudinal data. Latent Growth Curve Models allow researchers to examine individual differences in growth trajectories and the factors that might influence these trajectories. We’ll walk through an example using a dataset with three time points and a sample size of 250 participants.\n\n\n\nLatent Growth Curve Model 1_Tutorial\n\n\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "10_Tutorials_LatentGrowthCurveModels.html#basic-example",
    "href": "10_Tutorials_LatentGrowthCurveModels.html#basic-example",
    "title": "Latent Growth Curve Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we’ll use a hypothetical dataset called “data” with the following variables:\nsubject_id: A unique identifier for each participant score_t1: The measurement of a variable of interest at Time 1 score_t2: The measurement of the same variable at Time 2 score_t3: The measurement of the same variable at Time 3 First, let’s load the “lavaan” package and create a dataset for this example:\n\n\nCode\nlibrary(lavaan)\n\n# Create a sample dataset with 250 participants\nset.seed(42) # For reproducibility\nsubject_id &lt;- 1:250\nscore_t1 &lt;- rnorm(250, mean = 20, sd = 5)\nscore_t2 &lt;- score_t1 + rnorm(250, mean = 2, sd = 3)\nscore_t3 &lt;- score_t2 + rnorm(250, mean = 3, sd = 4)\ndata &lt;- data.frame(subject_id, score_t1, score_t2, score_t3)\n\n\n\nModel Specification and Estimation\nNow, let’s specify the Latent Growth Curve Model. In this example, we’ll estimate the intercept (initial level) and slope (rate of change) for the variable of interest, as well as the variances of the intercept and slope.\n\n\nCode\n# Define the Latent Growth Curve Model\nmodel &lt;- '\n  # Latent variables\n    i =~ 1 * score_t1 + 1 * score_t2 + 1 * score_t3\n    s =~ 0 * score_t1 + 1 * score_t2 + 2 * score_t3\n\n  # Means\n    i ~ mu_i\n    s ~ mu_s\n\n  # Variances\n    i ~~ var_i * i\n    s ~~ var_s * s\n\n  # Covariance\n    i ~~ cov_is * s\n'\n\n\n\n\nCode\n# Fit the model\nfit &lt;- sem(model, data = data, missing = \"FIML\")\n\n\n\n\nInterpreting the Results\nWe can now examine the results of our Latent Growth Curve Model. The main parameters of interest are:\nmu_i: The mean intercept (initial level) of the variable of interest mu_s: The mean slope (rate of change) of the variable of interest var_i: The variance of the intercept, which reflects individual differences in initial levels var_s: The variance of the slope, which reflects individual differences in rates"
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html",
    "href": "4_Tutorials_SignedRankTest.html",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The longitudinal signed-rank test is a nonparametric alternative to the paired t-test and is appropriate when the data are not normally distributed or when the assumptions of the paired t-test are violated. The test is based on the signed-rank of the differences between the paired observations, and it tests the null hypothesis that the median of the differences is zero. The repeated-measures design allows for the assessment of within-subject changes over time or under different conditions. The signed-rank test is robust to outliers and does not assume a normal distribution of the differences. This method has been shown to have good statistical power and efficiency, particularly when the sample size is small or the distribution is heavily skewed (Erceg-Hurn & Mirosevich, 2008; Bakdash & Marusich, 2017; Garcia-Berthou & Alcaraz, 2004). The signed-rank test is a useful tool for analyzing paired data when the assumption of normality is violated or when the data is highly skewed or contains outliers.\n ### When to use a Signed-Rank Test? You should use a Wilcoxon Signed-Rank Test in the following scenario:\n\nYou want to know if two groups are different on your variable of interest\nYour variable of interest is continuous\nYou have two and only two groups\nYou have independent samples\nYou have a skewed variable of interest\n\n\n\nIn this tutorial, we will introduce the concept of the longitudinal signed-rank test and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of the longitudinal signed-rank test.\nPerform a longitudinal signed-rank test using example data in R.\nInterpret the results of the test."
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html#overview",
    "href": "4_Tutorials_SignedRankTest.html#overview",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The longitudinal signed-rank test is a nonparametric alternative to the paired t-test and is appropriate when the data are not normally distributed or when the assumptions of the paired t-test are violated. The test is based on the signed-rank of the differences between the paired observations, and it tests the null hypothesis that the median of the differences is zero. The repeated-measures design allows for the assessment of within-subject changes over time or under different conditions. The signed-rank test is robust to outliers and does not assume a normal distribution of the differences. This method has been shown to have good statistical power and efficiency, particularly when the sample size is small or the distribution is heavily skewed (Erceg-Hurn & Mirosevich, 2008; Bakdash & Marusich, 2017; Garcia-Berthou & Alcaraz, 2004). The signed-rank test is a useful tool for analyzing paired data when the assumption of normality is violated or when the data is highly skewed or contains outliers.\n ### When to use a Signed-Rank Test? You should use a Wilcoxon Signed-Rank Test in the following scenario:\n\nYou want to know if two groups are different on your variable of interest\nYour variable of interest is continuous\nYou have two and only two groups\nYou have independent samples\nYou have a skewed variable of interest\n\n\n\nIn this tutorial, we will introduce the concept of the longitudinal signed-rank test and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of the longitudinal signed-rank test.\nPerform a longitudinal signed-rank test using example data in R.\nInterpret the results of the test."
  },
  {
    "objectID": "4_Tutorials_SignedRankTest.html#basic-example",
    "href": "4_Tutorials_SignedRankTest.html#basic-example",
    "title": "Signed-Rank Test",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime point 1 (T1) measurement\nTime point 2 (T2) measurement\n\n\n\n\nSubject ID\nT1\nT2\n\n\n\n\n1\n100\n105\n\n\n2\n95\n100\n\n\n3\n110\n112\n\n\n\n\nModel Specification and Estimation\nWe will use the wilcox.test() function in R to perform a longitudinal signed-rank test. First, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 2, 3),\n  t1 = c(100, 95, 110),\n  t2 = c(105, 100, 112)\n)\n\n\nPerform the longitudinal signed-rank test using the wilcox.test() function with the paired = TRUE argument:\n\n\nCode\ntest_result &lt;- wilcox.test(data$t1, data$t2, paired = TRUE)\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal signed-rank test, examine the p-value from the test_result object:\n\n\nCode\ntest_result$p.value\n\n\n[1] 0.1735682\n\n\nThe p-value represents the probability of observing the data if there is no difference between the measurements at T1 and T2. If the p-value is less than a predetermined significance level (e.g., 0.05), we can reject the null hypothesis that there is no difference between the two time points and conclude that there is a significant difference in the measurements between T1 and T2."
  },
  {
    "objectID": "5_HowTos_MarginalModels.html",
    "href": "5_HowTos_MarginalModels.html",
    "title": "Marginal Models",
    "section": "",
    "text": "test page for marginal models howtos"
  },
  {
    "objectID": "11_Tutorials_MultivariateLatentGrowthCurveModels.html",
    "href": "11_Tutorials_MultivariateLatentGrowthCurveModels.html",
    "title": "Multivariate Latent Growth Curves",
    "section": "",
    "text": "In this tutorial, we will introduce the Multivariate Latent Growth Curve Model (MLGCM), also known as Parallel Process Latent Growth Curve Model. These models allow us to analyze multiple growth processes simultaneously, examining the relationships between the initial levels and growth rates of multiple variables over time.\nWe will use the “lavaan” package in R to fit a MLGCM with two variables, each measured at three timepoints. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#overview",
    "href": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#overview",
    "title": "Multivariate Latent Growth Curves",
    "section": "",
    "text": "In this tutorial, we will introduce the Multivariate Latent Growth Curve Model (MLGCM), also known as Parallel Process Latent Growth Curve Model. These models allow us to analyze multiple growth processes simultaneously, examining the relationships between the initial levels and growth rates of multiple variables over time.\nWe will use the “lavaan” package in R to fit a MLGCM with two variables, each measured at three timepoints. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#basic-example",
    "href": "11_Tutorials_MultivariateLatentGrowthCurveModels.html#basic-example",
    "title": "Multivariate Latent Growth Curves",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Load necessary packages\nif (!(\"lavaan\" %in% installed.packages())) install.packages(\"lavaan\")\nlibrary(lavaan)\n\n# Generate sample data\nset.seed(42)\nn &lt;- 250\ntime1_var1 &lt;- rnorm(n, mean = 10, sd = 3)\ntime2_var1 &lt;- time1_var1 + rnorm(n, mean = 2, sd = 2)\ntime3_var1 &lt;- time2_var1 + rnorm(n, mean = 2, sd = 2)\n\ntime1_var2 &lt;- rnorm(n, mean = 5, sd = 2)\ntime2_var2 &lt;- time1_var2 + rnorm(n, mean = 1, sd = 1)\ntime3_var2 &lt;- time2_var2 + rnorm(n, mean = 1, sd = 1)\n\n# Combine into a data frame\ndata &lt;- data.frame(time1_var1, time2_var1, time3_var1,\n                   time1_var2, time2_var2, time3_var2)\n\n\n\nModel Specification and Estimation\n\n\nCode\n# Specify the multivariate latent growth curve model\nmodel &lt;- '\n  # Intercept and slope factors for variable 1\n  i_var1 =~ 1*time1_var1 + 1*time2_var1 + 1*time3_var1\n  s_var1 =~ 0*time1_var1 + 1*time2_var1 + 2*time3_var1\n\n  # Intercept and slope factors for variable 2\n  i_var2 =~ 1*time1_var2 + 1*time2_var2 + 1*time3_var2\n  s_var2 =~ 0*time1_var2 + 1*time2_var2 + 2*time3_var2\n'\n\n\n\n\nCode\n# Estimate the model\nfit &lt;- lavaan::sem(model, data = data)\n\n\n\n\nCode\nsummary(fit, fit.measures = TRUE)\n\n\nlavaan 0.6-12 ended normally after 63 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 1.840\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.871\n\nModel Test Baseline Model:\n\n  Test statistic                              1631.463\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.006\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2900.271\n  Loglikelihood unrestricted model (H1)      -2899.351\n                                                      \n  Akaike (AIC)                                5832.542\n  Bayesian (BIC)                              5888.886\n  Sample-size adjusted Bayesian (BIC)         5838.164\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.045\n  P-value RMSEA &lt;= 0.05                          0.961\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.010\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i_var1 =~                                           \n    time1_var1        1.000                           \n    time2_var1        1.000                           \n    time3_var1        1.000                           \n  s_var1 =~                                           \n    time1_var1        0.000                           \n    time2_var1        1.000                           \n    time3_var1        2.000                           \n  i_var2 =~                                           \n    time1_var2        1.000                           \n    time2_var2        1.000                           \n    time3_var2        1.000                           \n  s_var2 =~                                           \n    time1_var2        0.000                           \n    time2_var2        1.000                           \n    time3_var2        2.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i_var1 ~~                                           \n    s_var1            0.240    0.365    0.658    0.511\n    i_var2           -0.157    0.394   -0.400    0.689\n    s_var2            0.015    0.123    0.121    0.904\n  s_var1 ~~                                           \n    i_var2           -0.057    0.183   -0.310    0.757\n    s_var2            0.102    0.058    1.771    0.077\n  i_var2 ~~                                           \n    s_var2           -0.185    0.127   -1.454    0.146\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .time1_var1       -0.101    0.520   -0.194    0.846\n   .time2_var1        1.999    0.344    5.807    0.000\n   .time3_var1        0.031    0.733    0.043    0.966\n   .time1_var2       -0.348    0.190   -1.826    0.068\n   .time2_var2        0.689    0.116    5.950    0.000\n   .time3_var2       -0.460    0.224   -2.055    0.040\n    i_var1            8.630    0.931    9.274    0.000\n    s_var1            1.866    0.336    5.557    0.000\n    i_var2            4.947    0.481   10.291    0.000\n    s_var2            0.647    0.108    5.979    0.000\n\n\n\n\nInterpreting the Results\nIn the output, you will see the estimates for the factor loadings, intercepts, and slopes for both variables. These estimates describe the initial levels and growth rates for each variable. You will also see the variances and covariances of the latent intercept and slope factors, which provide information about individual differences in initial levels and growth rates, as well as the relationships between the initial levels and growth rates across the two variables.\nPay attention to the model fit indices (e.g., CFI, TLI, RMSEA, and SRMR) to evaluate how well the model fits the data. Good model fit is indicated by CFI and TLI values close to or greater than 0.95, RMSEA values close to or smaller than 0.06, and SRMR values close to or smaller than xxx"
  },
  {
    "objectID": "6_Tutorials_GeneralizedEstimatingEquations.html",
    "href": "6_Tutorials_GeneralizedEstimatingEquations.html",
    "title": "Generalized Estimating Equations",
    "section": "",
    "text": "[*add diagrams/figures]"
  },
  {
    "objectID": "6_Tutorials_GeneralizedEstimatingEquations.html#overview",
    "href": "6_Tutorials_GeneralizedEstimatingEquations.html#overview",
    "title": "Generalized Estimating Equations",
    "section": "Overview",
    "text": "Overview\nGeneralized estimating equations (GEEs) are a statistical method used to analyze longitudinal or clustered data, while accounting for within-subject correlation. The goal GEEs are to make inferences about population-averaged effects (controlling for within-subject correlations), rather than individual subject-level effects. GEEs can handle a wide range of outcome distributions, including binary, count, and continuous data (Fitzmaurice et al., 2011; Hardin & Hilbe, 2012). This method is an extension of the generalized linear model (Diggle et al., 2002), shows good statistical power and efficiency, is robust to non-normality and non-constant variance and can handle unbalanced or unequally spaced data.\n\nWhen to use Longitudinal Generalized Estimating Equations (GEEs)?\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\nGetting Started with Longitudinal Generalized Estimating Equations (GEEs)\nIn this tutorial, we will introduce the concept of longitudinal generalized estimating equations (GEEs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GEEs.\nFit a GEE model using example data in R.\nInterpret the results of the model.\n\n\n\nBasic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\n\nModel Specification and Estimation\nWe will use the geepack package in R to fit a longitudinal GEE model. First, install and load the required package:\n\n\nCode\nif (!(\"geepack\" %in% installed.packages())) install.packages(\"geepack\")\nlibrary(geepack)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\n\nFit the longitudinal GEE model with a binary outcome using a logit link function and an exchangeable correlation structure:\n\n\nCode\nmodel &lt;- geeglm(outcome ~ time, data = data, id = subject_id, family = binomial(link = \"logit\"), corstr = \"exchangeable\")\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal GEE model, we can use the summary() function in R to display the estimated population-averaged effects:\n\n\nCode\nsummary(model)\n\n\n\nCall:\ngeeglm(formula = outcome ~ time, family = binomial(link = \"logit\"), \n    data = data, id = subject_id, corstr = \"exchangeable\")\n\n Coefficients:\n            Estimate Std.err Wald Pr(&gt;|W|)\n(Intercept)   -43.54     NaN  NaN      NaN\ntime           82.78     NaN  NaN      NaN\n\nCorrelation structure = exchangeable \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept) 2.22e-16     NaN\n  Link = identity \n\nEstimated Correlation Parameters:\n      Estimate Std.err\nalpha     -0.5     NaN\nNumber of clusters:   2  Maximum cluster size: 3 \n\n\nThe output will show the estimated effect of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level."
  },
  {
    "objectID": "explanations.html",
    "href": "explanations.html",
    "title": "Explanations: A Brief Overview",
    "section": "",
    "text": "The primary goal of the explanation section is to provide context, background information, and a deeper understanding of the concepts, methodologies, or processes related to a specific analysis or topic. Unlike tutorials and how-to guides, which are goal-oriented and problem-oriented respectively, explanations aim to clarify and enhance the user’s knowledge. The explanation section aims to create informative, engaging, and accessible content that helps users build a solid foundation of understanding and knowledge about the subject matter.\n\n\nThe explanation section should:\n\nBe informative: Explanations should offer valuable insights and information, helping users develop a deeper understanding of the topic. This includes discussing the rationale behind certain choices, exploring alternative approaches, and explaining the advantages and disadvantages of various options.\nAddress “why” questions: Explanations should aim to answer the “why” questions users may have, delving into the reasoning, motivations, or principles that underlie a specific concept or approach.\nBe clear and concise: While explanations may go into greater depth than tutorials or how-to guides, they should still be presented in a clear and concise manner. This means using plain language, avoiding jargon, and providing examples to help users grasp the concepts more easily.\nBe well-structured: Explanations should be organized in a logical and coherent manner, making it easy for users to follow the flow of information and understand the relationships between different concepts.\nSupport other documentation types: Explanations should complement and support other types of documentation, such as tutorials and how-to guides, by providing the necessary context and background information. This may involve cross-referencing other resources or linking to related documentation.\nEngage the audience: Explanations should be engaging and interesting, capturing the user’s attention and encouraging them to explore the topic further. This may involve using analogies, storytelling, or real-world examples to illustrate the concepts and make them more relatable.\n\n\nFor additional information, see [https://documentation.divio.com/]"
  },
  {
    "objectID": "explanations.html#what-are-explanations",
    "href": "explanations.html#what-are-explanations",
    "title": "Explanations: A Brief Overview",
    "section": "",
    "text": "The primary goal of the explanation section is to provide context, background information, and a deeper understanding of the concepts, methodologies, or processes related to a specific analysis or topic. Unlike tutorials and how-to guides, which are goal-oriented and problem-oriented respectively, explanations aim to clarify and enhance the user’s knowledge. The explanation section aims to create informative, engaging, and accessible content that helps users build a solid foundation of understanding and knowledge about the subject matter.\n\n\nThe explanation section should:\n\nBe informative: Explanations should offer valuable insights and information, helping users develop a deeper understanding of the topic. This includes discussing the rationale behind certain choices, exploring alternative approaches, and explaining the advantages and disadvantages of various options.\nAddress “why” questions: Explanations should aim to answer the “why” questions users may have, delving into the reasoning, motivations, or principles that underlie a specific concept or approach.\nBe clear and concise: While explanations may go into greater depth than tutorials or how-to guides, they should still be presented in a clear and concise manner. This means using plain language, avoiding jargon, and providing examples to help users grasp the concepts more easily.\nBe well-structured: Explanations should be organized in a logical and coherent manner, making it easy for users to follow the flow of information and understand the relationships between different concepts.\nSupport other documentation types: Explanations should complement and support other types of documentation, such as tutorials and how-to guides, by providing the necessary context and background information. This may involve cross-referencing other resources or linking to related documentation.\nEngage the audience: Explanations should be engaging and interesting, capturing the user’s attention and encouraging them to explore the topic further. This may involve using analogies, storytelling, or real-world examples to illustrate the concepts and make them more relatable.\n\n\nFor additional information, see [https://documentation.divio.com/]"
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html",
    "href": "14_Tutorials_StateTraitModels.html",
    "title": "State-Trait Models",
    "section": "",
    "text": "State-Trait Models are a type of statistical model used to separate the variance in a given variable into two components: a stable, trait-like component and a time-specific, state-like component. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a State-Trait Model using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including State-Trait Models."
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html#overview",
    "href": "14_Tutorials_StateTraitModels.html#overview",
    "title": "State-Trait Models",
    "section": "",
    "text": "State-Trait Models are a type of statistical model used to separate the variance in a given variable into two components: a stable, trait-like component and a time-specific, state-like component. In this tutorial, we will walk you through a simple example using a simulated dataset and demonstrate how to fit a State-Trait Model using the lavaan package in R.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you will need to have R and RStudio installed on your computer. Additionally, you will need to install the lavaan package, which provides functions for fitting various structural equation models, including State-Trait Models."
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html#basic-example",
    "href": "14_Tutorials_StateTraitModels.html#basic-example",
    "title": "State-Trait Models",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Install the lavaan package if not already installed\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "14_Tutorials_StateTraitModels.html#simulating-the-data",
    "href": "14_Tutorials_StateTraitModels.html#simulating-the-data",
    "title": "State-Trait Models",
    "section": "Simulating the Data",
    "text": "Simulating the Data\nFor this tutorial, we will use a simulated dataset with 300 individuals, each measured at four time points. The dataset will contain a variable with both state-like and trait-like components.\n\n\nCode\nset.seed(123)\nn &lt;- 300\ntimepoints &lt;- 4\n\n# Simulate the trait-like component\ntrait &lt;- rnorm(n, mean = 100, sd = 10)\n\n# Simulate the state-like component\nstate &lt;- matrix(rnorm(n * timepoints, mean = 0, sd = 5), nrow = n, ncol = timepoints)\n\n# Combine trait and state components\ndata &lt;- data.frame(id = rep(1:n, each = timepoints),\n                   time = rep(1:timepoints, times = n),\n                   value = c(t(trait + state)))\n\n\n\nModel Specification and Estimation\nNow that we have our simulated data, we can fit a State-Trait Model using the lavaan package. The model will estimate the trait-like and state-like components for each individual.\n\n\nCode\n# Define the model\nmodel &lt;- '\n  # Trait component\n  trait =~ 1 * value_t1 + 1 * value_t2 + 1 * value_t3 + 1 * value_t4\n\n  # State component\n  state =~ value_t1 + value_t2 + value_t3 + value_t4\n\n  # Residual variances\n  value_t1 ~~ value_t1\n  value_t2 ~~ value_t2\n  value_t3 ~~ value_t3\n  value_t4 ~~ value_t4\n'\n\n\n\n\nCode\n# Reshape the data to wide format\ndata_wide &lt;- reshape(data, idvar = \"id\", timevar = \"time\", direction = \"wide\")\n\n\n\n\nCode\n# Fit the State-Trait Model\nfit &lt;- sem(model, data = data_wide)\n\n\n\n\nInterpreting the Results\nNow that we have estimated our State-Trait Model, we can interpret the results. The key parameters of interest in this model are the trait-like and state-like components, which are the variances attributed to each component.\n\n\nCode\n# Obtain the results\nsummary(fit)"
  },
  {
    "objectID": "7_HowTos_GeneralizedLinearMixedEffectsModels.html",
    "href": "7_HowTos_GeneralizedLinearMixedEffectsModels.html",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "",
    "text": "test page for GLMM howtos"
  },
  {
    "objectID": "11_HowTos_MultivariateLatentGrowthCurveModels.html",
    "href": "11_HowTos_MultivariateLatentGrowthCurveModels.html",
    "title": "Multivariate Latent Growth Curve Models",
    "section": "",
    "text": "test page for pplgcm howtos"
  },
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "Tutorials\n\n\n\n\nHow-Tos\n\n\n\n\n\n\n\nExplanations\n\n\n\n\nReference"
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "",
    "text": "Generalized linear mixed-effects models (GLMMs) are a statistical method used to analyze longitudinal or clustered data that accounts for within-subject correlation and allows for the estimation of subject-specific effects (Pinheiro & Bates, 2000; Fitzmaurice et al., 2011). This method extends the generalized linear mixed-effects model by modeling both fixed-effects (population-averaged effects) and random-effects (subject-specific deviations), while accounting for within-subject correlations. The method can handle unbalanced or unequally spaced data, and can accommodate various outcome distributions, including binary, count, and continuous data. GLMMs have been shown to have good statistical power and efficiency, and can be used to model complex data structures, including crossed and nested random effects. GLMMs have been shown to outperform other methods, such as GEE, in terms of statistical power and efficiency (Hardin & Hilbe, 2012).\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal generalized linear mixed effects models (GLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GLMMs.\nFit a GLMM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#overview",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#overview",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "",
    "text": "Generalized linear mixed-effects models (GLMMs) are a statistical method used to analyze longitudinal or clustered data that accounts for within-subject correlation and allows for the estimation of subject-specific effects (Pinheiro & Bates, 2000; Fitzmaurice et al., 2011). This method extends the generalized linear mixed-effects model by modeling both fixed-effects (population-averaged effects) and random-effects (subject-specific deviations), while accounting for within-subject correlations. The method can handle unbalanced or unequally spaced data, and can accommodate various outcome distributions, including binary, count, and continuous data. GLMMs have been shown to have good statistical power and efficiency, and can be used to model complex data structures, including crossed and nested random effects. GLMMs have been shown to outperform other methods, such as GEE, in terms of statistical power and efficiency (Hardin & Hilbe, 2012).\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal generalized linear mixed effects models (GLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal GLMMs.\nFit a GLMM using example data in R.\nInterpret the results of the model."
  },
  {
    "objectID": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#basic-example",
    "href": "7_Tutorials_GeneralizedLinearMixedEffectsModels.html#basic-example",
    "title": "Generalized Linear Mixed Effects Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nBinary outcome variable (e.g., presence or absence of a particular condition)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n1\n2\n1\n\n\n2\n0\n0\n\n\n2\n1\n1\n\n\n\n\nModel Specification and Estimation\nWe will use the lme4 package in R to fit a longitudinal GLMM. First, install the required package, if not already installed:\n\n\nCode\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nlibrary(lme4)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = factor(c(1, 1, 1, 2, 2)),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(0, 1, 1, 0, 1)\n)\n\n\nFit the longitudinal GLMM with a binary outcome using a logit link function and random intercepts for each subject:\n\n\nCode\nmodel &lt;- glmer(outcome ~ time + (1 | subject_id), data = data, family = binomial(link = \"logit\"))\n\n\n\n\nInterpreting the Results\nTo interpret the results of the longitudinal GLMM, we can use the summary() function in R to display the estimated fixed effects and random effects:\n\n\nCode\nsummary(model)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: outcome ~ time + (1 | subject_id)\n   Data: data\n\n     AIC      BIC   logLik deviance df.resid \n     6.0      4.8      0.0      0.0        2 \n\nScaled residuals: \n      Min        1Q    Median        3Q       Max \n-1.49e-08 -1.49e-08  1.49e-08  1.49e-08  1.49e-08 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n subject_id (Intercept) 0.36     0.6     \nNumber of obs: 5, groups:  subject_id, 2\n\nFixed effects:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept) -3.834e+01  4.393e+07       0        1\ntime         7.526e+01  4.011e+07       0        1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime -0.730\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nunable to evaluate scaled gradient\n Hessian is numerically singular: parameters are not uniquely determined\n\n\nThe output will show the estimated fixed effects of time on the binary outcome variable, expressed as an odds ratio. By examining the odds ratio and its associated p-value, we can determine if the change in the outcome variable over time is significant at the population level. Additionally, the output will display information about the random effects, such as the variance of the random intercepts for subjects."
  },
  {
    "objectID": "12_Tutorials_LatentTransitionAnalysis.html",
    "href": "12_Tutorials_LatentTransitionAnalysis.html",
    "title": "Latent Transition Analysis",
    "section": "",
    "text": "In this tutorial, we will introduce Latent Transition Analysis (LTA), a statistical method used to analyze the movement of individuals between latent (unobserved) statuses over time. LTA is particularly useful when dealing with categorical data and allows us to estimate the probabilities of transitioning between latent statuses.\nWe will use the “tidyLPA” package in R to fit a simple LTA model with four timepoints and three indicators per timepoint. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "12_Tutorials_LatentTransitionAnalysis.html#overview",
    "href": "12_Tutorials_LatentTransitionAnalysis.html#overview",
    "title": "Latent Transition Analysis",
    "section": "",
    "text": "In this tutorial, we will introduce Latent Transition Analysis (LTA), a statistical method used to analyze the movement of individuals between latent (unobserved) statuses over time. LTA is particularly useful when dealing with categorical data and allows us to estimate the probabilities of transitioning between latent statuses.\nWe will use the “tidyLPA” package in R to fit a simple LTA model with four timepoints and three indicators per timepoint. We will also provide a brief overview of interpreting the results.\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx"
  },
  {
    "objectID": "12_Tutorials_LatentTransitionAnalysis.html#basic-example",
    "href": "12_Tutorials_LatentTransitionAnalysis.html#basic-example",
    "title": "Latent Transition Analysis",
    "section": "Basic Example",
    "text": "Basic Example\n\n\nCode\n# Load necessary packages\nif (!(\"tidyLPA\" %in% installed.packages())) install.packages(\"tidyLPA\")\nlibrary(tidyLPA)\n\n\n\n\nCode\nset.seed(42)\nn &lt;- 250\n\n# Generate three indicators for time 1\ntime1_ind1 &lt;- rbinom(n, size = 1, prob = 0.7)\ntime1_ind2 &lt;- rbinom(n, size = 1, prob = 0.6)\ntime1_ind3 &lt;- rbinom(n, size = 1, prob = 0.5)\n\n# Generate three indicators for time 2\ntime2_ind1 &lt;- rbinom(n, size = 1, prob = 0.6)\ntime2_ind2 &lt;- rbinom(n, size = 1, prob = 0.5)\ntime2_ind3 &lt;- rbinom(n, size = 1, prob = 0.4)\n\n# Generate three indicators for time 3\ntime3_ind1 &lt;- rbinom(n, size = 1, prob = 0.5)\ntime3_ind2 &lt;- rbinom(n, size = 1, prob = 0.4)\ntime3_ind3 &lt;- rbinom(n, size = 1, prob = 0.3)\n\n# Generate three indicators for time 4\ntime4_ind1 &lt;- rbinom(n, size = 1, prob = 0.4)\ntime4_ind2 &lt;- rbinom(n, size = 1, prob = 0.3)\ntime4_ind3 &lt;- rbinom(n, size = 1, prob = 0.2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "1b_HowTos_DifferenceScores.html",
    "href": "1b_HowTos_DifferenceScores.html",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "This example will examine whether average change in CBCL externalizing scores from Basline (T0) to the 1-Year follow-up (T1) differs significantly between boys and girls taking part in the ABCD Study. This analysis is conducted in two primary steps: 1) computing a difference score (DiffScore = CBCL EXT T2 - CBCL EXT T1); 2) conducting a simple regression on the difference score. Our primary aim is to determine whether group membership (boys, girls) predict the average difference value in CBCL externalizing scores from T1 to T2.\n\n\n\n\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\n#rm(list = ls())\n\n#Load packages\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(rstatix)\nlibrary(ggpubr)\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                                  comment=NA, cache=T, code_folding=T,\n                                  R.options=list(width=220), fig.align='center', \n                                  out.width='75%', fig.asp=.75)\n\n\n\n\n\n\n\n\n\n\nRead and View Data\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n## Read data\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\ndf_wide &lt;- read_csv(\"/Users/shawes/Desktop/data/df_wide.csv\")\nstr(df_wide)\n\n\nspc_tbl_ [99 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ids                 : num [1:99] 1 2 3 4 5 6 7 8 9 10 ...\n $ site_id             : chr [1:99] \"site06\" \"site06\" \"site06\" \"site10\" ...\n $ fam_id              : num [1:99] 8781 8781 8781 10210 10210 ...\n $ sex                 : chr [1:99] \"Female\" \"Female\" \"Female\" \"Female\" ...\n $ age                 : num [1:99] 9 10 9 9 9 10 10 10 10 9 ...\n $ mature_vg           : num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ vg_total_Year_1     : num [1:99] 7 7 7 7 4 0 4 1 1 2 ...\n $ vg_total_Baseline   : num [1:99] 4 7 4 2 42 0 4 2 2 2 ...\n $ vg_total_Year_2     : num [1:99] 1 1 2 0 3 0 2 2 7 3 ...\n $ cbcl_extern_Year_1  : num [1:99] 7 7 7 7 2 0 4 1 1 2 ...\n $ cbcl_extern_Baseline: num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ cbcl_extern_Year_2  : num [1:99] 7 7 7 7 4 6 4 4 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ids = col_double(),\n  ..   site_id = col_character(),\n  ..   fam_id = col_double(),\n  ..   sex = col_character(),\n  ..   age = col_double(),\n  ..   mature_vg = col_double(),\n  ..   vg_total_Year_1 = col_double(),\n  ..   vg_total_Baseline = col_double(),\n  ..   vg_total_Year_2 = col_double(),\n  ..   cbcl_extern_Year_1 = col_double(),\n  ..   cbcl_extern_Baseline = col_double(),\n  ..   cbcl_extern_Year_2 = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nCode\n# set types\ndf_long$ids &lt;- as.factor(df_long$ids)\ndf_long$event &lt;- as.factor(df_long$event)\ndf_long$site_id &lt;- as.factor(df_long$site_id)\ndf_long$fam_id &lt;- as.factor(df_long$fam_id)\ndf_long$sex &lt;- as.factor(df_long$sex)\ndf_long$age &lt;- as.numeric(df_long$age)\ndf_long$mature_vg &lt;- as.numeric(df_long$mature_vg)\ndf_long$cbcl_extern &lt;- as.numeric(df_long$cbcl_extern)\ndf_long$vg_total &lt;- as.numeric(df_long$vg_total)\n\n\n\n\n\n\n\n\n\nThis code creates a table of descriptive information for continuous outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_1 &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\" \n), #\"Nmiss2\"\ncat.stats=c(\"countpct\"), #\"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n))  # , Nmiss2 ='Missing'\n\nmy_cont_labels &lt;- list(\n  age = \"Age\",\n  vg_total = \"Weekly # of Video Gaming Hrs\",\n  cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                                      cbcl_extern,\n                                      data=df_long, control=tab_descriptives_1)\n          \n#summary(tab_descriptives_1, labelTranslations = my_cont_labels , text=TRUE, title = #\"Continuous Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n                summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n            column_spec(3, width = \"20em\", border_right = T) %&gt;%\n            footnote(general = \"Here is a general comments of the table. \") %&gt;%\n            scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis code creates a descriptives table for categorical outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n), # \"Nmiss2\"\ncat.stats=c(\"countpct\"), # \"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n)) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n          \ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, data=df_long, control=tab_descriptives_2)\n\n#summary(tab_descriptives_2, labelTranslations = my_cat_labels , text=TRUE, title = #\"Categorical Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n            summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Categorical Outcomes\") %&gt;%\n            kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n            column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n::: panel-tabset ### Build Model {.tabset .tabset-fade .tabset-pills}\n\nThe code snippet below tells R to compute a difference score by subtracting each participant’s Externalizing score at T2 from their Externalizing score at T1. Next, a simple regression analyses is conducted to examine whether a grouping variable (participant sex) significantly predicts the difference score value (indicating significant group differences in the average difference score). The simple regression function (lm) is provided by the r ‘stats’ package.\nxxx First, compute the difference (\\Delta) between a score on some measure (x) assessed at baseline (x_{t1}) and follow-up (x_{t2}). The result of this formula (\\Delta=x_{t2} - x_{t1}) can be included as the outcome variable in a regression model that analyzes the role of the grouping variable (e.g., 0 = boy; 1 = girl) on changes in scores on the measure across follow-ups. xxx\nSTEP 1: Compute Difference Score\n\n\nCode\n# Compute difference score based on CBCL Externalizing subscale scores at baseline (t1) and 1-Year Follow-up (t2)\ndf_wide$diffscore &lt;- (df_wide$cbcl_extern_Year_1 - df_wide$cbcl_extern_Baseline)\n\n\n\n\nCode\n# Compute statistical summaries for the difference score variable\nsummary(df_wide$diffscore)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-27.000   1.000   5.000   5.576   8.000  33.000 \n\n\nThis summary of the difference score variable indicates xxxxx.\n\n\nCode\nhist(df_long$vg_total)\n\n\n\n\n\nCode\n## Summary statistics\nsummary&lt;-df_long %&gt;%\ngroup_by(event) %&gt;%\nget_summary_stats(cbcl_extern, type = \"mean_sd\")\ndata.frame(summary)\n\n\n\n\n  \n\n\n\nThis histogram indicates xxxxxx. The summary command shows xxxxxx.\n\n\nCode\n### Shapiro-Wilk test and normality (Q-Q) plot (visualization of correlation between a given sample and the normal distribution)\nshapiro.test(df_wide$cbcl_extern_Baseline[0:5000])\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  df_wide$cbcl_extern_Baseline[0:5000]\nW = 0.67151, p-value = 1.452e-13\n\n\nThis Shapiro-wilkes test shows xxxxxx.\n\n\nCode\nqqplot &lt;- ggqqplot(df_wide$cbcl_extern_Baseline,\n    ylab = \"Externalizing Difference Score\", xlab = FALSE,\n    ggtheme = theme_minimal()\n)\n\nsuppressWarnings(print(qqplot)) \n\n\n\n\n\nThis qqplot shows xxxxxx.\nSTEP 2: Conduct simple regression on Difference Score\n\n\nCode\n#Simple linear regression is used to examine the relationship between a continuous predictor variable and the average difference score.\n\n#Regression model\nresult &lt;- lm(df_wide$diffscore ~ vg_total_Baseline, data = df_wide)\n#summarize the reults\nsummary(result)\n\n\n\nCall:\nlm(formula = df_wide$diffscore ~ vg_total_Baseline, data = df_wide)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.022  -4.685  -0.387   2.091  28.315 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        4.57285    1.18272   3.866   0.0002 ***\nvg_total_Baseline  0.11219    0.08052   1.393   0.1667    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.337 on 97 degrees of freedom\nMultiple R-squared:  0.01962,   Adjusted R-squared:  0.009511 \nF-statistic: 1.941 on 1 and 97 DF,  p-value: 0.1667\n\n\nThe output from our model provides: i. a parameter estimate; ii. standard error; iii. p-value. In our example p = .001 which is less than .05 indicating significant differences in predicted cbcl externalizing scores between boys and girls in the ABCD Study. An examination of the regression coeefficient for sex (female = 0; male = 1) is b = .xx, indicating the difference in cbcl externalizing scores from Time 1 to Time 2 is significantly greater in boys taking part in the ABCD Study relative to girls. Then we conclude that participant sex (does/does not) predict change in cbcl externalizing scores from t1 to t2.\n\n\n\n\n\ntesting\n#Scatterplot to visualize relationship between a continuous predictor and a difference score\nscatterplot &lt;- ggplot (df_wide, aes(x = diffscore, y = vg_total_Baseline)) + geom_point(size = 3) + geom_smooth(method = lm, se = F) +\nxlab(\"Difference Score (x)\") +\nylab(\"Screentime hours (y) Baseline\")\n\nsuppressWarnings(print(scatterplot))\n\n\n\n\n\nExamination of this scatterplot indicates xxxxx.\n\n\nThis output shows xxxxxxxx. Briefly walk through each metric\n\n\n\n\n\n\n\n\n\n\n\nWrite-up\n\n\n\nA simple regression analysis was conducted to examine whether participant’s sex predicted change in cbcl externalzing scores measured across two timepoints. Findings showed a significant positive effect such that boys demonstrated increases in cbcl externalzing scores relative to girls (b = .xx; SE = .xx; p = .xx)"
  },
  {
    "objectID": "1b_HowTos_DifferenceScores.html#overview",
    "href": "1b_HowTos_DifferenceScores.html#overview",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "This example will examine whether average change in CBCL externalizing scores from Basline (T0) to the 1-Year follow-up (T1) differs significantly between boys and girls taking part in the ABCD Study. This analysis is conducted in two primary steps: 1) computing a difference score (DiffScore = CBCL EXT T2 - CBCL EXT T1); 2) conducting a simple regression on the difference score. Our primary aim is to determine whether group membership (boys, girls) predict the average difference value in CBCL externalizing scores from T1 to T2."
  },
  {
    "objectID": "1b_HowTos_DifferenceScores.html#preliminary-setup",
    "href": "1b_HowTos_DifferenceScores.html#preliminary-setup",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "Install PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\n#rm(list = ls())\n\n#Load packages\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(rstatix)\nlibrary(ggpubr)\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                                  comment=NA, cache=T, code_folding=T,\n                                  R.options=list(width=220), fig.align='center', \n                                  out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "1b_HowTos_DifferenceScores.html#descriptives-overview",
    "href": "1b_HowTos_DifferenceScores.html#descriptives-overview",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "Read and View Data\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n## Read data\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\ndf_wide &lt;- read_csv(\"/Users/shawes/Desktop/data/df_wide.csv\")\nstr(df_wide)\n\n\nspc_tbl_ [99 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ids                 : num [1:99] 1 2 3 4 5 6 7 8 9 10 ...\n $ site_id             : chr [1:99] \"site06\" \"site06\" \"site06\" \"site10\" ...\n $ fam_id              : num [1:99] 8781 8781 8781 10210 10210 ...\n $ sex                 : chr [1:99] \"Female\" \"Female\" \"Female\" \"Female\" ...\n $ age                 : num [1:99] 9 10 9 9 9 10 10 10 10 9 ...\n $ mature_vg           : num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ vg_total_Year_1     : num [1:99] 7 7 7 7 4 0 4 1 1 2 ...\n $ vg_total_Baseline   : num [1:99] 4 7 4 2 42 0 4 2 2 2 ...\n $ vg_total_Year_2     : num [1:99] 1 1 2 0 3 0 2 2 7 3 ...\n $ cbcl_extern_Year_1  : num [1:99] 7 7 7 7 2 0 4 1 1 2 ...\n $ cbcl_extern_Baseline: num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ cbcl_extern_Year_2  : num [1:99] 7 7 7 7 4 6 4 4 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ids = col_double(),\n  ..   site_id = col_character(),\n  ..   fam_id = col_double(),\n  ..   sex = col_character(),\n  ..   age = col_double(),\n  ..   mature_vg = col_double(),\n  ..   vg_total_Year_1 = col_double(),\n  ..   vg_total_Baseline = col_double(),\n  ..   vg_total_Year_2 = col_double(),\n  ..   cbcl_extern_Year_1 = col_double(),\n  ..   cbcl_extern_Baseline = col_double(),\n  ..   cbcl_extern_Year_2 = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nCode\n# set types\ndf_long$ids &lt;- as.factor(df_long$ids)\ndf_long$event &lt;- as.factor(df_long$event)\ndf_long$site_id &lt;- as.factor(df_long$site_id)\ndf_long$fam_id &lt;- as.factor(df_long$fam_id)\ndf_long$sex &lt;- as.factor(df_long$sex)\ndf_long$age &lt;- as.numeric(df_long$age)\ndf_long$mature_vg &lt;- as.numeric(df_long$mature_vg)\ndf_long$cbcl_extern &lt;- as.numeric(df_long$cbcl_extern)\ndf_long$vg_total &lt;- as.numeric(df_long$vg_total)\n\n\n\n\n\n\n\n\n\nThis code creates a table of descriptive information for continuous outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_1 &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\" \n), #\"Nmiss2\"\ncat.stats=c(\"countpct\"), #\"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n))  # , Nmiss2 ='Missing'\n\nmy_cont_labels &lt;- list(\n  age = \"Age\",\n  vg_total = \"Weekly # of Video Gaming Hrs\",\n  cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                                      cbcl_extern,\n                                      data=df_long, control=tab_descriptives_1)\n          \n#summary(tab_descriptives_1, labelTranslations = my_cont_labels , text=TRUE, title = #\"Continuous Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n                summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n            column_spec(3, width = \"20em\", border_right = T) %&gt;%\n            footnote(general = \"Here is a general comments of the table. \") %&gt;%\n            scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis code creates a descriptives table for categorical outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n), # \"Nmiss2\"\ncat.stats=c(\"countpct\"), # \"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n)) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n          \ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, data=df_long, control=tab_descriptives_2)\n\n#summary(tab_descriptives_2, labelTranslations = my_cat_labels , text=TRUE, title = #\"Categorical Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n            summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Categorical Outcomes\") %&gt;%\n            kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n            column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "1b_HowTos_DifferenceScores.html#results",
    "href": "1b_HowTos_DifferenceScores.html#results",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "::: panel-tabset ### Build Model {.tabset .tabset-fade .tabset-pills}\n\nThe code snippet below tells R to compute a difference score by subtracting each participant’s Externalizing score at T2 from their Externalizing score at T1. Next, a simple regression analyses is conducted to examine whether a grouping variable (participant sex) significantly predicts the difference score value (indicating significant group differences in the average difference score). The simple regression function (lm) is provided by the r ‘stats’ package.\nxxx First, compute the difference (\\Delta) between a score on some measure (x) assessed at baseline (x_{t1}) and follow-up (x_{t2}). The result of this formula (\\Delta=x_{t2} - x_{t1}) can be included as the outcome variable in a regression model that analyzes the role of the grouping variable (e.g., 0 = boy; 1 = girl) on changes in scores on the measure across follow-ups. xxx\nSTEP 1: Compute Difference Score\n\n\nCode\n# Compute difference score based on CBCL Externalizing subscale scores at baseline (t1) and 1-Year Follow-up (t2)\ndf_wide$diffscore &lt;- (df_wide$cbcl_extern_Year_1 - df_wide$cbcl_extern_Baseline)\n\n\n\n\nCode\n# Compute statistical summaries for the difference score variable\nsummary(df_wide$diffscore)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-27.000   1.000   5.000   5.576   8.000  33.000 \n\n\nThis summary of the difference score variable indicates xxxxx.\n\n\nCode\nhist(df_long$vg_total)\n\n\n\n\n\nCode\n## Summary statistics\nsummary&lt;-df_long %&gt;%\ngroup_by(event) %&gt;%\nget_summary_stats(cbcl_extern, type = \"mean_sd\")\ndata.frame(summary)\n\n\n\n\n  \n\n\n\nThis histogram indicates xxxxxx. The summary command shows xxxxxx.\n\n\nCode\n### Shapiro-Wilk test and normality (Q-Q) plot (visualization of correlation between a given sample and the normal distribution)\nshapiro.test(df_wide$cbcl_extern_Baseline[0:5000])\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  df_wide$cbcl_extern_Baseline[0:5000]\nW = 0.67151, p-value = 1.452e-13\n\n\nThis Shapiro-wilkes test shows xxxxxx.\n\n\nCode\nqqplot &lt;- ggqqplot(df_wide$cbcl_extern_Baseline,\n    ylab = \"Externalizing Difference Score\", xlab = FALSE,\n    ggtheme = theme_minimal()\n)\n\nsuppressWarnings(print(qqplot)) \n\n\n\n\n\nThis qqplot shows xxxxxx.\nSTEP 2: Conduct simple regression on Difference Score\n\n\nCode\n#Simple linear regression is used to examine the relationship between a continuous predictor variable and the average difference score.\n\n#Regression model\nresult &lt;- lm(df_wide$diffscore ~ vg_total_Baseline, data = df_wide)\n#summarize the reults\nsummary(result)\n\n\n\nCall:\nlm(formula = df_wide$diffscore ~ vg_total_Baseline, data = df_wide)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.022  -4.685  -0.387   2.091  28.315 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        4.57285    1.18272   3.866   0.0002 ***\nvg_total_Baseline  0.11219    0.08052   1.393   0.1667    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.337 on 97 degrees of freedom\nMultiple R-squared:  0.01962,   Adjusted R-squared:  0.009511 \nF-statistic: 1.941 on 1 and 97 DF,  p-value: 0.1667\n\n\nThe output from our model provides: i. a parameter estimate; ii. standard error; iii. p-value. In our example p = .001 which is less than .05 indicating significant differences in predicted cbcl externalizing scores between boys and girls in the ABCD Study. An examination of the regression coeefficient for sex (female = 0; male = 1) is b = .xx, indicating the difference in cbcl externalizing scores from Time 1 to Time 2 is significantly greater in boys taking part in the ABCD Study relative to girls. Then we conclude that participant sex (does/does not) predict change in cbcl externalizing scores from t1 to t2.\n\n\n\n\n\ntesting\n#Scatterplot to visualize relationship between a continuous predictor and a difference score\nscatterplot &lt;- ggplot (df_wide, aes(x = diffscore, y = vg_total_Baseline)) + geom_point(size = 3) + geom_smooth(method = lm, se = F) +\nxlab(\"Difference Score (x)\") +\nylab(\"Screentime hours (y) Baseline\")\n\nsuppressWarnings(print(scatterplot))\n\n\n\n\n\nExamination of this scatterplot indicates xxxxx.\n\n\nThis output shows xxxxxxxx. Briefly walk through each metric"
  },
  {
    "objectID": "1b_HowTos_DifferenceScores.html#wrapping-up",
    "href": "1b_HowTos_DifferenceScores.html#wrapping-up",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "Write-up\n\n\n\nA simple regression analysis was conducted to examine whether participant’s sex predicted change in cbcl externalzing scores measured across two timepoints. Findings showed a significant positive effect such that boys demonstrated increases in cbcl externalzing scores relative to girls (b = .xx; SE = .xx; p = .xx)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Sam Page Test"
  },
  {
    "objectID": "13_HowTos_GrowthMixtureModels.html",
    "href": "13_HowTos_GrowthMixtureModels.html",
    "title": "Growth Mixture Models",
    "section": "",
    "text": "test page of gmm how-tos"
  },
  {
    "objectID": "howto.html",
    "href": "howto.html",
    "title": "How-To’s: A Brief Overview",
    "section": "",
    "text": "The primary goal of the “how-to” section is on providing practical solutions to specific methods or analytic problems users might encounter. Unlike tutorials, which aim to teach a concept, how-to guides concentrate on the efficient execution of specific analyses without going into in-depth background explanations. By following these principles, the how-to section aims to create practical, efficient, and user-friendly guides that help users quickly identify solutions and accomplish their goals.\n\n\nThe how-to section should:\n\nBe problem-oriented: How-to guides should address specific problems or analyses users may face, offering clear and concise solutions. Each guide should focus on a single issue, making it easy for users to find and apply the relevant information.\nOffer step-by-step instructions: Similar to tutorials, how-to guides should provide a clear sequence of steps that users can follow to solve their problem or complete their analysis. Each step of the instructions should be explained in a straightforward manner.\nBe concise: How-to guides should be to the point, offering just enough information to help users accomplish their goal. This means avoiding unnecessary explanations or background information, as users are typically looking for a quick solution.\nBe actionable: The content in the how-to section should be practical, with a focus on actionable advice that users can apply immediately. This may involve providing code snippets, configuration settings, or other specific instructions that users can implement in their projects.\nInclude examples: How-to guides should include relevant examples that demonstrate the solution in action, allowing users to see how the instructions can be applied in a real-world context.\nCross-reference other resources: How-to guides should link to other relevant documentation, such as explanations or reference material, for users who may require additional background information or a deeper understanding of the topic.\n\n\nFor additional information, see [https://documentation.divio.com/]"
  },
  {
    "objectID": "howto.html#what-are-how-tos",
    "href": "howto.html#what-are-how-tos",
    "title": "How-To’s: A Brief Overview",
    "section": "",
    "text": "The primary goal of the “how-to” section is on providing practical solutions to specific methods or analytic problems users might encounter. Unlike tutorials, which aim to teach a concept, how-to guides concentrate on the efficient execution of specific analyses without going into in-depth background explanations. By following these principles, the how-to section aims to create practical, efficient, and user-friendly guides that help users quickly identify solutions and accomplish their goals.\n\n\nThe how-to section should:\n\nBe problem-oriented: How-to guides should address specific problems or analyses users may face, offering clear and concise solutions. Each guide should focus on a single issue, making it easy for users to find and apply the relevant information.\nOffer step-by-step instructions: Similar to tutorials, how-to guides should provide a clear sequence of steps that users can follow to solve their problem or complete their analysis. Each step of the instructions should be explained in a straightforward manner.\nBe concise: How-to guides should be to the point, offering just enough information to help users accomplish their goal. This means avoiding unnecessary explanations or background information, as users are typically looking for a quick solution.\nBe actionable: The content in the how-to section should be practical, with a focus on actionable advice that users can apply immediately. This may involve providing code snippets, configuration settings, or other specific instructions that users can implement in their projects.\nInclude examples: How-to guides should include relevant examples that demonstrate the solution in action, allowing users to see how the instructions can be applied in a real-world context.\nCross-reference other resources: How-to guides should link to other relevant documentation, such as explanations or reference material, for users who may require additional background information or a deeper understanding of the topic.\n\n\nFor additional information, see [https://documentation.divio.com/]"
  },
  {
    "objectID": "ListofReferences.html",
    "href": "ListofReferences.html",
    "title": "List of Reference Material",
    "section": "",
    "text": "A flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution.{#sec-glm}"
  },
  {
    "objectID": "ListofReferences.html#generalized-linear-model-glm",
    "href": "ListofReferences.html#generalized-linear-model-glm",
    "title": "List of Reference Material",
    "section": "",
    "text": "A flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution.{#sec-glm}"
  },
  {
    "objectID": "ListofReferences.html#non-independence",
    "href": "ListofReferences.html#non-independence",
    "title": "List of Reference Material",
    "section": "Non-independence:",
    "text": "Non-independence:\nThe situation where observations are not statistically independent, often arising in longitudinal or clustered data."
  },
  {
    "objectID": "ListofReferences.html#sample-average-of-differences",
    "href": "ListofReferences.html#sample-average-of-differences",
    "title": "List of Reference Material",
    "section": "Sample average of differences:",
    "text": "Sample average of differences:\nThe mean of the differences between paired observations, typically used in paired-sample designs to assess the average change between two time points or conditions."
  },
  {
    "objectID": "ListofReferences.html#fixed-effects",
    "href": "ListofReferences.html#fixed-effects",
    "title": "List of Reference Material",
    "section": "Fixed effects:",
    "text": "Fixed effects:\nEffects in a statistical model that are constant across all observations, representing the average relationship between predictors and the outcome variable."
  },
  {
    "objectID": "ListofReferences.html#random-effects",
    "href": "ListofReferences.html#random-effects",
    "title": "List of Reference Material",
    "section": "Random effects:",
    "text": "Random effects:\nEffects in a statistical model that vary across different levels of a grouping factor (e.g., subjects, clusters), capturing the variability within each level."
  },
  {
    "objectID": "ListofReferences.html#hierarchical-data-structures",
    "href": "ListofReferences.html#hierarchical-data-structures",
    "title": "List of Reference Material",
    "section": "Hierarchical data structures:",
    "text": "Hierarchical data structures:\nData structures where observations are nested within higher-order units (e.g., students within schools, employees within companies), resulting in dependency among observations."
  },
  {
    "objectID": "ListofReferences.html#within-subject-correlations",
    "href": "ListofReferences.html#within-subject-correlations",
    "title": "List of Reference Material",
    "section": "Within-subject correlations:",
    "text": "Within-subject correlations:\nCorrelations between repeated measurements on the same subject or unit, often present in longitudinal or clustered data."
  },
  {
    "objectID": "ListofReferences.html#model-fit-indices",
    "href": "ListofReferences.html#model-fit-indices",
    "title": "List of Reference Material",
    "section": "Model fit indices:",
    "text": "Model fit indices:\nQuantitative measures used to assess how well a statistical model fits the data, such as R-squared, AIC, or BIC."
  },
  {
    "objectID": "ListofReferences.html#nonparametric",
    "href": "ListofReferences.html#nonparametric",
    "title": "List of Reference Material",
    "section": "Nonparametric:",
    "text": "Nonparametric:\nStatistical methods that do not rely on assumptions about the underlying distribution of the data."
  },
  {
    "objectID": "ListofReferences.html#resampling-permutation-method",
    "href": "ListofReferences.html#resampling-permutation-method",
    "title": "List of Reference Material",
    "section": "Resampling permutation method:",
    "text": "Resampling permutation method:\nA nonparametric method for hypothesis testing that involves randomly rearranging the observed data to create new samples and assess the probability of the observed test statistic under the null hypothesis."
  },
  {
    "objectID": "ListofReferences.html#clustered-data",
    "href": "ListofReferences.html#clustered-data",
    "title": "List of Reference Material",
    "section": "Clustered data:",
    "text": "Clustered data:\nData where observations are grouped or clustered within higher-order units, resulting in dependency among observations within each cluster."
  },
  {
    "objectID": "ListofReferences.html#population-averaged-effects",
    "href": "ListofReferences.html#population-averaged-effects",
    "title": "List of Reference Material",
    "section": "Population-averaged effects:",
    "text": "Population-averaged effects:\nEffects in a statistical model that represent the average relationship between predictors and the outcome variable across the entire population, rather than for specific levels of a grouping factor."
  },
  {
    "objectID": "ListofReferences.html#identity-link",
    "href": "ListofReferences.html#identity-link",
    "title": "List of Reference Material",
    "section": "Identity link:",
    "text": "Identity link:\nA link function in GLMs that relates the linear predictor to the expected value of the outcome variable without any transformation (E[Y] = Xβ)."
  },
  {
    "objectID": "ListofReferences.html#logit-link",
    "href": "ListofReferences.html#logit-link",
    "title": "List of Reference Material",
    "section": "Logit link:",
    "text": "Logit link:\nA link function in GLMs used for binary outcomes, relating the linear predictor to the log-odds of the outcome variable (log(E[Y]/(1-E[Y])) = Xβ)."
  },
  {
    "objectID": "ListofReferences.html#log-link",
    "href": "ListofReferences.html#log-link",
    "title": "List of Reference Material",
    "section": "Log link:",
    "text": "Log link:\nA link function in GLMs used for count outcomes, relating the linear predictor to the natural logarithm of the expected value of the outcome variable (log(E[Y]) = Xβ)."
  },
  {
    "objectID": "ListofReferences.html#logistic-link",
    "href": "ListofReferences.html#logistic-link",
    "title": "List of Reference Material",
    "section": "Logistic link:",
    "text": "Logistic link:\nSynonymous with the logit link."
  },
  {
    "objectID": "ListofReferences.html#binomial-distribution",
    "href": "ListofReferences.html#binomial-distribution",
    "title": "List of Reference Material",
    "section": "Binomial distribution:",
    "text": "Binomial distribution:\nA probability distribution that describes the number of successes in a fixed number of Bernoulli trials with the same probability of success."
  },
  {
    "objectID": "ListofReferences.html#exchangeable-correlation-structure",
    "href": "ListofReferences.html#exchangeable-correlation-structure",
    "title": "List of Reference Material",
    "section": "Exchangeable correlation structure:",
    "text": "Exchangeable correlation structure:\nA working correlation structure in GEE models, assuming constant correlation between any pair of repeated measurements within subjects."
  },
  {
    "objectID": "ListofReferences.html#autoregressive-correlation-structure",
    "href": "ListofReferences.html#autoregressive-correlation-structure",
    "title": "List of Reference Material",
    "section": "Autoregressive correlation structure:",
    "text": "Autoregressive correlation structure:\nA working correlation structure in GEE models, assuming correlation between repeated measurements decreases as the time lag between measurements increases."
  },
  {
    "objectID": "ListofReferences.html#unstructured-correlation-structure",
    "href": "ListofReferences.html#unstructured-correlation-structure",
    "title": "List of Reference Material",
    "section": "Unstructured correlation structure:",
    "text": "Unstructured correlation structure:\nA working correlation structure in GEE models, allowing for different correlations between each pair of repeated measurements within subjects."
  },
  {
    "objectID": "ListofReferences.html#sandwich-estimator",
    "href": "ListofReferences.html#sandwich-estimator",
    "title": "List of Reference Material",
    "section": "Sandwich estimator:",
    "text": "Sandwich estimator:\nA method for computing robust standard errors in GEE models, providing valid inference even if the working correlation structure is misspecified."
  },
  {
    "objectID": "ListofReferences.html#quasi-likelihood-under-the-independence-model-criterion-qic",
    "href": "ListofReferences.html#quasi-likelihood-under-the-independence-model-criterion-qic",
    "title": "List of Reference Material",
    "section": "Quasi-likelihood under the Independence model Criterion (QIC):",
    "text": "Quasi-likelihood under the Independence model Criterion (QIC):\nA model selection criterion for GEE models, analogous to AIC, used to compare models with different working correlation structures."
  },
  {
    "objectID": "ListofReferences.html#odds-ratios",
    "href": "ListofReferences.html#odds-ratios",
    "title": "List of Reference Material",
    "section": "Odds ratios:",
    "text": "Odds ratios:\nA measure of association for binary outcomes, representing the ratio of the odds of an event occurring in one group to the odds in another group."
  },
  {
    "objectID": "ListofReferences.html#rate-ratios",
    "href": "ListofReferences.html#rate-ratios",
    "title": "List of Reference Material",
    "section": "Rate ratios:",
    "text": "Rate ratios:\nA measure of association for count outcomes, representing the ratio of the rates of an event occurring in one group to the rates in another group."
  },
  {
    "objectID": "ListofReferences.html#maximum-likelihood-estimation",
    "href": "ListofReferences.html#maximum-likelihood-estimation",
    "title": "List of Reference Material",
    "section": "Maximum likelihood estimation:",
    "text": "Maximum likelihood estimation:\nA statistical method for estimating model parameters by finding the values that maximize the likelihood of the observed data given the model."
  },
  {
    "objectID": "ListofReferences.html#unbalanced-data",
    "href": "ListofReferences.html#unbalanced-data",
    "title": "List of Reference Material",
    "section": "Unbalanced data:",
    "text": "Unbalanced data:\nData where the number of observations or the number of measurements per subject or group is unequal across subjects or groups."
  },
  {
    "objectID": "ListofReferences.html#unequally-spaced-data",
    "href": "ListofReferences.html#unequally-spaced-data",
    "title": "List of Reference Material",
    "section": "Unequally spaced data:",
    "text": "Unequally spaced data:\nData where the time intervals between repeated measurements or the spacing of observations are not equal."
  },
  {
    "objectID": "ListofReferences.html#maximum-likelihood-ml",
    "href": "ListofReferences.html#maximum-likelihood-ml",
    "title": "List of Reference Material",
    "section": "Maximum likelihood (ML):",
    "text": "Maximum likelihood (ML):\nA method of estimation that involves finding the parameter values that maximize the likelihood of the observed data given a statistical model."
  },
  {
    "objectID": "ListofReferences.html#restricted-maximum-likelihood-reml",
    "href": "ListofReferences.html#restricted-maximum-likelihood-reml",
    "title": "List of Reference Material",
    "section": "Restricted maximum likelihood (REML):",
    "text": "Restricted maximum likelihood (REML):\nA modification of maximum likelihood estimation that is less biased for estimating variance components in mixed-effects models, particularly when the sample size is small."
  },
  {
    "objectID": "ListofReferences.html#penalized-quasi-likelihood-pql",
    "href": "ListofReferences.html#penalized-quasi-likelihood-pql",
    "title": "List of Reference Material",
    "section": "Penalized quasi-likelihood (PQL):",
    "text": "Penalized quasi-likelihood (PQL):\nAn approximate method for fitting generalized linear mixed models, particularly for non-normal outcomes, which involves a penalized likelihood function and iteratively weighted least squares."
  },
  {
    "objectID": "ListofReferences.html#akaike-information-criterion-aic",
    "href": "ListofReferences.html#akaike-information-criterion-aic",
    "title": "List of Reference Material",
    "section": "Akaike Information Criterion (AIC):",
    "text": "Akaike Information Criterion (AIC):\nA model selection criterion that balances goodness-of-fit and model complexity, calculated as AIC = -2 * log-likelihood + 2 * k, where k is the number of parameters. Lower AIC values indicate better model fit."
  },
  {
    "objectID": "ListofReferences.html#bayesian-information-criterion-bic",
    "href": "ListofReferences.html#bayesian-information-criterion-bic",
    "title": "List of Reference Material",
    "section": "Bayesian Information Criterion (BIC):",
    "text": "Bayesian Information Criterion (BIC):\nA model selection criterion that balances goodness-of-fit and model complexity, calculated as BIC = -2 * log-likelihood + k * log(n), where k is the number of parameters and n is the sample size. Lower BIC values indicate better model fit."
  },
  {
    "objectID": "12_HowTos_LatentTransitionAnalysis.html",
    "href": "12_HowTos_LatentTransitionAnalysis.html",
    "title": "Latent Transition Analysis",
    "section": "",
    "text": "test page for lta howtos"
  },
  {
    "objectID": "temp.html",
    "href": "temp.html",
    "title": "Tutorials: A Brief Overview",
    "section": "",
    "text": "LPA Structure"
  },
  {
    "objectID": "temp.html#section-iii",
    "href": "temp.html#section-iii",
    "title": "Tutorials: A Brief Overview",
    "section": "Section III",
    "text": "Section III\nSection focused on different ways of considering/grouping/deciding on which specific analysis to choose (see curran&bauer slides)\n\nSteps\n\nupdate manuscript text\nsection order via yaml file\ncall out boxes\n\n 2 call out blocks/boxes to emphasize main sections of parts II (e.g., vulnerable periods, experience effects) and III (e.g., # of time points, types of stability and change). Help to add some visuals to first sections of manuscript \nxxxxxxxxxxx Traditional Models -Linear - Difference Scores - Change Scores -Non-Linear - Signed-Rank test - Generalized Estimating Equations\nModern Approaches -Linear - Linear Mixed Models -Non-Linear - Generalized Linear Mixed Models\nSEM - Variable-Centered - Autoregressive Crosslagged Panel Model - Latent Change Score - Latent Growth Curve Models - Multivariate Latent Growth Curve Models - State-Trait Models - Person-Centered - Latent Transition Analysis - Latent Class Growth Analysis - Hybrid - Growth Mixture Model\nAdvanced SEM - Random-Intercept Crosslagged Panel Model - Latent Curve Model with Structured Residuals\nLongitudinal Twin Designs/Genetic Models\nLongitudinal Neuroimaging\nxxxxxxxxxx\n\nTraditional Models -Linear - Difference Scores - Change Scores -Non-Linear - Signed-Rank test - Generalized Estimating Equations\nxxxxxxxxx - title: “Tutorials” contents: - tutorials.qmd - section: “Traditional Models” contents: - 1_Tutorials_DifferenceScores.qmd - 2_Tutorials_ResidualizedChangeScores.qmd - 3_Tutorials_LinearMixedModels.qmd - section: “Traditional Non-linear Models” contents: - 4_Tutorials_SignedRankTest.qmd - 5_Tutorials_MarginalModels.qmd - 6_Tutorials_GeneralizedEstimatingEquations.qmd - 7_Tutorials_GeneralizedLinearMixedEffectsModels.qmd - section: “SEM Approaches” contents: - 8_Tutorials_AutoregressiveCrosslaggedPanelModels.qmd - 9_Tutorials_LatentChangeScoresModels.qmd - 10_Tutorials_LatentGrowthCurveModels.qmd - 11_Tutorials_MultivariateLatentGrowthCurveModels.qmd - 12_Tutorials_LatentTransitionAnalysis.qmd - 13_Tutorials_GrowthMixtureModels.qmd - 14_Tutorials_StateTraitModels.qmd - section: “Advanced SEM” contents: - 15_Tutorials_RandomInterceptCrosslaggedPanelModels.qmd - 16_Tutorials_LatentCurveModelsStructuredResiduals.qmd - section: “Longitudinal Neuroimaging” contents: - blank.qmd - section: “Twin Modeling & Genetics Designs” contents: - blank.qmd - section: “Data Wrangling” contents: - blank.qmd - title: “How-To” contents: - howto.qmd - section: “Traditional Linear Models” contents: - section: “Difference Scores” contents: - 1a_HowTos_DifferenceScores_PairedTtests.qmd - 1b_HowTos_DifferenceScores_SimpleRegression.qmd - section: “Residualized Change Scores” contents: - 2_HowTos_ResidualizedChangeScores.qmd - section: “Linear Mixed Models” contents: - 3a_HowTos_LinearMixedModels.qmd - 3b_HowTos_LinearMixedModels.qmd - section: “Traditional Non-linear Models” contents: - section: “Signed-Rank Test” contents: - 4_HowTos_SignedRankTest.qmd - section: “Marginal Models” contents: - 5_HowTos_MarginalModels.qmd - section: “Generalized Estimating Equations” contents: - 6_HowTos_GeneralizedEstimatingEquations.qmd - section: “Generalized Linear Mixed-Effects Models” contents: - 7_HowTos_GeneralizedLinearMixedEffectsModels.qmd - section: “SEM Approaches” contents: - section: “Autoregressive Crosslagged Panel Models” contents: - 8_HowTos_AutoregressiveCrosslaggedPanelModels.qmd - section: “Latent Change Scores Models” contents: - 9_HowTos_LatentChangeScoresModels.qmd - section: “LatentGrowthCurveModels” contents: - 10_HowTos_LatentGrowthCurveModels.qmd - section: “Multivariate Latent Growth Curve Models” contents: - 11_HowTos_MultivariateLatentGrowthCurveModels.qmd - section: “Latent Transition Analysis” contents: - 12_HowTos_LatentTransitionAnalysis.qmd - section: “Growth Mixture Models” contents: - 13_HowTos_GrowthMixtureModels.qmd - section: “State-Trait Models” contents: - 14_HowTos_StateTraitModels.qmd - section: “Advanced SEM” contents: - 15_HowTos_RandomInterceptCrosslaggedPanelModels.qmd - 16_HowTos_LatentCurveModelsStructuredResiduals.qmd - section: “Longitudinal Neuroimaging” contents: - blank.qmd - section: “Twin Modeling & Genetics Designs” contents: - blank.qmd - section: “Data Wrangling” contents: - blank.qmd # navigation items - title: “Explanations” contents: - explanations.qmd - section: “Traditional Linear Models” contents: - 1_Explanations_DifferenceScores.qmd - 2_Explanations_ResidualizedChangeScores.qmd - 3_Explanations_LinearMixedModels.qmd - section: “Traditional Non-linear Models” contents: - 4_Explanations_SignedRankTest.qmd - 5_Explanations_MarginalModels.qmd - 6_Explanations_GeneralizedEstimatingEquations.qmd - 7_Explanations_GeneralizedLinearMixedEffectsModels.qmd - section: “SEM Approaches” contents: - 8_Explanations_AutoregressiveCrosslaggedPanelModels.qmd - 9_Explanations_LatentChangeScoresModels.qmd - 10_Explanations_LatentGrowthCurveModels.qmd - 11_Explanations_MultivariateLatentGrowthCurveModels.qmd - 12_Explanations_LatentTransitionAnalysis.qmd - 13_Explanations_GrowthMixtureModels.qmd - 14_Explanations_StateTraitModels.qmd - section: “Advanced SEM” contents: - 15_Explanations_RandomInterceptCrosslaggedPanelModels.qmd - 16_Explanations_LatentCurveModelsStructuredResiduals.qmd - section: “Longitudinal Neuroimaging” contents: - blank.qmd - section: “Twin Modeling & Genetics Designs” contents: - blank.qmd - section: “Data Wrangling” contents: - blank.qmd # navigation items\n- title: \"Reference\"\n  contents:\n    - reference.qmd\n    - section: \"List of Reference Material\"\n      contents:\n        - ListofReferences.qmd\n\n- title: \"Documentation\"\n  contents:\n    - documentation.qmd\nxxxxxxxxxxx\n\n\n\ntest\n\n\nxxx\n\nFruit prices\n\n\nfruit\nprice\n\n\n\n\napple\n2.05\n\n\npear\n1.37\n\n\norange\n3.09\n\n\n\nxxx\nxxx\n\n\nCode\nlibrary(leaflet)\nleaflet() %&gt;%\n  addTiles() %&gt;%  # Add default OpenStreetMap map tiles\n  addMarkers(lng=-77.0168, lat=38.7814, popup=\"You are here - in Maryland!\")\n\n\n\n\n\n\nxxx\n\n\nCode\n%%| fig-width: 6.5\n%%| fig-height: 6.5\n\ngraph TB\nA[LDA Structures] \nA -.-&gt; |Focus on if & when an event occurs| B[Time-to-Event]\nB -.-&gt; C[Continuous-Time &lt;br/&gt;Survival Analysis]\nB -.-&gt; D[Discrete-Time &lt;br/&gt;Survival Analysis]\nA --&gt;|Focus on Change & Growth| E[Repeated Measures]\nE -.-&gt; F[Time-Series &lt;br/&gt; Models]\nE -.-&gt; G[Intensive &lt;br/&gt; Longitudinal Data]\nE --&gt; H[Longitudinal Panel Data]\nH --Traditional Models--&gt; J[Mean-level change & Marginal models]\nH --Contemporary  Methods--&gt; I[Within-person change & Random-effects models]\n\nJ --&gt; K[ANOVA &lt;br/&gt; Generalized Estimating Equations &lt;br/&gt; ... ]\nI --&gt; L[Mixed Models &lt;br/&gt; Growth Curves &lt;br/&gt; ...]\n\nclick A href \"https://www.github.com\" \"This is a link\"\nclick B href \"https://www.github.com\" \"This is a link\"\nclick C href \"https://www.github.com\" \"This is a link\"\nclick D href \"https://www.github.com\" \"This is a link\"\n\nstyle A fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle E fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle B fill:floralwhite,stroke:black\nstyle C fill:floralwhite,stroke:black\nstyle D fill:floralwhite,stroke:black\nstyle F fill:floralwhite,stroke:black\nstyle G fill:floralwhite,stroke:black\n\nstyle H fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle J fill:blue,stroke:#333,stroke-width:2px,color:#fff\nstyle I fill:blue,stroke:#333,stroke-width:2px,color:#fff\nstyle K fill:blue,stroke:#333,stroke-width:2px,color:#fff,text-align:center\nstyle L fill:blue,stroke:#333,stroke-width:2px,color:#fff,text-align:center\n\n\n\n\n%%| fig-width: 6.5\n%%| fig-height: 6.5\n\ngraph TB\nA[LDA Structures] \nA -.-&gt; |Focus on if & when an event occurs| B[Time-to-Event]\nB -.-&gt; C[Continuous-Time &lt;br/&gt;Survival Analysis]\nB -.-&gt; D[Discrete-Time &lt;br/&gt;Survival Analysis]\nA --&gt;|Focus on Change & Growth| E[Repeated Measures]\nE -.-&gt; F[Time-Series &lt;br/&gt; Models]\nE -.-&gt; G[Intensive &lt;br/&gt; Longitudinal Data]\nE --&gt; H[Longitudinal Panel Data]\nH --Traditional Models--&gt; J[Mean-level change & Marginal models]\nH --Contemporary  Methods--&gt; I[Within-person change & Random-effects models]\n\nJ --&gt; K[ANOVA &lt;br/&gt; Generalized Estimating Equations &lt;br/&gt; ... ]\nI --&gt; L[Mixed Models &lt;br/&gt; Growth Curves &lt;br/&gt; ...]\n\nclick A href \"https://www.github.com\" \"This is a link\"\nclick B href \"https://www.github.com\" \"This is a link\"\nclick C href \"https://www.github.com\" \"This is a link\"\nclick D href \"https://www.github.com\" \"This is a link\"\n\nstyle A fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle E fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle B fill:floralwhite,stroke:black\nstyle C fill:floralwhite,stroke:black\nstyle D fill:floralwhite,stroke:black\nstyle F fill:floralwhite,stroke:black\nstyle G fill:floralwhite,stroke:black\n\nstyle H fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle J fill:blue,stroke:#333,stroke-width:2px,color:#fff\nstyle I fill:blue,stroke:#333,stroke-width:2px,color:#fff\nstyle K fill:blue,stroke:#333,stroke-width:2px,color:#fff,text-align:center\nstyle L fill:blue,stroke:#333,stroke-width:2px,color:#fff,text-align:center\n\n\n\n\n\n\n (remove marginal models from “examples” address (vs random-effects) in the manuscript)\n\nsection: “Traditional Linear Models” contents: - 1_Tutorials_DifferenceScores.qmd - 2_Tutorials_ResidualizedChangeScores.qmd - section: “Traditional Non-linear Models” contents: - 4_Tutorials_SignedRankTest.qmd - 6_Tutorials_GeneralizedEstimatingEquations.qmd (population average effects) - section: “Modern GLM Extensions(?)” - 7_Tutorials_LinearMixedModels.qmd\n\n\n8_Tutorials_GeneralizedLinearMixedEffectsModels.qmd - section: “SEM Approaches” contents: - 8_Tutorials_AutoregressiveCrosslaggedPanelModels.qmd - 9_Tutorials_LatentChangeScoresModels.qmd - 10_Tutorials_LatentGrowthCurveModels.qmd - 11_Tutorials_MultivariateLatentGrowthCurveModels.qmd - 12_Tutorials_LatentTransitionAnalysis.qmd - 13_Tutorials_GrowthMixtureModels.qmd - 14_Tutorials_StateTraitModels.qmd - section: “Advanced SEM” contents: - 15_Tutorials_RandomInterceptCrosslaggedPanelModels.qmd - 16_Tutorials_LatentCurveModelsStructuredResiduals.qmd\n\n\nGEE, on the other hand, is fitting a marginal model. These model population-averages. You’re modeling the expectation conditional only on your fixed design matrix. GLMM is fitting a mixed-effects model; Thus the the estimates are subject-specific. What differs between GEE and GLMM is the target of inference: population-average or subject-specific.\nThis is in contrast to mixed effect models as explained above which condition on both the fixed design matrix and the random effects. So with the marginal model above you’re saying, “forget about the difference among classrooms, I just want the population (school-wise) rate of failure and its association with gender.” You fit the model and get an odds ratio that is the population-averaged odds ratio of failure associated with gender.\nMolenberghs, Verbeke 2005 has an entire chapter on marginal vs. random effects models.\nxxxxxx\n\n\nModels for the analysis of longitudinal data\n\n\n\n\n\n\n\n\n\nModels\nForm of Change\nMinimum # of Timepoints\nVariable-Centered vs Person-Centered\nTime-varying Covariates\n\n\nDifference Scores\nmean-level\n2+\n-\nnone\n\n\nChange Scores\nrank-order\n2+\n-\nnone\n\n\nSigned-Rank Test\nrank-order\n2+\n-\nnone\n\n\nGeneralized Estimating Equations\nrank-order\n2+\n-\nallowed\n\n\nLinear Mixed Models\nwithin and between\n3+\nVariable-Centered\nallowed\n\n\nGeneralized Linear Mixed-Effects Models\nwithin and between\n3+\n\nallowed\n\n\nAutoregressive Crosslagged Panel Models\nrank-order\n3+\nVariable-Centered\nallowed\n\n\nLatent Change Scores Models\nrank-order\n2+\nVariable-Centered\nallowed\n\n\nLatent Growth Curve Models\nwithin and between\n3+\nVariable-Centered\nallowed\n\n\nMultivariate Latent Growth Curve Model\nwithin and between\n3+\nVariable-Centered\nallowed\n\n\nLatent Transition Analysis\nwithin and between\n3+\nMixed\nallowed\n\n\nLatent Class Growth Analysis\nwithin and between\n3+\nPerson-Centered\nallowed\n\n\nGrowth Mixture Models\nwithin and between\n3+\nMixed\nallowed\n\n\nState-Trait Models\ncontinuous and discrete\n3+\nVariable-Centered\nallowed\n\n\nRandom-Intercept Crosslagged Panel Models\nwithin and between\n4+\nVariable-Centered\nallowed\n\n\nLatent Curve Models Structured Residuals\nwithin and between\n4+\nVariable-Centered\nallowed\n\n\n\n\n\n\n\n\n\n\n\nxxxxxx\n\nModels for Longitudinal Data Since both the GLMM and WGEE are extensions of the GLM, we start with a brief overview of the latter.\n\n2.1 Generalized Linear Models (GLM)\nLMM vs LGCM? For modeling growth, researchers typically employ some type of random effects model such that a mean growth trajectory is estimated for all observations in the data but a unique growth curve is estimated for each individual in the data as well (Curran & Bauer, 2011). These types of models are generally referred to as subject-specific models (Zeger, Liang, & Albert, 1988), which are more commonly known in psychology as growth curve models. Growth models have many aliases but can be broadly grouped into two different classes of methods: the latent-curve (LC) approach, which treats the repeated measures as multivariate (also known as the “wide” data format) and tends to be fit with general structural equation modeling (SEM) software (Meredith & Tisak, 1990; Tucker, 1958; Willett & Sayer, 1994), and the mixed-effect (ME) approach, which treats the repeated measures as univariate (also known as the “long” data format) and is generally fitted with regression software (Bryk & Raudenbush, 1987; Laird & Ware, 1982; Rao 1965).Footnote1\nOver the past 20 years, methodological research has shown that the LC and ME approaches are actually nuanced twists on the same idea; they have been shown to converge, and to be mathematically equivalent in many cases (e.g., Bauer, 2003; Curran, 2003; Ledermann & Kenny, 2017; Mehta & Neale, 2005).\n\n\n\n\nFigmaLandingTest2\n\n\n\nxxxxx It is important to match a theory of change with design and statistical model to assess change. (p. 4) Models with two time points cannot provide estimates of within-person change. “Stability” over time can reflect many things, only some of which mean a lack of change. (p. 14) It is helpful to describe not only average growth (e.g. intercept and slope means), but variances in the growth parameters. (p. 25)\nModels that focus exclusively on mean-level change sometimes called Marginal Models Those that emphasize individual change often do so through inclusion of Random Effects often called “growth models”\nxxxxx\n\n\nCode\nmindmap\n  root((mindmap))\n    Origins\n      Long history\n      ::icon(fa fa-book)\n      Popularisation\n        British popular psychology author Tony Buzan\n    Research\n      On effectiveness&lt;br/&gt;and features\n      On Automatic creation\n        Uses\n            Creative techniques\n            Strategic planning\n            Argument mapping\n    Tools\n      Pen and paper\n      Mermaid\n\n\n\n\nmindmap\n  root((mindmap))\n    Origins\n      Long history\n      ::icon(fa fa-book)\n      Popularisation\n        British popular psychology author Tony Buzan\n    Research\n      On effectiveness&lt;br/&gt;and features\n      On Automatic creation\n        Uses\n            Creative techniques\n            Strategic planning\n            Argument mapping\n    Tools\n      Pen and paper\n      Mermaid\n\n\n\n\n\n\nxxxxx\nLongitudinal Psychometrics\nxxxxxx\n\nThis is the middle section\n\n\n\n\n\n\n\nTesting Sample Test!\n\n\n\n\n\n\nThe primary goal of the tutorial section is to help users learn and understand a specific topic or method by providing an introductory and hands-on, step-by-step guide. This section aims to create engaging, accessible, and effective entry learning experiences that enable users to develop their skills and understanding of the subject matter.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is the temporary landing page for the Longitudinal Analysis Project.  The site is currently under construction and used for testing purposes only.  Contents may be inaccurate."
  },
  {
    "objectID": "9_HowTos_LatentChangeScoresModels.html",
    "href": "9_HowTos_LatentChangeScoresModels.html",
    "title": "Latent Change Score Models",
    "section": "",
    "text": "test page for lcs models how tos"
  },
  {
    "objectID": "figures/Code for LDA Structure Mermaid Diagram.html",
    "href": "figures/Code for LDA Structure Mermaid Diagram.html",
    "title": "Code for LDA Structure Mermaid Diagram",
    "section": "",
    "text": "Code\n%%| echo: false\n%%| fig-width: 3\n%%| fig-height: 3\n\ngraph TB\nA[LDA Structures] \nA -.-&gt; |Focus on if & when an event occurs| B[Time-to-Event]\nB -.-&gt; C[Continuous-Time &lt;br/&gt;Survival Analysis]\nB -.-&gt; D[Discrete-Time &lt;br/&gt;Survival Analysis]\nA --&gt;|Focus on Change & Growth| E[Repeated Measures]\nE -.-&gt; F[Time-Series &lt;br/&gt; Models]\nE -.-&gt; G[Intensive &lt;br/&gt; Longitudinal Data]\nE --&gt; H[Longitudinal Panel Data]\nH --Traditional Models--&gt; J[Mean-level change & Marginal models]\nH --Contemporary  Methods--&gt; I[Within-person change & Random-effects models]\n\nJ --&gt; K[ANOVA &lt;br/&gt; Generalized Estimating Equations &lt;br/&gt; ... ]\nI --&gt; L[Mixed Models &lt;br/&gt; Growth Curves &lt;br/&gt; ...]\n\nclick A href \"https://www.github.com\" \"This is a link\"\nclick B href \"https://www.github.com\" \"This is a link\"\nclick C href \"https://www.github.com\" \"This is a link\"\nclick D href \"https://www.github.com\" \"This is a link\"\n\nstyle A fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle E fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle B fill:floralwhite,stroke:black\nstyle C fill:floralwhite,stroke:black\nstyle D fill:floralwhite,stroke:black\nstyle F fill:floralwhite,stroke:black\nstyle G fill:floralwhite,stroke:black\n\nstyle H fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle J fill:blue,stroke:#333,stroke-width:2px,color:#fff\nstyle I fill:blue,stroke:#333,stroke-width:2px,color:#fff\nstyle K fill:blue,stroke:#333,stroke-width:2px,color:#fff,text-align:center\nstyle L fill:blue,stroke:#333,stroke-width:2px,color:#fff,text-align:center\n\n\n\n\n%%| echo: false\n%%| fig-width: 3\n%%| fig-height: 3\n\ngraph TB\nA[LDA Structures] \nA -.-&gt; |Focus on if & when an event occurs| B[Time-to-Event]\nB -.-&gt; C[Continuous-Time &lt;br/&gt;Survival Analysis]\nB -.-&gt; D[Discrete-Time &lt;br/&gt;Survival Analysis]\nA --&gt;|Focus on Change & Growth| E[Repeated Measures]\nE -.-&gt; F[Time-Series &lt;br/&gt; Models]\nE -.-&gt; G[Intensive &lt;br/&gt; Longitudinal Data]\nE --&gt; H[Longitudinal Panel Data]\nH --Traditional Models--&gt; J[Mean-level change & Marginal models]\nH --Contemporary  Methods--&gt; I[Within-person change & Random-effects models]\n\nJ --&gt; K[ANOVA &lt;br/&gt; Generalized Estimating Equations &lt;br/&gt; ... ]\nI --&gt; L[Mixed Models &lt;br/&gt; Growth Curves &lt;br/&gt; ...]\n\nclick A href \"https://www.github.com\" \"This is a link\"\nclick B href \"https://www.github.com\" \"This is a link\"\nclick C href \"https://www.github.com\" \"This is a link\"\nclick D href \"https://www.github.com\" \"This is a link\"\n\nstyle A fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle E fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle B fill:floralwhite,stroke:black\nstyle C fill:floralwhite,stroke:black\nstyle D fill:floralwhite,stroke:black\nstyle F fill:floralwhite,stroke:black\nstyle G fill:floralwhite,stroke:black\n\nstyle H fill:blue,stroke:#333,stroke-width:4px,color:#fff\nstyle J fill:blue,stroke:#333,stroke-width:2px,color:#fff\nstyle I fill:blue,stroke:#333,stroke-width:2px,color:#fff\nstyle K fill:blue,stroke:#333,stroke-width:2px,color:#fff,text-align:center\nstyle L fill:blue,stroke:#333,stroke-width:2px,color:#fff,text-align:center"
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials: A Brief Overview",
    "section": "",
    "text": "The primary goal of the tutorial section is to help users learn and understand a specific topic or method by providing an introductory and hands-on, step-by-step guide. This section aims to create engaging, accessible, and effective entry learning experiences that enable users to develop their skills and understanding of the subject matter.\n\n\nThe tutorial section should:\n\nBe goal-oriented: Tutorials should focus on a specific task the user wants to accomplish. By concentrating on a particular outcome, the tutorial becomes more engaging and relevant to the user.\nProvide clear steps: Tutorials should offer step-by-step instructions, guiding users through the process of achieving their goal. Each step should be clearly explained and easy to follow, making sure users can successfully complete the tutorial.\nUse examples: Tutorials should include real-world examples and use cases that are relatable and meaningful to the user. This helps users better understand the concepts being taught and how they can apply them in their own projects.\nBe practical: Tutorials should emphasize hands-on learning, encouraging users to actively engage with the content and practice the skills they are learning. This may involve providing code samples, interactive exercises, or other activities that help users develop their understanding.\nEncourage exploration: Tutorials should encourage users to explore and experiment with the concepts they are learning. This may involve providing opportunities for users to adapt the tutorial to their own needs or offering suggestions for further experimentation.\n\n\nFor additional information, see [https://documentation.divio.com/]"
  },
  {
    "objectID": "tutorials.html#what-are-tutorials",
    "href": "tutorials.html#what-are-tutorials",
    "title": "Tutorials: A Brief Overview",
    "section": "",
    "text": "The primary goal of the tutorial section is to help users learn and understand a specific topic or method by providing an introductory and hands-on, step-by-step guide. This section aims to create engaging, accessible, and effective entry learning experiences that enable users to develop their skills and understanding of the subject matter.\n\n\nThe tutorial section should:\n\nBe goal-oriented: Tutorials should focus on a specific task the user wants to accomplish. By concentrating on a particular outcome, the tutorial becomes more engaging and relevant to the user.\nProvide clear steps: Tutorials should offer step-by-step instructions, guiding users through the process of achieving their goal. Each step should be clearly explained and easy to follow, making sure users can successfully complete the tutorial.\nUse examples: Tutorials should include real-world examples and use cases that are relatable and meaningful to the user. This helps users better understand the concepts being taught and how they can apply them in their own projects.\nBe practical: Tutorials should emphasize hands-on learning, encouraging users to actively engage with the content and practice the skills they are learning. This may involve providing code samples, interactive exercises, or other activities that help users develop their understanding.\nEncourage exploration: Tutorials should encourage users to explore and experiment with the concepts they are learning. This may involve providing opportunities for users to adapt the tutorial to their own needs or offering suggestions for further experimentation.\n\n\nFor additional information, see [https://documentation.divio.com/]"
  },
  {
    "objectID": "manuscript.html",
    "href": "manuscript.html",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "The Adolescent Brain Cognitive Development (ABCD) Study® is the largest long-term investigation of neurodevelopment and child health in the United States. Conceived and initiated by the National Institutes of Health (NIH), this landmark prospective longitudinal study aims to transform our understanding of the genetic and environmental influences on brain development and their roles in behavioral and health outcomes in adolescents (Volkow et al. 2018). At its heart, the study is designed to chart the course of human development across multiple, interacting domains from late childhood to early adulthood and to identify factors that lead to both positive and negative developmental outcomes. Central to achieving these goals is the ABCD Study’s® commitment to an open science framework designed to facilitate access to and sharing of scientific knowledge by espousing practices that increase openness, integrity, and reproducibility of scientific research (e.g., public data releases). In this sense, the ABCD Study® is a collaboration with the larger research community, with the rich longitudinal nature of the ABCD Study dataset allowing researchers to perform a variety of analyses of both methodological and substantive interest. Together, this presents a unique opportunity to significantly advance our understanding of how a multitude of biopsychosocial processes emerge and unfold across critical periods of development.\n[section still be developed…]\n\n\nParticipants enrolled in the ABCD Study include a large cohort of youth (n=11880) aged 9-10 years at baseline and their parents/guardians. The study sample was recruited from household populations in defined catchment areas for each of the 21 study sites across the United States (information regarding funding agencies, recruitment sites, investigators, and project organization can be obtained at the ABCD Study website). The ABCD Study is collecting longitudinal data on a rich variety of outcomes that will enable the construction of realistically-complex etiological models by incorporating factors from many domains simultaneously. Each new wave of data collection provides the building blocks for conducting probing longitudinal analyses that allow us to characterize normative development, identify variables that presage deviations from prototypic development, and assess a range of outcomes associated with variables of interest. This data includes a neurocognitive battery (Luciana et al. 2018; Thompson et al. 2019), mental and physical health assessments (Barch et al. 2018), measures of culture and environment (Zucker et al. 2018), substance use [add citation], biospecimens (Uban et al. 2018), structural and functional brain imaging (Casey et al. 2018; Hagler et al. 2019), geolocation-based environmental exposure data, wearables, and mobile technology (Bagot et al. 2018), and whole genome genotyping (Loughnan et al. 2020). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual telephone interviews between in-person visits. Data are publicly released on an annual basis through the NIMH Data Archive. By necessity, the study’s earliest data releases were cross-sectional (i.e., the baseline data), however, the most recent public data release (NDA Release 4.0) contains data collected across three annual assessments, including two imaging assessments (baseline and year 2 follow-up visits).\n\n\n\nThe rich longitudinal nature of the ABCD Study dataset will allow researchers to perform analyses of both methodological and substantive interest. This report describes methods for longitudinal analyses of ABCD Study data that can address its fundamental scientific aims, as well as challenges inherent in a large population-based long-term study of adolescents. The manuscript is organized as follows:\n[section still be developed…]"
  },
  {
    "objectID": "manuscript.html#the-abcd-study-data",
    "href": "manuscript.html#the-abcd-study-data",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "Participants enrolled in the ABCD Study include a large cohort of youth (n=11880) aged 9-10 years at baseline and their parents/guardians. The study sample was recruited from household populations in defined catchment areas for each of the 21 study sites across the United States (information regarding funding agencies, recruitment sites, investigators, and project organization can be obtained at the ABCD Study website). The ABCD Study is collecting longitudinal data on a rich variety of outcomes that will enable the construction of realistically-complex etiological models by incorporating factors from many domains simultaneously. Each new wave of data collection provides the building blocks for conducting probing longitudinal analyses that allow us to characterize normative development, identify variables that presage deviations from prototypic development, and assess a range of outcomes associated with variables of interest. This data includes a neurocognitive battery (Luciana et al. 2018; Thompson et al. 2019), mental and physical health assessments (Barch et al. 2018), measures of culture and environment (Zucker et al. 2018), substance use [add citation], biospecimens (Uban et al. 2018), structural and functional brain imaging (Casey et al. 2018; Hagler et al. 2019), geolocation-based environmental exposure data, wearables, and mobile technology (Bagot et al. 2018), and whole genome genotyping (Loughnan et al. 2020). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual telephone interviews between in-person visits. Data are publicly released on an annual basis through the NIMH Data Archive. By necessity, the study’s earliest data releases were cross-sectional (i.e., the baseline data), however, the most recent public data release (NDA Release 4.0) contains data collected across three annual assessments, including two imaging assessments (baseline and year 2 follow-up visits)."
  },
  {
    "objectID": "manuscript.html#organization-of-current-manuscript",
    "href": "manuscript.html#organization-of-current-manuscript",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "The rich longitudinal nature of the ABCD Study dataset will allow researchers to perform analyses of both methodological and substantive interest. This report describes methods for longitudinal analyses of ABCD Study data that can address its fundamental scientific aims, as well as challenges inherent in a large population-based long-term study of adolescents. The manuscript is organized as follows:\n[section still be developed…]"
  },
  {
    "objectID": "manuscript.html#basic-concepts-and-considerations",
    "href": "manuscript.html#basic-concepts-and-considerations",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "2.1 Basic Concepts and Considerations",
    "text": "2.1 Basic Concepts and Considerations\nThere are several important concepts to consider when conducting longitudinal analyses in a developmental context. These include different ways of thinking about developmental course, whether certain periods of development are relatively sensitive or insensitive to various types of insults or stressors, whether some time periods or situations inhibit the expression of individual differences due to extreme environmental pressures, and whether the same behavior manifested at different times represent the same phenomenon or different ones. Further, in the case of developmentally focused longitudinal research, each new measurement occasion not only provides a more extended portrait of the child’s life course (and not just characterize growth during this period but also assesses the durability/chronicity of prior effects/consequences) but also brings with it greater methodological opportunities to exploit the statistical properties of longitudinal data in the furtherance of critical scientific questions. That is, we can ask more nuanced questions and make stronger inferences as our number of time-ordered observations grows, assuming we have assessed the “right” variables and the timings of our observations comport with the temporal dynamics of the mechanisms of interest. Appreciation of these and other issues can help to guide the analysis and interpretation of data and aid translation to clinical and public health applications.\nVulnerable periods. Development normatively progresses from less mature to more mature levels of functioning. However, unique epochs and experiences can alter the course of this idealized form of development. Consider research that shows cannabis use during adolescence is associated with later psychosis to a greater degree than cannabis use initiated later in development [add citation]; or, similarly, experimental research on rodents that shows rodent brains to be especially sensitive to the neurotoxic effects of alcohol on brain structure and learning early in development (corresponding to early adolescence in humans)[add citation]. These examples highlight the importance of considering the role of vulnerable periods – temporal windows of rapid brain development or remodeling during which the effects of environmental stimuli (e.g. cannabis exposure) on the developing brain may be particularly pronounced– when trying to establish an accurate understanding of the association between exposures and outcomes.\nDevelopmental disturbances. Whereas vulnerable periods heighten neurobiological susceptibility to environmental influences, at other times environmental pressures will tend to suppress stability and disrupt the orderly stochastic process of normative development (e.g., xxx-xxx). This situation reflects a developmental disturbance in that the normal course of development is “disturbed” for some time by some time-limited process. In such cases, we might find that prediction of behavior in the period of the disturbance is reduced and/or, similarly, the behavior exhibited during the disturbance might have less predictive power with respect to distal outcomes compared to the behavior exhibited before and following the disrupted period. That is, once the environmental stimuli are removed (or the individual is removed from the environment), individual differences are again more freely expressed and the autoregressive effects increase to levels similar to those before entering the environment.\nDevelopmental snares and cascade effects. Normative development can also be upended by experiences (e.g., drug use) that, through various mechanisms, disrupt the normal flow of development wherein each stage establishes a platform for the next. For instance, substance use could lead to association with deviant peers, precluding opportunities for learning various adaptive skills and prosocial behaviors, in effect, creating a “snare” that retards psychosocial development. Relatedly, the consequences of these types of events can cascade (e.g., school dropout, involvement in the criminal justice system) so that the effects of the snare are amplified. Although conceptually distinct from vulnerable periods, both of these types of developmental considerations highlight the importance of viewing behavior in the context of development and the importance of attempting to determine how various developmental pathways unfold.\nDistinguishing developmental change from experience effects. One can often observe systematic changes over time in a variable of interest and assume this change is attributable to development. To this point, cognitive abilities (e.g, verbal ability, problem-solving) normatively grow earlier in development and often decline in late life (e.g., memory, speed of processing). However, the observed patterns of growth and decline often differ between cross-sectional vs. longitudinal effects (Salthouse 2014) where subjects gain increasing experience with the assessment with each successive measurement occasion. Such experience effects on cognitive functioning have been demonstrated in adolescent longitudinal samples similar to ABCD (Sullivan et al. 2017) and highlight the need to consider these effects and address them analytically. In the case of performance-based measures [e.g., matrix reasoning related to neurocognitive functioning; see Salthouse (2014)], this can be due to “learning” the task from previous test administrations (e.g., someone taking the test a second time performs better than they did the first time simply as a function of having taken it before). Even in the case of non-performance-based measures (e.g., levels of depression), where one cannot easily make the argument that one has acquired some task-specific skill through learning, it has been observed that respondents tend to endorse lower levels on subsequent assessments (e.g., Beck et al. 1961; see French and Sutton 2010) and this phenomenon has been well documented in research on structured diagnostic interviews (Robins 1985). While it is typically assumed that individuals are rescinding or telling us less information on follow-up interviews, there is reason to suspect that in some cases the initial assessment may be artefactually elevated (see Shrout et al. 2018). Some designs (specifically, accelerated longitudinal designs) are especially well suited for discovering these effects and modeling them. While ABCD was not designed as an accelerated longitudinal design, the variability in age at the time of baseline recruitment (9 years, 0 months to 10 years, 11 months) allows some measures, collected every year, to be conceptualized as an accelerated longitudinal design. Moreover, it is possible that in later waves, patterns of longitudinal missing data will allow some analyses to assess the confounded effects of age and the number of prior assessments. However, ABCD is fundamentally a single-cohort, longitudinal design, where a number of prior assessments and age are highly confounded, and for, perhaps, most analyses, the possible influence of experience effects needs to be kept in mind."
  },
  {
    "objectID": "manuscript.html#interpretation-issues-pitfalls-assumption",
    "href": "manuscript.html#interpretation-issues-pitfalls-assumption",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "3.1 Interpretation / Issues / Pitfalls & Assumption",
    "text": "3.1 Interpretation / Issues / Pitfalls & Assumption\n\n\n\nFigure 1: LDA Structural Diagram\n\n\nDefining Features of Longitudinal Data Analysis. The hallmark characteristic of longitudinal data analysis is its application to repeated assessments of the same assessment targets (e.g., individuals, families) across time. While the primary reason for collecting longitudinal data is in pursuit of addressing scientific questions, from a methodological perspective, having multiple observations over time allows researchers to identify potentially problematic observations when highly improbable longitudinal patterns are observed. That is, we can ask more nuanced questions and make stronger inferences as our number of time-ordered observations grows assuming we have assessed the “right” variables and the timings of our observations comport with the temporal dynamics of the mechanisms of interest .\n“traditional approaches”: marginal models\nrandom effects: Growth Curves- SEM (lgcm) vs ME (lmm)\n(between- and within-person levels?)\n\n3.1.1 Modeling Data Across Two Time Points versus Three or More Time Points.\nAlthough the clear leap to the realm of longitudinal data involves going from one assessment to two or more assessments, there are also notable distinctions in designs based on two-assessment points versus three or more measurement occasions. Just as cross-sectional data can be informative in some situations, two waves of data can be beneficial in contexts such as when experimental manipulation is involved (e.g., pre/post tests), or if the central goal is prediction (e.g., trying to predict scores on Variable A at time T as a function of prior scores on Variable A and Variable B at time T-1). At the same time, data based on two assessments are inherently limited on multiple fronts. As (Rogosa, Brandt, and Zimowski 1982) noted approximately forty years ago, “Two waves of data are better than one, but maybe not much better”. These sentiments are reflected in more contemporary recommendations regarding best-practice guidelines for prospective data, which increasingly emphasize the benefits of additional measurement occasions for model identification and accurate parameter estimation. It is also consistent with research recommending that developmental studies include three or more assessment points, given it is impossible for data based on two-time points to determine the shape of development (since linear, straight line change is the only possible form, given two assessments; see (Duncan and Duncan 2009)). Research designs that include three or more time points allow for increasingly nuanced analyses that more adequately tease apart sources of variation and covariation among the repeated assessments (King et al. 2018)– a key aspect of inferential research. To illustrate, developmental theories are typically interested in understanding patterns of within-individual change over time (discussed in further detail, below); however, two data points provide meager information on change at the person level. This point is further underscored in a recent review of statistical models commonly touted as distinguishing within-individual vs between-individual sources of variance in which the study authors concluded “… researchers are limited when attempting to differentiate these sources of variation in psychological phenomenon when using two waves of data” and perhaps more concerning, “…the models discussed here do not offer a feasible way to overcome these inherent limitations” Littlefield et al. (2021). It is important to note, however, that despite the current focus on two-wave designs versus three or more assessment waves, garnering three assessment points is not a panacea for longitudinal modeling. Indeed, several contemporary longitudinal models designed to isolate within-individual variability [e.g., the Latent Curve Model with Structured Residuals; Curran et al. (2014)] require at least four assessments to parameterize fully and, more generally, increasingly accurate parameter estimates are obtained as more assessment occasions are used (Duncan and Duncan 2009).\n\n\n3.1.2 Types of stability and change\nIf one were to try to sum up what development in a living organism is exactly, one could plausibly argue it’s the characterization of stability and change as the organism traverses the life course. There are a few different ways to think of stability (and change). Consider we measure the height of all youth in a 6th-grade class, once in the fall at the beginning of the school year and once again in the spring at the end of the school year. A common first step may be to compare the class’s average height values obtained at these two different measurement occasions. This comparison of the average scores for the same group of individuals at multiple time points is referred to as “mean-level” stability as it provides information about continuity and change in the group level of an outcome of interest (e.g., height) over time. Another type of stability involves calculating the correlation between the values obtained at different time points (e.g., ‘height in the fall’ with ‘height in the spring’). This type of “rank-order” stability evaluates between-individual change by focusing on the degree to which individuals retain their relative placement in a group across time. Consider, someone who is the shortest person in their class in 6th grade may grow considerably over the school year (i.e., exhibit mean level change), but remain the shortest person among their classmates. That is, the individual is manifesting a type of rank-order stability. Both types of stability and change are important. Mean-level change in certain traits might help to explain why, in general, individuals are particularly vulnerable to social influences at some ages more than others; rank order change might help to quantify the extent to which certain characteristics of the individual are more trait-like. For example, in some areas of development, there is considerable mean-level change that occurs over time (e.g., changes in Big 5 personality traits), but relatively high rank-order stability. Despite the useful information afforded by examining mean-level and rank-order change, these approaches are limited in that they provide little information about patterns of “within-individual” change and, in turn, can result in fundamental misinterpretations about substantial or meaningful changes in an outcome of interest.\nThere is growing recognition that statistical models commonly applied to longitudinal data often fail to comport with the developmental theory they are being used to assess (e.g., Curran, Lee, Howard, Lane, & MacCallum, 2012; Hoffman, 2015; Littlefield et al., 2021. Specifically, developmental studies typically involve the use of prospective data to inform theories that are concerned with clear within-person (i.e., intraindividual) processes (e.g., how phenotypes change or remain stable within individuals over time) (e.g., see Curran and Bauer 2011). Despite this, methods generally unsuited for disaggregating between- and within-person effects (e.g., cross-lagged panel models [CLPM]) remain common within various extant literatures. As a result, experts increasingly caution about the need to xxxxxxxx [add citation]. Fortunately, there exists a range of models that have been proposed to tease apart between- and within-person sources of variance across time (see Littlefield et al. 2021; Orth et al. 2021). Most of these contemporary alternatives incorporate time-specific latent variables to capture between-person sources of variance and model within-person deviations around an individual’s mean (or trait) level across time (e.g., RI-CLPM, Hamaker, Kuiper, and Grasman 2015; LCM-SR, Curran et al. 2014). It is important to note however that these models require multiple assessments waves (e.g., four or more to fully specify the LCM-SR), additional expertise to overcome issues with model convergence, and appreciation of modeling assumptions when attempting to adjudicate among potential models in each research context (see Littlefield et al. 2021, for further discussion).\nThis is illustrated well by Figure 1.\n\n\n3.1.3 Model Assumptions\nMany statistical models assume certain characteristics about the data to which they are being applied. As an example, common assumptions of parametric statistical models include normality, linearity, and equality of variances. These assumptions must be carefully considered before conducting analysis so that valid inferences can be made from the data; that is, violation of a model’s assumptions can substantively alter the interpretation of results. Similarly, statistical models employed in the analyses of longitudinal data often entail a range of assumptions that must be closely inspected. One central issue for repeated measurements on an individual is how to account for the correlated nature of the data; another common feature of longitudinal data is heterogeneous variability; that is, the variance of the response changes over the duration of the study. Traditional techniques, such as a standard regression or ANOVA model, assume residuals are independent and thus are inappropriate for designs that assess (for example) the same individuals across time. That is, given the residuals are no longer independent, the standard errors from the models are biased and can produce misleading inferential results. Although there are formal tests of independence for time series data (e.g., the Durbin-Watson statistic (Durbin and Watson 1950)), more commonly independence is assumed to be violated in study designs with repeated assessments. Therefore, an initial question to be addressed by a researcher analyzing prospective data is how to best model the covariance structure of said data.\n\n\n3.1.4 Covariance Structures\nStatistical models for longitudinal data include two main components to account for assumptions that are commonly violated when working with repeated measures data: a model for the covariance among repeated measures (both the correlations among pairs of repeated measures on an individual and the variability of the responses on different occasions), coupled with a model for the mean response and its dependence on covariates (eg, treatment group in the context of clinical trials). This allows for the specification of a range of so-called covariance structures, each with its own set of tradeoffs between model fit and parsimony (e.g., see Kincaid 2005).\n\n\n3.1.5 Accounting for Correlated Data\nAs an example, one alternative structure that attempts to handle the reality that correlations between repeated assessments tend to diminish across time is the autoregressive design. As the name implies, the structure assumes a subsequent measurement occasion (e.g., assessment at Wave 2) is regressed onto (that is, is predicted by) a prior measurement occasion (e.g., assessment at Wave 1). The most common type of autoregressive design is the AR(1), where assessments at time T + 1 are regressed on assessments at Time T. Identical to compound symmetry, this model assumes the variances are homogenous across time. Diverting from compound symmetry, this model assumes the correlations between repeated assessments decline exponentially across time rather than remaining constant. For example, per the AR(1) structure, if the correlation between Time 1 and Time 2 data is thought to be .5, then the correlation between Time 1 and Time 3 data would be assumed to be .5.5 = .25, and the correlation between Time 1 and Time 4 data would be assumed to be .5.5*.5 = .125. As with compound symmetry, the basic AR(1) model is parsimonious in that it only requires two parameters (the variance of the assessments and the autoregressive coefficient). Notably, the assumption of constant autoregressive relations between assessments is often relaxed in commonly employed designs that use autoregressive modeling (e.g., cross-lagged panel models [CLPM]). These designs still typically assume an AR(1) process (e.g., it is sufficient to regress the Time 3 assessment onto the Time 2 assessment and is not necessary to also regress the Time 3 assessment onto the Time 1 assessment, which would result in an AR(2) process). However, the magnitude of these relations is often allowed to differ across different AR(1) pairs of assessment (e.g., the relation between Time 1 and Time 2 can be different from the relation between Time 2 and Time 3). These more commonly employed models also often relax the assumption of equal variances of the repeated assessments. Although the AR(1) structure may involve a more realistic set of assumptions compared to compound symmetry, in that the AR(1) model allows for diminishing correlations across time, the basic AR(1) model, as well as autoregressive models more generally, can also suffer from several limitations in contexts that are common in prospective designs. In particular, recent work demonstrates that if a construct being assessed prospectively across time is trait-like in nature, then autoregressive relations fail to adequately account for this trait-like structure, with the downstream consequence that estimates derived from models based on AR structures (such as the CLPM) can be misleading and fail to adequately demarcate between- vs. within-person sources of variance (Hamaker, Kuiper, and Grasman 2015).\n\n\n3.1.6 Linear vs non-linear models\nIdentification of optimal statistical models and appropriate mathematical functions requires an understanding of the type of data being used. Repeated assessments can be based on either continuous or discrete measures. Examples of discrete measures include repeated assessments of binary variables (e.g., past 12-month alcohol use disorder status measured across ten years), ordinal variables (e.g., a single item measuring the level of agreement to a statement on a three-point scale including the categories of “disagree”, “neutral”, and “agree” in an ecological momentary assessment study that involves multiple daily assessments), and count variables (e.g., number of cigarettes smoked per day across a daily diary study). In many ways, the distributional assumptions of indicators used in longitudinal designs mirror the decision points and considerations when delineating across different types of discrete outcome variables, a topic that spans entire textbooks (e.g., see Lenz 2016). For example, the Mplus manual (Muthén 2017) includes examples of a) censored and censored-inflated models, b) linear growth models for binary or ordinal variables, c) linear growth models for a count outcome assuming a Poisson model, d) linear growth models for a count outcome assuming a zero-inflated Poisson model and e) discrete- and continuous-time survival analysis for a binary outcome. Beyond these highlighted examples, other distributions (e.g., negative binomial) can be assumed for the indicators when modeling longitudinal data. These models can account for issues that can occur when working with discrete outcomes, including overdispersion (when the variance is higher than would be expected based on a given distribution) and zero-inflation [when more zeros occur than is expected based on a given distribution; see Lenz (2016)]. Models involving zero-inflation parameters are referred to as two-part models, given one part of the model predicts the zero-inflation whereas the other part of the model predicts outcomes consistent with a given distribution [e.g., Poisson distribution; see Farewell et al. (2017), for a review of two-part models for longitudinal data]. Although there exist several alternative models for discrete indicators, some more recent models that have been proposed for prospective data are only feasible in cases where indicators are assumed to be continuous rather than discrete [e.g., LCM-SR; Curran et al. (2014)]. Given the sheer breadth of issues relevant to determining better models for discrete outcomes, it is not uncommon for texts on longitudinal data analysis to only cover models and approaches that assume continuous indicators (e.g., T. D. Little 2013). However, some textbooks on categorical data analysis provide more detailed coverage of the myriad issues and modeling choices to consider when working with discrete outcomes [e.g., Lenz (2016), Chapter 11 for matched pair/two-assessment designs; Chapter 12 for marginal and transitional models for repeated designs, such as generalized estimating equations, and Chapter 13 for random effects models for discrete outcomes].\n\n\n3.1.7 Marginal vs Conditional Models (?)\n[section still under development…]\n\n\n3.1.8 Missing Data/Attrition\nAs recently reviewed by Littlefield (in press), investigators of prospective data are confronted with study attrition (i.e., participants may not provide data at a given wave of assessment) and thus approaches are needed to confront the issue of missing data. Three models of missingness are typically considered in the literature (see R. J. Little and Rubin 1989). These three models are data: a) missing completely at random (MCAR), b) missing at random (MAR), and c) missing not at random (MNAR). Data that are MCAR means missing data is a random sample of all the types of participants (e.g., males) in a given dataset. MAR suggests conditionally missing at random (see Graham 2009). That is, MAR implies missingness is completely random (i.e., does not hinge on some unmeasured variables) once missingness has been adjusted by all available variables in a dataset (e.g., biological sex). Data that are MNAR are missing as a function of unobserved variables. Graham (2009) provides an excellent and easy-to-digest overview of further details involving missing data considerations.\nMultiple approaches have been posited to handle missing data. Before the advent of more contemporary approaches, common methods included several ad hoc procedures. These include eliminating the data of participants with missing data (e.g., listwise or pairwise deletion) or using mean imputation (i.e., replacing the missing value with the mean score of the sample that did participate). However, these methods are not recommended because they can contribute to biased parameter estimates and research conclusions (see Graham 2009). More specifically, the last observation carried forward (LOCF) is a common approach to imputing missing data. LOCF replaces a participant’s missing values after dropout with the last available measurement (Molnar, Hutton, and Fergusson 2008). This approach assumes stability (i.e., a given participant’s score is not anticipated to increase or decline after study dropout) and that the data are MCA R. However, as described by Molnar, Hutton, and Fergusson (2008), it is common for treatment groups to show higher attrition compared to control groups in studies of dementia drugs. Given that dementia worsens over time, using LOCF biases the results in favor of the treatment group (see Molnar, Hutton, and Fergusson 2008, for more details).\nMore modern approaches, such as using maximum likelihood or multiple imputation to estimate missing data, are thought to avoid some of the biases of older approaches (see Enders 2010; Graham 2009). Graham (2009) noted several “myths” regarding missing data. For example, Graham notes many assume the data must be minimally MAR to permit estimating procedures (such as maximum likelihood or multiple imputation) compared to other, more traditional approaches (e.g., using only complete case data). Violations of MAR impact both traditional and more modern data estimation procedures, though as noted by Graham, violations of MAR tend to have a greater effect on older methods. Graham thus suggests that estimating missing data is a better approach compared to the older procedures in most circumstances, regardless of the model of missingness [i.e., MCAR, MAR, MNAR; see Graham (2009)].\nAttrition from a longitudinal panel study such as ABCD is inevitable and represents a threat to the validity of longitudinal analyses and cross-sectional analyses conducted at later time points, especially since attrition can only be expected to grow over time. While, to date, attrition in ABCD has been minimal (some cite here), it remains an important focus for longitudinal analysis and its significance is likely to only grow as the cohort ages. Ideally, one tries to minimize attrition through good retention practices from the outset via strategies designed to maintain engagement in the project (Cotter et al. 2005; Hill et al. 2016; Watson et al. 2018). However, even the best-executed studies need to anticipate growing attrition over the length of the study and implement analytic strategies designed to provide the most valid inferences. Perhaps the most key concern when dealing with data that is missing due to attrition is determining the degree of bias in retained variables that is a consequence of attrition. Assuming that the data are not missing completely at random, attention to the nature of the missingness and employing techniques designed to mitigate attrition-related biases need to be considered in all longitudinal analyses. Several different approaches can be considered and employed depending upon the nature of the intended analyses, the degree of missingness, and data available to help estimate missing and unobserved values.\n\n\n3.1.9 Quantifying effect sizes longitudinally\nGiven longitudinal data involve different sources of variance, quantifying effect sizes longitudinally is a more difficult task compared to deriving such estimates from cross-sectional data. Effect size can be defined as, “a population parameter (estimated in a sample) encapsulating the practical or clinical importance of a phenomenon under study.” (Kraemer 2014). Common effect size metrics include r (i.e., the standardized covariance, or correlation, between two variables) and Cohen’s d (Cohen 1988). Adjustments to common effect size calculations, such as Cohen’s d, are required even when only two time points are considered (e.g., see Morris and DeShon 2002). Wang et al. (2019) note there are multiple approaches to obtaining standardized within-person effects, and that commonly suggested approaches (e.g., global standardization) can be problematic (see Wang et al. 2019, for more details). Thus, obtaining effect size metrics based on standardized estimates that are relatively simple in cross-sectional data (such as r) becomes more complex in the context of prospective data. Feingold (2009) noted that equations for effects sizes used in studies involving growth modeling analysis (e.g., latent growth curve modeling) were not mathematically equivalent, and the effect sizes were not in the same metric as effect sizes from traditional analysis (see Feingold 2009, for more details). Given this issue, there have been various proposals for adjusting effect size measures in repeated assessments. Feingold (2019) reviews the approach for effect size metrics for analyses based on growth modeling, including when considering linear and non-linear (i.e., quadratic) growth factors. Morris and DeShon (2002) review various equations for effect size calculations relevant to when combining estimates in meta-analysis with repeated measures and independent-groups designs. Other approaches to quantifying effect sizes longitudinally may be based on standardized estimates from models that more optimally disentangle between- and within-person sources of variance (as reviewed above). As an example, within a RI-CLPM framework, standardized estimates between random intercepts (i.e., the correlation between two random intercepts for two different constructs assessed repeatedly) could be used to index the between-person relation, whereas standardized estimates among the structured residuals could be used as informing the effect sizes of within-person relations."
  },
  {
    "objectID": "TailwindTest.html",
    "href": "TailwindTest.html",
    "title": "Tailwind Test Doc",
    "section": "",
    "text": "xxxzzzzzxxx\n\n\n include contentzzzzzzz\n\n\n include content"
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html",
    "href": "1_Tutorials_DifferenceScores.html",
    "title": "Difference Scores",
    "section": "",
    "text": "Difference scores are one of the earliest developed and commonly used statistical approaches to compare data collected from the same individual across two measurement occasions (Castro-Schilo and Grimm 2018; Jennings and Cribbie 2016). The difference between scores at the two time points is calculated for each individual and the resulting value is taken as a measure of change. It is common to then perform statistical tests on the difference scores, such as being included as an outcome in a GLM analysis to test for differences in patterns of change over time and between groups. For example, difference scores may be used in a paired-samples t-test to compare mean test scores of students before and after attending a math workshop, or in a simple regression analysis to assess the effectiveness of a weight loss program by calculating the difference in weight between between groups of interest, before and after the program.\n\n\n\nDifference Score 1_Tutorial\n\n\n\n\nYou should use difference scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will guide you through two simple examples of using difference scores. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of difference scores.\nCalculate difference scores using example data.\nInterpret the results of the difference scores analysis."
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html#overview",
    "href": "1_Tutorials_DifferenceScores.html#overview",
    "title": "Difference Scores",
    "section": "",
    "text": "Difference scores are one of the earliest developed and commonly used statistical approaches to compare data collected from the same individual across two measurement occasions (Castro-Schilo and Grimm 2018; Jennings and Cribbie 2016). The difference between scores at the two time points is calculated for each individual and the resulting value is taken as a measure of change. It is common to then perform statistical tests on the difference scores, such as being included as an outcome in a GLM analysis to test for differences in patterns of change over time and between groups. For example, difference scores may be used in a paired-samples t-test to compare mean test scores of students before and after attending a math workshop, or in a simple regression analysis to assess the effectiveness of a weight loss program by calculating the difference in weight between between groups of interest, before and after the program.\n\n\n\nDifference Score 1_Tutorial\n\n\n\n\nYou should use difference scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will guide you through two simple examples of using difference scores. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of difference scores.\nCalculate difference scores using example data.\nInterpret the results of the difference scores analysis."
  },
  {
    "objectID": "1_Tutorials_DifferenceScores.html#basic-example",
    "href": "1_Tutorials_DifferenceScores.html#basic-example",
    "title": "Difference Scores",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nTime point (T1, T2)\nJob satisfaction (independent variable)\nLife satisfaction (dependent variable)\n\n\n\n\nIndividual\nTime Point\nJob Satisfaction\nLife Satisfaction\n\n\n\n\nA\nT1\n7\n6\n\n\nA\nT2\n8\n7\n\n\nB\nT1\n6\n5\n\n\nB\nT2\n7\n6\n\n\n\nWe will then create a new variable, age_diff, that represents the difference in age between two time points:\n\n\nCode\n#titanic$age_diff &lt;- titanic$age - titanic$age[1]\n\n\n\nRepeated Measures Paired Samples T-test\nTo conduct a repeated measures paired samples t-test on age_diff, we will use the t.test() function in R:\n\n\nCode\n#t.test(titanic$age_diff, mu = 0, paired = TRUE)\\\n\n\nThe mu argument represents the hypothesized mean difference, which we have set to 0. The paired argument tells R that the samples are paired.\n\n\nInterpreting the Results\nThe output of the t.test() function includes several statistics, including the t-value, degrees of freedom, and p-value. The t-value represents the difference between the mean of age_diff and the hypothesized mean difference, divided by the standard error. The degrees of freedom represents the number of observations minus one. The p-value represents the probability of observing a t-value as extreme or more extreme than the one observed, assuming that the null hypothesis is true.\nIf the p-value is less than our chosen significance level (typically 0.05), we can reject the null hypothesis and conclude that there is a significant difference between the means of age_diff and the hypothesized mean difference. If the p-value is greater than our chosen significance level, we fail to reject the null hypothesis and conclude that there is insufficient evidence to suggest a difference between the means.\n\n\nConclusion\nIn this tutorial, we learned how to conduct a repeated measures paired samples t-test on a difference score using R. This statistical method is useful when we want to compare the means of two related variables that are measured at two different time points or under two different conditions. We also learned how to interpret the results of the t-test, including the t-value, degrees of freedom, and p-value.\n\n\nPaired Samples T-test Model Specification and Estimation\nTo calculate [xxxxx] scores, we will follow these steps:\n[two timepoints, t1 and t2, and we want to test whether there is a significant difference between the means of two variables measured at each timepoint. We can use a paired samples t-test to do this.]\nA paired samples t-test is used to determine whether there is a significant difference between two related variables. For example, you may be interested in whether there is a significant difference in anxiety levels between participants before and after an intervention. To conduct a paired samples t-test in R, we can use the t.test() function.\nLet’s use a hypothetical example to illustrate how to conduct a paired samples t-test in R. In this example, we have data from 30 participants who completed a pre-test and post-test on anxiety levels measured on a 10-point scale. We want to determine if there was a significant difference in anxiety levels before and after an intervention.\n\n\nCode\n# Generate example data\npre_test &lt;- rnorm(30, mean = 6, sd = 1)\npost_test &lt;- rnorm(30, mean = 4, sd = 1)\n\n\n\n\nCode\n# Conduct paired samples t-test\nt.test(pre_test, post_test, paired = TRUE)\n\n\n\n    Paired t-test\n\ndata:  pre_test and post_test\nt = 7.6083, df = 29, p-value = 2.18e-08\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.522869 2.642611\nsample estimates:\nmean difference \n        2.08274 \n\n\nThe t.test() function returns the t-value, degrees of freedom, and p-value for the paired samples t-test. In this example, the p-value is less than 0.05, indicating that there is a significant difference in anxiety levels before and after the intervention.\n\n\nSimple Regression on a Difference Score\nA simple regression on a difference score is used to determine the relationship between the difference scores of two related variables and a third variable. For example, you may be interested in whether there is a relationship between the difference in anxiety levels before and after an intervention and a participant’s age. To conduct a simple regression on a difference score in R, we can use the lm() function.\nLet’s continue with the hypothetical example from the paired samples t-test. We want to determine if there is a relationship between the difference in anxiety levels before and after the intervention and the participants’ age. We will create a new variable diff_score to represent the difference in anxiety levels.\n\n\nCode\n# Calculate difference score\ndiff_score &lt;- post_test - pre_test\n\n# Generate example age data\nage &lt;- rnorm(30, mean = 35, sd = 5)\n\n# Conduct simple regression on difference score and age\nmodel &lt;- lm(diff_score ~ age)\nsummary(model)\n\n\n\nCall:\nlm(formula = diff_score ~ age)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5068 -0.9876  0.3755  1.0985  2.7064 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -4.08802    2.29748  -1.779    0.086 .\nage          0.05783    0.06578   0.879    0.387  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.505 on 28 degrees of freedom\nMultiple R-squared:  0.02686,   Adjusted R-squared:  -0.007894 \nF-statistic: 0.7729 on 1 and 28 DF,  p-value: 0.3868\n\n\nThe lm() function returns the intercept, slope, and p-value for the simple regression on the difference score. In this example, the p-value is greater than 0.05, indicating that there is no significant relationship between the difference in anxiety levels and age.\n\nInterpreting the Results\nFor the paired samples t-test, the output from the t.test() function provides the t-value, degrees of freedom, and p-value. The t-value represents the size of the difference between the means of the two related variables relative to the variation within the data. The degrees of freedom represent the number of observations minus the number of variables being compared. The p-value represents the probability of obtaining a result as extreme as the one observed, assuming that the null hypothesis is true.\nFor the simple regression on the difference score, the output from the lm() function provides the intercept, slope,"
  },
  {
    "objectID": "manuscrip_test version.html",
    "href": "manuscrip_test version.html",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "The Adolescent Brain Cognitive Development (ABCD) Study® is the largest long-term investigation of neurodevelopment and child health in the United States. Conceived and initiated by the National Institutes of Health (NIH), this landmark prospective longitudinal study aims to transform our understanding of the genetic and environmental influences on brain development and their roles in behavioral and health outcomes in adolescents (Volkow et al. 2018). At its heart, the study is designed to chart the course of human development across multiple, interacting domains from late childhood to early adulthood and to identify factors that lead to both positive and negative developmental outcomes. Central to achieving these goals is the ABCD Study’s® commitment to an open science framework designed to facilitate access to and sharing of scientific knowledge by espousing practices that increase openness, integrity, and reproducibility of scientific research (e.g., public data releases). In this sense, the ABCD Study® is a collaboration with the larger research community, with the rich longitudinal nature of the ABCD Study dataset allowing researchers to perform a variety of analyses of both methodological and substantive interest. Together, this presents a unique opportunity to significantly advance our understanding of how a multitude of biopsychosocial processes emerge and unfold across critical periods of development.\n[section still be developed…]\n\n\nParticipants enrolled in the ABCD Study include a large cohort of youth (n=11880) aged 9-10 years at baseline and their parents/guardians. The study sample was recruited from household populations in defined catchment areas for each of the 21 study sites across the United States (information regarding funding agencies, recruitment sites, investigators, and project organization can be obtained at the ABCD Study website). The ABCD Study is collecting longitudinal data on a rich variety of outcomes that will enable the construction of realistically-complex etiological models by incorporating factors from many domains simultaneously. Each new wave of data collection provides the building blocks for conducting probing longitudinal analyses that allow us to characterize normative development, identify variables that presage deviations from prototypic development, and assess a range of outcomes associated with variables of interest. This data includes a neurocognitive battery (Luciana et al. 2018; Thompson et al. 2019), mental and physical health assessments (Barch et al. 2018), measures of culture and environment (Zucker et al. 2018), substance use [add citation], biospecimens (Uban et al. 2018), structural and functional brain imaging (Casey et al. 2018; Hagler et al. 2019), geolocation-based environmental exposure data, wearables, and mobile technology (Bagot et al. 2018), and whole genome genotyping (Loughnan et al. 2020). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual telephone interviews between in-person visits. Data are publicly released on an annual basis through the NIMH Data Archive. By necessity, the study’s earliest data releases were cross-sectional (i.e., the baseline data), however, the most recent public data release (NDA Release 4.0) contains data collected across three annual assessments, including two imaging assessments (baseline and year 2 follow-up visits).\n\n\n\nThe rich longitudinal nature of the ABCD Study dataset will allow researchers to perform analyses of both methodological and substantive interest. This report describes methods for longitudinal analyses of ABCD Study data that can address its fundamental scientific aims, as well as challenges inherent in a large population-based long-term study of adolescents. The manuscript is organized as follows:\n[section still be developed…]"
  },
  {
    "objectID": "manuscrip_test version.html#the-abcd-study-data",
    "href": "manuscrip_test version.html#the-abcd-study-data",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "Participants enrolled in the ABCD Study include a large cohort of youth (n=11880) aged 9-10 years at baseline and their parents/guardians. The study sample was recruited from household populations in defined catchment areas for each of the 21 study sites across the United States (information regarding funding agencies, recruitment sites, investigators, and project organization can be obtained at the ABCD Study website). The ABCD Study is collecting longitudinal data on a rich variety of outcomes that will enable the construction of realistically-complex etiological models by incorporating factors from many domains simultaneously. Each new wave of data collection provides the building blocks for conducting probing longitudinal analyses that allow us to characterize normative development, identify variables that presage deviations from prototypic development, and assess a range of outcomes associated with variables of interest. This data includes a neurocognitive battery (Luciana et al. 2018; Thompson et al. 2019), mental and physical health assessments (Barch et al. 2018), measures of culture and environment (Zucker et al. 2018), substance use [add citation], biospecimens (Uban et al. 2018), structural and functional brain imaging (Casey et al. 2018; Hagler et al. 2019), geolocation-based environmental exposure data, wearables, and mobile technology (Bagot et al. 2018), and whole genome genotyping (Loughnan et al. 2020). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual telephone interviews between in-person visits. Data are publicly released on an annual basis through the NIMH Data Archive. By necessity, the study’s earliest data releases were cross-sectional (i.e., the baseline data), however, the most recent public data release (NDA Release 4.0) contains data collected across three annual assessments, including two imaging assessments (baseline and year 2 follow-up visits)."
  },
  {
    "objectID": "manuscrip_test version.html#organization-of-current-manuscript",
    "href": "manuscrip_test version.html#organization-of-current-manuscript",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "The rich longitudinal nature of the ABCD Study dataset will allow researchers to perform analyses of both methodological and substantive interest. This report describes methods for longitudinal analyses of ABCD Study data that can address its fundamental scientific aims, as well as challenges inherent in a large population-based long-term study of adolescents. The manuscript is organized as follows:\n[section still be developed…]"
  },
  {
    "objectID": "manuscrip_test version.html#modeling-data-across-two-time-points-versus-three-or-more-time-points.",
    "href": "manuscrip_test version.html#modeling-data-across-two-time-points-versus-three-or-more-time-points.",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "Modeling Data Across Two Time Points versus Three or More Time Points.",
    "text": "Modeling Data Across Two Time Points versus Three or More Time Points.\nAlthough the clear leap to the realm of longitudinal data involves going from one assessment to two or more assessments, there are also notable distinctions in designs based on two-assessment points versus three or more measurement occasions. Just as cross-sectional data can be informative in some situations, two waves of data can be beneficial in contexts such as when experimental manipulation is involved (e.g., pre/post tests), or if the central goal is prediction (e.g., trying to predict scores on Variable A at time T as a function of prior scores on Variable A and Variable B at time T-1). At the same time, data based on two assessments are inherently limited on multiple fronts. As (Rogosa, Brandt, and Zimowski 1982) noted approximately forty years ago, “Two waves of data are better than one, but maybe not much better”. These sentiments are reflected in more contemporary recommendations regarding best-practice guidelines for prospective data, which increasingly emphasize the benefits of additional measurement occasions for model identification and accurate parameter estimation. It is also consistent with research recommending that developmental studies include three or more assessment points, given it is impossible for data based on two-time points to determine the shape of development (since linear, straight line change is the only possible form, given two assessments; see (Duncan and Duncan 2009)). Research designs that include three or more time points allow for increasingly nuanced analyses that more adequately tease apart sources of variation and covariation among the repeated assessments (King et al. 2018)– a key aspect of inferential research. To illustrate, developmental theories are typically interested in understanding patterns of within-individual change over time (discussed in further detail, below); however, two data points provide meager information on change at the person level. This point is further underscored in a recent review of statistical models commonly touted as distinguishing within-individual vs between-individual sources of variance in which the study authors concluded “… researchers are limited when attempting to differentiate these sources of variation in psychological phenomenon when using two waves of data” and perhaps more concerning, “…the models discussed here do not offer a feasible way to overcome these inherent limitations” Littlefield et al. (2021). It is important to note, however, that despite the current focus on two-wave designs versus three or more assessment waves, garnering three assessment points is not a panacea for longitudinal modeling. Indeed, several contemporary longitudinal models designed to isolate within-individual variability [e.g., the Latent Curve Model with Structured Residuals; Curran et al. (2014)] require at least four assessments to parameterize fully and, more generally, increasingly accurate parameter estimates are obtained as more assessment occasions are used (Duncan and Duncan 2009)."
  },
  {
    "objectID": "manuscrip_test version.html#types-of-stability-and-change",
    "href": "manuscrip_test version.html#types-of-stability-and-change",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "Types of stability and change",
    "text": "Types of stability and change\nIf one were to try to sum up what development in a living organism is exactly, one could plausibly argue it’s the characterization of stability and change as the organism traverses the life course. There are a few different ways to think of stability (and change). Consider we measure the height of all youth in a 6th-grade class, once in the fall at the beginning of the school year and once again in the spring at the end of the school year. A common first step may be to compare the class’s average height values obtained at these two different measurement occasions. This comparison of the average scores for the same group of individuals at multiple time points is referred to as “mean-level” stability as it provides information about continuity and change in the group level of an outcome of interest (e.g., height) over time. Another type of stability involves calculating the correlation between the values obtained at different time points (e.g., ‘height in the fall’ with ‘height in the spring’). This type of “rank-order” stability evaluates between-individual change by focusing on the degree to which individuals retain their relative placement in a group across time. Consider, someone who is the shortest person in their class in 6th grade may grow considerably over the school year (i.e., exhibit mean level change), but remain the shortest person among their classmates. That is, the individual is manifesting a type of rank-order stability. Both types of stability and change are important. Mean-level change in certain traits might help to explain why, in general, individuals are particularly vulnerable to social influences at some ages more than others; rank order change might help to quantify the extent to which certain characteristics of the individual are more trait-like. For example, in some areas of development, there is considerable mean-level change that occurs over time (e.g., changes in Big 5 personality traits), but relatively high rank-order stability. Despite the useful information afforded by examining mean-level and rank-order change, these approaches are limited in that they provide little information about patterns of “within-individual” change and, in turn, can result in fundamental misinterpretations about substantial or meaningful changes in an outcome of interest.\nThere is growing recognition that statistical models commonly applied to longitudinal data often fail to comport with the developmental theory they are being used to assess (e.g., Curran, Lee, Howard, Lane, & MacCallum, 2012; Hoffman, 2015; Littlefield et al., 2021. Specifically, developmental studies typically involve the use of prospective data to inform theories that are concerned with clear within-person (i.e., intraindividual) processes (e.g., how phenotypes change or remain stable within individuals over time) (e.g., see Curran and Bauer 2011). Despite this, methods generally unsuited for disaggregating between- and within-person effects (e.g., cross-lagged panel models [CLPM]) remain common within various extant literatures. As a result, experts increasingly caution about the need to xxxxxxxx [add citation]. Fortunately, there exists a range of models that have been proposed to tease apart between- and within-person sources of variance across time (see Littlefield et al. 2021; Orth et al. 2021). Most of these contemporary alternatives incorporate time-specific latent variables to capture between-person sources of variance and model within-person deviations around an individual’s mean (or trait) level across time (e.g., RI-CLPM, Hamaker, Kuiper, and Grasman 2015; LCM-SR, Curran et al. 2014). It is important to note however that these models require multiple assessments waves (e.g., four or more to fully specify the LCM-SR), additional expertise to overcome issues with model convergence, and appreciation of modeling assumptions when attempting to adjudicate among potential models in each research context (see Littlefield et al. 2021, for further discussion)."
  },
  {
    "objectID": "manuscrip_test version.html#model-assumptions",
    "href": "manuscrip_test version.html#model-assumptions",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "Model Assumptions",
    "text": "Model Assumptions\nMany statistical models assume certain characteristics about the data to which they are being applied. As an example, common assumptions of parametric statistical models include normality, linearity, and equality of variances. These assumptions must be carefully considered before conducting analysis so that valid inferences can be made from the data; that is, violation of a model’s assumptions can substantively alter the interpretation of results. Similarly, statistical models employed in the analyses of longitudinal data often entail a range of assumptions that must be closely inspected. One central issue for repeated measurements on an individual is how to account for the correlated nature of the data; another common feature of longitudinal data is heterogeneous variability; that is, the variance of the response changes over the duration of the study. Traditional techniques, such as a standard regression or ANOVA model, assume residuals are independent and thus are inappropriate for designs that assess (for example) the same individuals across time. That is, given the residuals are no longer independent, the standard errors from the models are biased and can produce misleading inferential results. Although there are formal tests of independence for time series data (e.g., the Durbin-Watson statistic (Durbin and Watson 1950)), more commonly independence is assumed to be violated in study designs with repeated assessments. Therefore, an initial question to be addressed by a researcher analyzing prospective data is how to best model the covariance structure of said data."
  },
  {
    "objectID": "manuscrip_test version.html#covariance-structures",
    "href": "manuscrip_test version.html#covariance-structures",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "Covariance Structures",
    "text": "Covariance Structures\nStatistical models for longitudinal data include two main components to account for assumptions that are commonly violated when working with repeated measures data: a model for the covariance among repeated measures (both the correlations among pairs of repeated measures on an individual and the variability of the responses on different occasions), coupled with a model for the mean response and its dependence on covariates (eg, treatment group in the context of clinical trials). This allows for the specification of a range of so-called covariance structures, each with its own set of tradeoffs between model fit and parsimony (e.g., see Kincaid 2005)."
  },
  {
    "objectID": "manuscrip_test version.html#accounting-for-correlated-data",
    "href": "manuscrip_test version.html#accounting-for-correlated-data",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "Accounting for Correlated Data",
    "text": "Accounting for Correlated Data\nAs an example, one alternative structure that attempts to handle the reality that correlations between repeated assessments tend to diminish across time is the autoregressive design. As the name implies, the structure assumes a subsequent measurement occasion (e.g., assessment at Wave 2) is regressed onto (that is, is predicted by) a prior measurement occasion (e.g., assessment at Wave 1). The most common type of autoregressive design is the AR(1), where assessments at time T + 1 are regressed on assessments at Time T. Identical to compound symmetry, this model assumes the variances are homogenous across time. Diverting from compound symmetry, this model assumes the correlations between repeated assessments decline exponentially across time rather than remaining constant. For example, per the AR(1) structure, if the correlation between Time 1 and Time 2 data is thought to be .5, then the correlation between Time 1 and Time 3 data would be assumed to be .5.5 = .25, and the correlation between Time 1 and Time 4 data would be assumed to be .5.5*.5 = .125. As with compound symmetry, the basic AR(1) model is parsimonious in that it only requires two parameters (the variance of the assessments and the autoregressive coefficient). Notably, the assumption of constant autoregressive relations between assessments is often relaxed in commonly employed designs that use autoregressive modeling (e.g., cross-lagged panel models [CLPM]). These designs still typically assume an AR(1) process (e.g., it is sufficient to regress the Time 3 assessment onto the Time 2 assessment and is not necessary to also regress the Time 3 assessment onto the Time 1 assessment, which would result in an AR(2) process). However, the magnitude of these relations is often allowed to differ across different AR(1) pairs of assessment (e.g., the relation between Time 1 and Time 2 can be different from the relation between Time 2 and Time 3). These more commonly employed models also often relax the assumption of equal variances of the repeated assessments. Although the AR(1) structure may involve a more realistic set of assumptions compared to compound symmetry, in that the AR(1) model allows for diminishing correlations across time, the basic AR(1) model, as well as autoregressive models more generally, can also suffer from several limitations in contexts that are common in prospective designs. In particular, recent work demonstrates that if a construct being assessed prospectively across time is trait-like in nature, then autoregressive relations fail to adequately account for this trait-like structure, with the downstream consequence that estimates derived from models based on AR structures (such as the CLPM) can be misleading and fail to adequately demarcate between- vs. within-person sources of variance (Hamaker, Kuiper, and Grasman 2015)."
  },
  {
    "objectID": "manuscrip_test version.html#linear-vs-non-linear-models",
    "href": "manuscrip_test version.html#linear-vs-non-linear-models",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "Linear vs non-linear models",
    "text": "Linear vs non-linear models\nIdentification of optimal statistical models and appropriate mathematical functions requires an understanding of the type of data being used. Repeated assessments can be based on either continuous or discrete measures. Examples of discrete measures include repeated assessments of binary variables (e.g., past 12-month alcohol use disorder status measured across ten years), ordinal variables (e.g., a single item measuring the level of agreement to a statement on a three-point scale including the categories of “disagree”, “neutral”, and “agree” in an ecological momentary assessment study that involves multiple daily assessments), and count variables (e.g., number of cigarettes smoked per day across a daily diary study). In many ways, the distributional assumptions of indicators used in longitudinal designs mirror the decision points and considerations when delineating across different types of discrete outcome variables, a topic that spans entire textbooks (e.g., see Lenz 2016). For example, the Mplus manual (Muthén 2017) includes examples of a) censored and censored-inflated models, b) linear growth models for binary or ordinal variables, c) linear growth models for a count outcome assuming a Poisson model, d) linear growth models for a count outcome assuming a zero-inflated Poisson model and e) discrete- and continuous-time survival analysis for a binary outcome. Beyond these highlighted examples, other distributions (e.g., negative binomial) can be assumed for the indicators when modeling longitudinal data. These models can account for issues that can occur when working with discrete outcomes, including overdispersion (when the variance is higher than would be expected based on a given distribution) and zero-inflation [when more zeros occur than is expected based on a given distribution; see Lenz (2016)]. Models involving zero-inflation parameters are referred to as two-part models, given one part of the model predicts the zero-inflation whereas the other part of the model predicts outcomes consistent with a given distribution [e.g., Poisson distribution; see Farewell et al. (2017), for a review of two-part models for longitudinal data]. Although there exist several alternative models for discrete indicators, some more recent models that have been proposed for prospective data are only feasible in cases where indicators are assumed to be continuous rather than discrete [e.g., LCM-SR; Curran et al. (2014)]. Given the sheer breadth of issues relevant to determining better models for discrete outcomes, it is not uncommon for texts on longitudinal data analysis to only cover models and approaches that assume continuous indicators (e.g., T. D. Little 2013). However, some textbooks on categorical data analysis provide more detailed coverage of the myriad issues and modeling choices to consider when working with discrete outcomes [e.g., Lenz (2016), Chapter 11 for matched pair/two-assessment designs; Chapter 12 for marginal and transitional models for repeated designs, such as generalized estimating equations, and Chapter 13 for random effects models for discrete outcomes]."
  },
  {
    "objectID": "manuscrip_test version.html#missing-dataattrition",
    "href": "manuscrip_test version.html#missing-dataattrition",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "Missing Data/Attrition",
    "text": "Missing Data/Attrition\nAs recently reviewed by Littlefield (in press), investigators of prospective data are confronted with study attrition (i.e., participants may not provide data at a given wave of assessment) and thus approaches are needed to confront the issue of missing data. Three models of missingness are typically considered in the literature (see R. J. Little and Rubin 1989). These three models are data: a) missing completely at random (MCAR), b) missing at random (MAR), and c) missing not at random (MNAR). Data that are MCAR means missing data is a random sample of all the types of participants (e.g., males) in a given dataset. MAR suggests conditionally missing at random (see Graham 2009). That is, MAR implies missingness is completely random (i.e., does not hinge on some unmeasured variables) once missingness has been adjusted by all available variables in a dataset (e.g., biological sex). Data that are MNAR are missing as a function of unobserved variables. Graham (2009) provides an excellent and easy-to-digest overview of further details involving missing data considerations.\nMultiple approaches have been posited to handle missing data. Before the advent of more contemporary approaches, common methods included several ad hoc procedures. These include eliminating the data of participants with missing data (e.g., listwise or pairwise deletion) or using mean imputation (i.e., replacing the missing value with the mean score of the sample that did participate). However, these methods are not recommended because they can contribute to biased parameter estimates and research conclusions (see Graham 2009). More specifically, the last observation carried forward (LOCF) is a common approach to imputing missing data. LOCF replaces a participant’s missing values after dropout with the last available measurement (Molnar, Hutton, and Fergusson 2008). This approach assumes stability (i.e., a given participant’s score is not anticipated to increase or decline after study dropout) and that the data are MCA R. However, as described by Molnar, Hutton, and Fergusson (2008), it is common for treatment groups to show higher attrition compared to control groups in studies of dementia drugs. Given that dementia worsens over time, using LOCF biases the results in favor of the treatment group (see Molnar, Hutton, and Fergusson 2008, for more details).\nMore modern approaches, such as using maximum likelihood or multiple imputation to estimate missing data, are thought to avoid some of the biases of older approaches (see Enders 2010; Graham 2009). Graham (2009) noted several “myths” regarding missing data. For example, Graham notes many assume the data must be minimally MAR to permit estimating procedures (such as maximum likelihood or multiple imputation) compared to other, more traditional approaches (e.g., using only complete case data). Violations of MAR impact both traditional and more modern data estimation procedures, though as noted by Graham, violations of MAR tend to have a greater effect on older methods. Graham thus suggests that estimating missing data is a better approach compared to the older procedures in most circumstances, regardless of the model of missingness [i.e., MCAR, MAR, MNAR; see Graham (2009)].\nAttrition from a longitudinal panel study such as ABCD is inevitable and represents a threat to the validity of longitudinal analyses and cross-sectional analyses conducted at later time points, especially since attrition can only be expected to grow over time. While, to date, attrition in ABCD has been minimal (some cite here), it remains an important focus for longitudinal analysis and its significance is likely to only grow as the cohort ages. Ideally, one tries to minimize attrition through good retention practices from the outset via strategies designed to maintain engagement in the project (Cotter et al. 2005; Hill et al. 2016; Watson et al. 2018). However, even the best-executed studies need to anticipate growing attrition over the length of the study and implement analytic strategies designed to provide the most valid inferences. Perhaps the most key concern when dealing with data that is missing due to attrition is determining the degree of bias in retained variables that is a consequence of attrition. Assuming that the data are not missing completely at random, attention to the nature of the missingness and employing techniques designed to mitigate attrition-related biases need to be considered in all longitudinal analyses. Several different approaches can be considered and employed depending upon the nature of the intended analyses, the degree of missingness, and data available to help estimate missing and unobserved values."
  },
  {
    "objectID": "manuscrip_test version.html#quantifying-effect-sizes-longitudinally",
    "href": "manuscrip_test version.html#quantifying-effect-sizes-longitudinally",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "Quantifying effect sizes longitudinally",
    "text": "Quantifying effect sizes longitudinally\nGiven longitudinal data involve different sources of variance, quantifying effect sizes longitudinally is a more difficult task compared to deriving such estimates from cross-sectional data. Effect size can be defined as, “a population parameter (estimated in a sample) encapsulating the practical or clinical importance of a phenomenon under study.” (Kraemer 2014). Common effect size metrics include r (i.e., the standardized covariance, or correlation, between two variables) and Cohen’s d (Cohen 1988). Adjustments to common effect size calculations, such as Cohen’s d, are required even when only two time points are considered (e.g., see Morris and DeShon 2002). Wang et al. (2019) note there are multiple approaches to obtaining standardized within-person effects, and that commonly suggested approaches (e.g., global standardization) can be problematic (see Wang et al. 2019, for more details). Thus, obtaining effect size metrics based on standardized estimates that are relatively simple in cross-sectional data (such as r) becomes more complex in the context of prospective data. Feingold (2009) noted that equations for effects sizes used in studies involving growth modeling analysis (e.g., latent growth curve modeling) were not mathematically equivalent, and the effect sizes were not in the same metric as effect sizes from traditional analysis (see Feingold 2009, for more details). Given this issue, there have been various proposals for adjusting effect size measures in repeated assessments. Feingold (2019) reviews the approach for effect size metrics for analyses based on growth modeling, including when considering linear and non-linear (i.e., quadratic) growth factors. Morris and DeShon (2002) review various equations for effect size calculations relevant to when combining estimates in meta-analysis with repeated measures and independent-groups designs. Other approaches to quantifying effect sizes longitudinally may be based on standardized estimates from models that more optimally disentangle between- and within-person sources of variance (as reviewed above). As an example, within a RI-CLPM framework, standardized estimates between random intercepts (i.e., the correlation between two random intercepts for two different constructs assessed repeatedly) could be used to index the between-person relation, whereas standardized estimates among the structured residuals could be used as informing the effect sizes of within-person relations."
  },
  {
    "objectID": "1a_HowTos_DifferenceScores_PairedTtests.html",
    "href": "1a_HowTos_DifferenceScores_PairedTtests.html",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "This example examines the question whether participants reported different mean levels of externalizing problems on the CBCL when measured at Baseline (T0) compared to when measured at the 1-Year follow-up (T1). This analysis is conducted in two primary steps: 1) computing a difference score (DiffScore = CBCL EXT T2 - CBCL EXT T1); 2) conducting a paired samples t-test on the difference score. Our primary aim is to determine whether average CBCL externalizing scores of the participants change from assessement 1 (T1) to assessement 2 (T2), while accounting for observations that are clustered within youth over time.\n\n\n\n\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n#rm(list = ls())\n\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nif (!(\"lmerTest\" %in% installed.packages())) install.packages(\"lmerTest\")\nif (!(\"tidyverse\" %in% installed.packages())) install.packages(\"tidyverse\")\nif (!(\"arrow\" %in% installed.packages())) install.packages(\"arrow\")\nif (!(\"arsenal\" %in% installed.packages())) install.packages(\"arsenal\")\nif (!(\"kableExtra\" %in% installed.packages())) install.packages(\"kableExtra\")\nif (!(\"ggpubr\" %in% installed.packages())) install.packages(\"ggpubr\")\nif (!(\"rstatix\" %in% installed.packages())) install.packages(\"rstatix\")\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\n#rm(list = ls())\n\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(rstatix)\nlibrary(ggpubr)\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                                  comment=NA, cache=T, code_folding=T,\n                                  R.options=list(width=220), fig.align='center', \n                                  out.width='75%', fig.asp=.75)\n\n\n\n\n\n\n\n\n\n\nRead and View DataContinuous OutcomesCategorical Outcomes\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n## Read data\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\ndf_wide &lt;- read_csv(\"/Users/shawes/Desktop/data/df_wide.csv\")\n\n# set types\ndf_long$ids &lt;- as.factor(df_long$ids)\ndf_long$event &lt;- as.factor(df_long$event)\ndf_long$site_id &lt;- as.factor(df_long$site_id)\ndf_long$fam_id &lt;- as.factor(df_long$fam_id)\ndf_long$sex &lt;- as.factor(df_long$sex)\ndf_long$age &lt;- as.numeric(df_long$age)\ndf_long$mature_vg &lt;- as.numeric(df_long$mature_vg)\ndf_long$cbcl_extern &lt;- as.numeric(df_long$cbcl_extern)\ndf_long$vg_total &lt;- as.numeric(df_long$vg_total)\n\n\n\n\n\n\nThis code creates a table of descriptive information for continuous outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_1 &lt;- tableby.control(test=FALSE, total=FALSE, numeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"), #\"Nmiss2\"\ncat.stats=c(\"countpct\"), #\"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median ='Median', \n                  range='Min - Max'))  #, Nmiss2 ='Missing'\nmy_cont_labels &lt;- list(age = \"Age\", vg_total = \"Weekly # of Video Gaming Hrs\",\n            cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                                      cbcl_extern,\n                                      data=df_long, control=tab_descriptives_1)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", \n                full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15, position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;% \n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis code creates a descriptives table for categorical outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n), # \"Nmiss2\"\ncat.stats=c(\"countpct\"), # \"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n)) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n          \ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, data=df_long, control=tab_descriptives_2)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n            summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Categorical Outcomes\") %&gt;%\n            kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size =\n                            15, position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild Model\n\n\nThe code snippet below tells R to compute a difference score by subtracting each participant’s Externalizing score at T2 from their Externalizing score at T1. Next, a one-sample t-test is computed to examine whether the average difference score is different than zero (indicating change).\nSTEP 1: Compute Difference Score\n\n\nCode\n# Compute difference score based on CBCL Externalizing subscale scores at baseline (t1) and 1-Year Follow-up (t2)\ndf_wide$diffscore &lt;- df_wide$cbcl_extern_Year_1 - df_wide$cbcl_extern_Baseline\n\n\n\n\nCode\n# Compute statistical summaries for the difference score variable\nsummary(df_wide$diffscore)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-27.000   1.000   5.000   5.576   8.000  33.000 \n\n\nThis summary of the difference score variable indicates xxxxx.\n\n\nCode\nhist(df_long$vg_total)\n\n\n\n\n\nCode\n## Summary statistics\nsummary&lt;-df_long %&gt;%\ngroup_by(event) %&gt;%\nget_summary_stats(cbcl_extern, type = \"mean_sd\")\ndata.frame(summary)\n\n\n\n\n  \n\n\n\nThis histogram indicates xxxxxx. The summary command shows xxxxxx.\n\n\nCode\n### Shapiro-Wilk test and normality (Q-Q) plot (visualization of correlation between a given sample and the normal distribution)\nshapiro.test(df_wide$cbcl_extern_Baseline[0:5000])\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  df_wide$cbcl_extern_Baseline[0:5000]\nW = 0.67151, p-value = 1.452e-13\n\n\nThis Shapiro-Wilkes test shows xxxxxx.\n\n\nCode\nqqplot &lt;- ggqqplot(df_wide$cbcl_extern_Baseline,\n    ylab = \"Externalizing Difference Score\", xlab = FALSE,\n    ggtheme = theme_minimal()\n)\n\nsuppressWarnings(print(qqplot)) \n\n\n\n\n\nThis qqplot shows xxxxxx.\nSTEP 2: Conduct t-test on Difference Score\n\n\nCode\n# One-sample t-test to determine whether the average difference score is significantly different than 0.\nresult &lt;- t.test(df_wide$cbcl_extern_Baseline, mu = 0, alternative = \"two.sided\")\n# Print the results\nresult\n\n\n\n    One Sample t-test\n\ndata:  df_wide$cbcl_extern_Baseline\nt = 6.3752, df = 98, p-value = 6.01e-09\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 2.003549 3.814633\nsample estimates:\nmean of x \n 2.909091 \n\n\n\n\n\nThe output from our model provides: i. a t-statistic ii. degrees of freedom under iii. p-value (&lt; .05 then we reject the null hypothesis) iv. a mean estimate v. 95% confidence intervals\nIn our example p = .002 which is less than .05 then we reject the null hypothesis and conclude that the mean difference score µ is different from zero. So we can conclude that there𝐷 is a difference between cbcl externalizing scores from t1 to t2. This output also provides the mean for cbcl externalizing scores (4.45),as well as the correpsonding confidence intervals\n\n\n\n\n\ntesting\n# Scatterplot to visualize relationship between t1 & t2 data used to create difference score\nscatterplot &lt;- ggplot(df_wide, aes(x = cbcl_extern_Baseline, y = cbcl_extern_Year_1)) +\n    geom_point(size = 3) +\n    geom_smooth(method = lm, se = F) +\n    xlab(\"CBCL Externalizing (x) Baseline\") +\n    ylab(\"CBCL Externalizing (x) 1-Year Follow-up\")\n\nsuppressWarnings(print(scatterplot))\n\n\n\n\n\nExamination of this scatterplot indicates xxxxx.\n\n\ntesting\n### boxplot\ndiffscore_boxplot &lt;- ggboxplot(df_wide$cbcl_extern_Baseline,\n    ylab = \"Externalizing Difference Score\", xlab = FALSE,\n    ggtheme = theme_minimal()\n)\n\nsuppressWarnings(print(diffscore_boxplot))\n\n\n\n\n\nExamination of this boxplot indicates xxxxx.\n\n\nThis output shows xxxxxxxx. Briefly walk through each metric :::\n\n\n\n\n\n\n\n\nWrite-up\n\n\n\nA paired samples t test was conducted to compare differences in participants cbcl externalzing scores measured across two timepoints. Findings indicated that there was a difference between cbcl externalzing scores obtained at T1 compared to cbcl externalzing scores obtained at T2, t(179) = 3.10, p = .002, Cohen’s d = 0.23. Youth exhibited an increase of cbcl externalzing scores at t2 ( M = 5.67, SD = 1.24) compared to t1 ( M = 5.83, SD = 1.21)."
  },
  {
    "objectID": "1a_HowTos_DifferenceScores_PairedTtests.html#overview",
    "href": "1a_HowTos_DifferenceScores_PairedTtests.html#overview",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "This example examines the question whether participants reported different mean levels of externalizing problems on the CBCL when measured at Baseline (T0) compared to when measured at the 1-Year follow-up (T1). This analysis is conducted in two primary steps: 1) computing a difference score (DiffScore = CBCL EXT T2 - CBCL EXT T1); 2) conducting a paired samples t-test on the difference score. Our primary aim is to determine whether average CBCL externalizing scores of the participants change from assessement 1 (T1) to assessement 2 (T2), while accounting for observations that are clustered within youth over time."
  },
  {
    "objectID": "1a_HowTos_DifferenceScores_PairedTtests.html#preliminary-setup",
    "href": "1a_HowTos_DifferenceScores_PairedTtests.html#preliminary-setup",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "Install PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n#rm(list = ls())\n\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nif (!(\"lmerTest\" %in% installed.packages())) install.packages(\"lmerTest\")\nif (!(\"tidyverse\" %in% installed.packages())) install.packages(\"tidyverse\")\nif (!(\"arrow\" %in% installed.packages())) install.packages(\"arrow\")\nif (!(\"arsenal\" %in% installed.packages())) install.packages(\"arsenal\")\nif (!(\"kableExtra\" %in% installed.packages())) install.packages(\"kableExtra\")\nif (!(\"ggpubr\" %in% installed.packages())) install.packages(\"ggpubr\")\nif (!(\"rstatix\" %in% installed.packages())) install.packages(\"rstatix\")\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\n#rm(list = ls())\n\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(rstatix)\nlibrary(ggpubr)\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                                  comment=NA, cache=T, code_folding=T,\n                                  R.options=list(width=220), fig.align='center', \n                                  out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "1a_HowTos_DifferenceScores_PairedTtests.html#descriptives-overview",
    "href": "1a_HowTos_DifferenceScores_PairedTtests.html#descriptives-overview",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "Read and View DataContinuous OutcomesCategorical Outcomes\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n## Read data\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\ndf_wide &lt;- read_csv(\"/Users/shawes/Desktop/data/df_wide.csv\")\n\n# set types\ndf_long$ids &lt;- as.factor(df_long$ids)\ndf_long$event &lt;- as.factor(df_long$event)\ndf_long$site_id &lt;- as.factor(df_long$site_id)\ndf_long$fam_id &lt;- as.factor(df_long$fam_id)\ndf_long$sex &lt;- as.factor(df_long$sex)\ndf_long$age &lt;- as.numeric(df_long$age)\ndf_long$mature_vg &lt;- as.numeric(df_long$mature_vg)\ndf_long$cbcl_extern &lt;- as.numeric(df_long$cbcl_extern)\ndf_long$vg_total &lt;- as.numeric(df_long$vg_total)\n\n\n\n\n\n\nThis code creates a table of descriptive information for continuous outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_1 &lt;- tableby.control(test=FALSE, total=FALSE, numeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"), #\"Nmiss2\"\ncat.stats=c(\"countpct\"), #\"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median ='Median', \n                  range='Min - Max'))  #, Nmiss2 ='Missing'\nmy_cont_labels &lt;- list(age = \"Age\", vg_total = \"Weekly # of Video Gaming Hrs\",\n            cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                                      cbcl_extern,\n                                      data=df_long, control=tab_descriptives_1)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", \n                full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15, position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;% \n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis code creates a descriptives table for categorical outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n), # \"Nmiss2\"\ncat.stats=c(\"countpct\"), # \"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n)) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n          \ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, data=df_long, control=tab_descriptives_2)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n            summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Categorical Outcomes\") %&gt;%\n            kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size =\n                            15, position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table."
  },
  {
    "objectID": "1a_HowTos_DifferenceScores_PairedTtests.html#results",
    "href": "1a_HowTos_DifferenceScores_PairedTtests.html#results",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "Build Model\n\n\nThe code snippet below tells R to compute a difference score by subtracting each participant’s Externalizing score at T2 from their Externalizing score at T1. Next, a one-sample t-test is computed to examine whether the average difference score is different than zero (indicating change).\nSTEP 1: Compute Difference Score\n\n\nCode\n# Compute difference score based on CBCL Externalizing subscale scores at baseline (t1) and 1-Year Follow-up (t2)\ndf_wide$diffscore &lt;- df_wide$cbcl_extern_Year_1 - df_wide$cbcl_extern_Baseline\n\n\n\n\nCode\n# Compute statistical summaries for the difference score variable\nsummary(df_wide$diffscore)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-27.000   1.000   5.000   5.576   8.000  33.000 \n\n\nThis summary of the difference score variable indicates xxxxx.\n\n\nCode\nhist(df_long$vg_total)\n\n\n\n\n\nCode\n## Summary statistics\nsummary&lt;-df_long %&gt;%\ngroup_by(event) %&gt;%\nget_summary_stats(cbcl_extern, type = \"mean_sd\")\ndata.frame(summary)\n\n\n\n\n  \n\n\n\nThis histogram indicates xxxxxx. The summary command shows xxxxxx.\n\n\nCode\n### Shapiro-Wilk test and normality (Q-Q) plot (visualization of correlation between a given sample and the normal distribution)\nshapiro.test(df_wide$cbcl_extern_Baseline[0:5000])\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  df_wide$cbcl_extern_Baseline[0:5000]\nW = 0.67151, p-value = 1.452e-13\n\n\nThis Shapiro-Wilkes test shows xxxxxx.\n\n\nCode\nqqplot &lt;- ggqqplot(df_wide$cbcl_extern_Baseline,\n    ylab = \"Externalizing Difference Score\", xlab = FALSE,\n    ggtheme = theme_minimal()\n)\n\nsuppressWarnings(print(qqplot)) \n\n\n\n\n\nThis qqplot shows xxxxxx.\nSTEP 2: Conduct t-test on Difference Score\n\n\nCode\n# One-sample t-test to determine whether the average difference score is significantly different than 0.\nresult &lt;- t.test(df_wide$cbcl_extern_Baseline, mu = 0, alternative = \"two.sided\")\n# Print the results\nresult\n\n\n\n    One Sample t-test\n\ndata:  df_wide$cbcl_extern_Baseline\nt = 6.3752, df = 98, p-value = 6.01e-09\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 2.003549 3.814633\nsample estimates:\nmean of x \n 2.909091 \n\n\n\n\n\nThe output from our model provides: i. a t-statistic ii. degrees of freedom under iii. p-value (&lt; .05 then we reject the null hypothesis) iv. a mean estimate v. 95% confidence intervals\nIn our example p = .002 which is less than .05 then we reject the null hypothesis and conclude that the mean difference score µ is different from zero. So we can conclude that there𝐷 is a difference between cbcl externalizing scores from t1 to t2. This output also provides the mean for cbcl externalizing scores (4.45),as well as the correpsonding confidence intervals\n\n\n\n\n\ntesting\n# Scatterplot to visualize relationship between t1 & t2 data used to create difference score\nscatterplot &lt;- ggplot(df_wide, aes(x = cbcl_extern_Baseline, y = cbcl_extern_Year_1)) +\n    geom_point(size = 3) +\n    geom_smooth(method = lm, se = F) +\n    xlab(\"CBCL Externalizing (x) Baseline\") +\n    ylab(\"CBCL Externalizing (x) 1-Year Follow-up\")\n\nsuppressWarnings(print(scatterplot))\n\n\n\n\n\nExamination of this scatterplot indicates xxxxx.\n\n\ntesting\n### boxplot\ndiffscore_boxplot &lt;- ggboxplot(df_wide$cbcl_extern_Baseline,\n    ylab = \"Externalizing Difference Score\", xlab = FALSE,\n    ggtheme = theme_minimal()\n)\n\nsuppressWarnings(print(diffscore_boxplot))\n\n\n\n\n\nExamination of this boxplot indicates xxxxx.\n\n\nThis output shows xxxxxxxx. Briefly walk through each metric :::"
  },
  {
    "objectID": "1a_HowTos_DifferenceScores_PairedTtests.html#wrapping-up",
    "href": "1a_HowTos_DifferenceScores_PairedTtests.html#wrapping-up",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "Write-up\n\n\n\nA paired samples t test was conducted to compare differences in participants cbcl externalzing scores measured across two timepoints. Findings indicated that there was a difference between cbcl externalzing scores obtained at T1 compared to cbcl externalzing scores obtained at T2, t(179) = 3.10, p = .002, Cohen’s d = 0.23. Youth exhibited an increase of cbcl externalzing scores at t2 ( M = 5.67, SD = 1.24) compared to t1 ( M = 5.83, SD = 1.21)."
  },
  {
    "objectID": "3b_HowTos_LinearMixedModels.html",
    "href": "3b_HowTos_LinearMixedModels.html",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "In this example, we will use the LMM:ri to analyze trajectories of scores on the externalizing subscale of the child behavior checklist (CBCL) obtained across three measurement occasions in a sample of youth taking part in the ABCD Study. Our primary aim is to characterize stability and change in CBCL externalizing scores across assessments, while accounting for observations that are clustered within youth over time. To do so, we will use the LMM:ri to simultaneously model an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory.\n\n\n\n\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\n\nCode\n#rm(list = ls())\n\n#Load packages\n#library(lme4)\n#library(lmerTest)\n#library(tidyverse)\n#library(afex)\n#library(janitor)\n#library(skimr)\n#library(sdamr)\n\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(afex)\nlibrary(janitor)\nlibrary(skimr)\nlibrary(sdamr)\nlibrary(formatR)\nlibrary(report)\nlibrary(easystats)\nlibrary(emmeans)\nlibrary(poorman)\nlibrary(parameters)\nlibrary(modelbased)\nlibrary(DT)\nlibrary(data.table)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(equatiomatic)\nlibrary(gtsummary)\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                        comment=NA, cache=T, code_folding=T,\n                        R.options=list(width=220), fig.align='center',\n                        out.width='75%', fig.asp=.75)\n\n\n\n\n\n\n\n\n\n\nRead and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n## Read data\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\n#df_wide &lt;- read_csv(\"/path/to/datafile\")\n\n# set types (if necessary)\n#df_long$x &lt;- as.factor(df_long$x)\n#df_long$y &lt;- as.numeric(df_long$y)\n\n\n\n\n\n\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ndescriptives_1  &lt;- tableby.control(test=FALSE, total=FALSE,\n                               numeric.test=\"kwt\", cat.test=\"chisq\",\n                               numeric.stats=c(\"N\", \"meansd\", \"median\", \"range\" \n                                               ), #\"Nmiss2\"\n                               cat.stats=c(\"countpct\"), #\"Nmiss2\"\n                               stats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n                                                 ='Median', range='Min - Max'\n                                                 )) #, Nmiss2 ='Missing'\n\nmy_cont_labels &lt;- list(\n  age = \"Age\",\n  vg_total = \"Weekly # of Video Gaming Hrs\",\n  cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                            cbcl_extern,\n                            data=df_long, control=descriptives_1)\n\n#summary(tab_descriptives_1, labelTranslations = my_cont_labels , text=TRUE, title = #\"Continuous Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ndescriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\n                               numeric.test=\"kwt\", cat.test=\"chisq\",\n                               numeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n                                               ), # \"Nmiss2\"\n                               cat.stats=c(\"countpct\"), # \"Nmiss2\"\n                               stats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n                                                 ='Median', range='Min - Max'\n                                                 )) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n\ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, \n                            data=df_long, control=descriptives_2)\n\n#summary(tab_descriptives_2, labelTranslations = my_cat_labels , text=TRUE, title = #\"Categorical Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Categorical Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: panel-tabset ### Build Model {.tabset .tabset-fade .tabset-pills}\n::: blue\nThe code snippet below tells R to compute xxxxx by xxxxxxx. Next, xxxxx is conducted to examine whether xxxxxx does xxxxxxx (indicating xxxxx). The xxxx function (xxx) is provided by the r ‘xxx’ package. The code above is very similar to the code for the random intercept model, except that now we use the code (1 + Days | Subject) to specify a random intercept for each Subject, and a random slope of Days for each Subject. This allows both the intercept and the slope of days to vary across participants.\nSTEP 1: Compute xxxxxxxx\n\n\nCode\n## Linear Mixed Model with a random intercept (LMM-ri)\n#really still an intercept only model\nrandom_slopes &lt;- lmer(cbcl_extern ~ 1 + event + (1|ids), data = df_long, REML=F)\nprint(random_slopes)\n\n\nLinear mixed model fit by maximum likelihood  ['lmerModLmerTest']\nFormula: cbcl_extern ~ 1 + event + (1 | ids)\n   Data: df_long\n      AIC       BIC    logLik  deviance  df.resid \n 606.4845  619.4601 -298.2423  596.4845        94 \nRandom effects:\n Groups   Name        Std.Dev.\n ids      (Intercept) 4.881   \n Residual             3.528   \nNumber of obs: 99, groups:  ids, 37\nFixed Effects:\n(Intercept)  eventYear_1  eventYear_2  \n     4.5897       0.7558       1.7460  \n\n\n\n\ntesting\nsummary(random_slopes)\n\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: cbcl_extern ~ 1 + event + (1 | ids)\n   Data: df_long\n\n     AIC      BIC   logLik deviance df.resid \n   606.5    619.5   -298.2    596.5       94 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.7525 -0.4865 -0.1845  0.2842  2.9679 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ids      (Intercept) 23.82    4.881   \n Residual             12.45    3.528   \nNumber of obs: 99, groups:  ids, 37\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)   4.5897     1.0059 59.7864   4.563 2.56e-05 ***\neventYear_1   0.7558     0.8618 64.8217   0.877   0.3837    \neventYear_2   1.7460     0.9021 65.6574   1.935   0.0572 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) evnY_1\neventYear_1 -0.419       \neventYear_2 -0.401  0.475\n\n\ntesting\n## Output and reports extending from the LMM-ri analyses\nsummary(random_slopes)\n\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: cbcl_extern ~ 1 + event + (1 | ids)\n   Data: df_long\n\n     AIC      BIC   logLik deviance df.resid \n   606.5    619.5   -298.2    596.5       94 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.7525 -0.4865 -0.1845  0.2842  2.9679 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ids      (Intercept) 23.82    4.881   \n Residual             12.45    3.528   \nNumber of obs: 99, groups:  ids, 37\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)   4.5897     1.0059 59.7864   4.563 2.56e-05 ***\neventYear_1   0.7558     0.8618 64.8217   0.877   0.3837    \neventYear_2   1.7460     0.9021 65.6574   1.935   0.0572 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) evnY_1\neventYear_1 -0.419       \neventYear_2 -0.401  0.475\n\n\ntesting\nconfint(random_slopes, level = 0.95, method = \"Wald\")\n\n\n                  2.5 %   97.5 %\n.sig01               NA       NA\n.sigma               NA       NA\n(Intercept)  2.61814609 6.561329\neventYear_1 -0.93332355 2.445020\neventYear_2 -0.02209218 3.514008\n\n\ntesting\nreport(random_slopes)\n\n\nWe fitted a linear mixed model (estimated using ML and nloptwrap optimizer) to\npredict cbcl_extern with event (formula: cbcl_extern ~ 1 + event). The model\nincluded ids as random effect (formula: ~1 | ids). The model's total\nexplanatory power is substantial (conditional R2 = 0.66) and the part related\nto the fixed effects alone (marginal R2) is of 0.01. The model's intercept,\ncorresponding to event = Baseline, is at 4.59 (95% CI [2.59, 6.59], t(94) =\n4.56, p &lt; .001). Within this model:\n\n  - The effect of event [Year_1] is statistically non-significant and positive\n(beta = 0.76, 95% CI [-0.96, 2.47], t(94) = 0.88, p = 0.383; Std. beta = 0.12,\n95% CI [-0.15, 0.40])\n  - The effect of event [Year_2] is statistically non-significant and positive\n(beta = 1.75, 95% CI [-0.05, 3.54], t(94) = 1.94, p = 0.056; Std. beta = 0.28,\n95% CI [-7.28e-03, 0.57])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\ntesting\nreport_performance(random_slopes)\n\n\nThe model's total explanatory power is substantial (conditional R2 = 0.66) and\nthe part related to the fixed effects alone (marginal R2) is of 0.01\n\n\ntesting\nreport_statistics(random_slopes)\n\n\nbeta = 4.59, 95% CI [2.59, 6.59], t(94) = 4.56, p &lt; .001; Std. beta = -0.17, 95% CI [-0.50, 0.15]\nbeta = 0.76, 95% CI [-0.96, 2.47], t(94) = 0.88, p = 0.383; Std. beta = 0.12, 95% CI [-0.15, 0.40]\nbeta = 1.75, 95% CI [-0.05, 3.54], t(94) = 1.94, p = 0.056; Std. beta = 0.28, 95% CI [-7.28e-03, 0.57]\n\n\ntesting\nrandom &lt;- estimate_grouplevel(random_slopes)\n\n\n\nThe summary function is used to print out the results from the random intercept model and\nSTEP 2: Conduct xxxxxxx\n\n\nCode\n## Obtain LMM-ri model parameters to plot/graph of results\n## Fixed-Effects\nmodel_intercept &lt;- rep(coef(random_slopes)$ids[,1], each = 4)\nslopes2 &lt;- rep(coef(random_slopes)$ids[,2], each = 4)\n#This code allows for extracting the fixed effects estimates for the model intercept and slope.\n\n\nThe output from our model provides: i. a parameter estimate; ii. standard error; iii. p-value. In our example p = .001 which is less than .05 indicating significant differences in predicted cbcl externalizing scores between boys and girls in the ABCD Study. An examination of the regression coeefficient for sex (female = 0; male = 1) is b = .xx, indicating the difference in cbcl externalizing scores from Time 1 to Time 2 is significantly greater in boys taking part in the ABCD Study relative to girls. Then we conclude that participant sex (does/does not) predict change in cbcl externalizing scores from t1 to t2.\nFrom the fixed effects section of the model summary, we can conclude that there is strong evidence that number of days of sleep deprivation significantly increased reaction time under a significance level of 0.05. On average, for each additional day of sleep deprivation, reaction time increased by 10.47ms (b = 10.47, SE = 1.55, p &lt; .001).\nWe are 95% confident that the average increase was between 7.44 and 13.50.\nFrom the fixed effects section, we estimated the average intercept and average effect of days of sleep deprivation (slopes of Days). We also estimated the corresponding 95% confidence intervals. Using the results from the random effects section, we can calculate the coverage intervals for both the intercept and the slope.\nThe variance of the intercept and for the slope of Days is 612.1 and 35.1 respectively. Taking their square root, the corresponding standard deviations are 24.7 and 5.9. The 95% coverage interval of the intercept is 251.4 ± 1.96*24.7. The lower bound is 203.0 and the upper bound is 299.8. It is therefore estimated that 95% of the participants had a reaction time between 203.0 and 299.8 at Day 0.\nThe 95% coverage interval of the slope of Days is 10.5 ± 1.96*5.9. The lower bound is -1.1 and the upper bound is 22.1. It is therefore estimated that for 95% of the participants, the effect of each additional day of sleep deprivation was between -1.1 and 22.1. This is not to be confused with the 95% confidence interval (7.4 and 13.5), which means that we are 95% confident that average effect (across all participants) of each additional day of sleep deprivation on reaction time was between 7.4 and 13.5. The model now estimates a variance of the random slopes effects, as well as a correlation between the random intercept and slope effects. :::\n\n\nCode\n# # ! THIS PLOT RUNS & PRINTS TO SCREEN. I am temporarily commenting it out due to a side-effect of the \n# #\"intercepts2 variable\"\n# ggplot(df_long, aes(x = event, y = cbcl_extern)) + \n#   geom_abline(model_slope = slopes2, model_intercept = intercepts2, \n#               linetype = \"solid\", color = \"black\", linewidth = 1) + \n#   # geom_abline(mapping = aes(slopes2 = model_slope, intercepts2 = model_intercept, linetype = PID), \n#   #             linetype = \"dashed\", color = \"grey70\", linewidth = .4) +\n#   #geom_point(aes(shape = ids), size = 3.25, color = \"grey70\") + \n#   #scale_shape_manual() + \n#   # geom_segment(aes(x = event, xend = event, \n#   #                  y = cbcl1, yend = fitted(model_slope)), \n#   #              color = \"grey70\") +\n#   scale_y_continuous(expand = c(0, 0), breaks = c(0, 100, 200, 300, 400, 500), \n#                      limits = c(0, 500)) +\n#   scale_x_continuous(expand = c(0, 0), breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), \n#                      limits = c(-0.5, 10.5)) +\n#   theme(panel.background = element_blank(),         \n#           panel.grid.major = element_blank(),\n#             panel.grid.minor = element_blank(),\n#             panel.border = element_rect(colour = \"black\", fill = NA),\n#           legend.position = \"none\", \n#           axis.text = element_text(size = 14),\n#           axis.title = element_text(size = 14)) +\n#     labs (x = \"event\", y = \"cbcl_extern\") \n#   \n# #Save the figure\n#  ggsave(\"random_slopes.png\", units = \"in\", width = 9, height = 6, dpi = 300)\n\n\n\n\n:::blue\n\n\nCode\n# #| messages: FALSE\n# #| warning: FALSE\n# #| echo: FALSE\n# #| column: screen-inset-shaded\n# #| layout-nrow: 2\n#     \n# ## xxxxx plot\n# random_intercepts.std &lt;- resid(model_intercept)/sd(resid(model_intercept))\n# plot (random_intercepts.std, ylab=\"Standardized Residuals\")\n# \n# ## Outlier Tests. \n# #car::outlierTest(random_intercepts)\n# car::infIndexPlot(random_intercepts)\n# \n# ## qqplot\n# ggplot(as.data.frame(random_intercepts.std), aes(sample = random_intercepts.std)) +\n#   geom_qq() +\n#   geom_qq_line()\n# \n# ## Predicted vs Actual plot\n# predicted &lt;- estimate_expectation(random_intercepts, data = \"grid\")\n# plot(predicted)\n# \n# ## Estimated means plot\n# means &lt;- estimate_means(random_intercepts)\n# plot(means)\n\n\n#Build diagnostic plots. Observations with a Bonferroni p &lt; .05 might #be considered as outliers and might need further investigation. Examination of this scatterplot indicates xxxxx.\n\n\nCode\n# Basic ggplot2 barplot with mean\np &lt;-df_long %&gt;%\n    filter(!is.na(event)) %&gt;% # filter on non-missing values  \n    ggplot(aes(x = mature_vg, y = cbcl_extern, fill = sex)) +\n    geom_col(position = \"dodge\",\n           stat = \"summary\",\n           fun = \"mean\",\n           #fill = \"#AA4A44\",\n           #color = \"#0099f9\"\n           ) +\n    #scale_fill_brewer(palette = \"Set1\") +\n    scale_fill_manual(values = c(\"#3db5ff\", \"#0099f9\")) +\n    #scale_fill_gradient(high = \"#B00B69\", low = \"#0e0e63\") +\n    #geom_text(aes(label = cu_traits), position = position_dodge(0.9), \n              #vjust = 2, size = 4, color = \"#ffffff\") +\n    labs(title = \"Behavior Problems by Video Game Groups\", subtitle = \"Simple bar chart\",\n         caption = \"Simple caption\", x = \"DBD Group\", y = \"CBCL Externalizing\") +\n              #coord_flip() +\n    #geom_hline(yintercept = mean(df$cbcl_agg), linetype = \"dashed\", size = 1) +\n    theme_minimal() +\n    theme(\n          plot.title = element_text(color = \"#0099f9\", size = 20, hjust = 0.5),\n          plot.subtitle = element_text(face = \"bold\", hjust = 1),\n          plot.caption = element_text(face = \"italic\", hjust = 0),\n            axis.title.x = element_text(color = \"#0099f9\", size = 15, face = \"bold\"),\n            axis.title.y = element_text(size = 15, face = \"italic\")\n    )\n\n\nExamination of this scatterplot indicates xxxxx.\n\n\nCode\n#Random Intercept LMM Plot/Graph\n#random_intercepts &lt;- lmer(Externalizing ~ 1 + Event + DBD + Sex + (1|ids), data = df, #REML=T)\n\n##  LMM-ri plot of estimated random intercepts \nmodel &lt;- lmer(cbcl_extern ~ mature_vg + (1 | sex), data = df_long)\npreds &lt;- estimate_relation(model, include_random = TRUE)\n    \n## Adding fixed effect trajectory to LMM-ri plot \nfixed_pred &lt;- estimate_relation(model) # This time, include_random is FALSE (default)\n plot(preds, ribbon = list(alpha = 0)) + # Previous plot\n  geom_ribbon(data = fixed_pred, aes(x = mature_vg, ymin = CI_low, ymax = CI_high), alpha = 0.4) +\n  geom_line(data = fixed_pred, aes(x = mature_vg, y = Predicted), size = 2)\n\n\n\n\n\nCode\n# ggplot(df_long_sub, aes(x = event, y = cbcl_agg, color=sex, shape=sex)) + \n# geom_abline(slope = model_slope, intercept = model_intercept, linetype = \"solid\", color = \"red\", linewidth = 1) + \n# geom_point(color = \"grey70\") + \n# geom_smooth(method=lm, se=FALSE, fullrange=TRUE)+\n# scale_shape() + \n# geom_segment(aes(x = event, xend = event, y = cbcl_agg, yend = fitted(cbcl_agg)), color = \"grey70\") + \n# scale_y_continuous(expand = c(0, 0), breaks = c(0, 20, 40, 60, 80, 100), limits = c(0, 100)) + \n# scale_x_continuous(expand = c(0, 0), breaks = c(1, 2, 3, 4), limits = c(0, 4)) +\n# theme(panel.background = element_blank(),         \n#         panel.grid.major = element_blank(),\n#         panel.grid.minor = element_blank(),\n#         panel.border = element_rect(colour = \"black\", fill = NA),\n#         legend.position = \"none\",\n#         axis.text = element_text(size = 14), \n#         axis.title = element_text(size = 14)) +\n#         labs (x = \"Event\", y= \"CBCL Aggression\")\n\n#Save the plot\n#ggsave(\"random_intercept.png\", units = \"in\", width = 9, height = 6, dpi = 300)  \n\n\n\nFigure x: The overall group-mean (fixed effects) trajectory is shown in blue. The faded lines represent each individual youth’s estimated trajectory. An examination of this figure shows happiness scores to be increasing across measurement occasions, however, there appears to be substantial variability in the youth’s initial happiness scores.\n\nExamination of this barplot indicates xxxxx.\n\n\n\n\n\n\n\n\n::: panel-tabset ### Write-up {.tabset .tabset-fade .tabset-pills}\n\nA random slope model is used to test if sleep deprivation affects reaction time. To account for the repeated measures design, a random intercept was specified for participants. The random slope for days of sleep deprivation was included in the model to allow the effect of sleep deprivation to vary across participants. Results are shown in Table 1. Using a significant level of 0.05, results indicate that sleep deprivation significantly increased reaction time. On average, each additional day of sleep deprivation increased reaction time by 10.47ms (b = 10.47, 95% CI = [7.44, 13.50], p &lt; .001). Model fit comparison between model with and without random slope for sleep deprivation shows that the effect of sleep deprivation varied across participants, χ2(2)= 42.14, p &lt; .001. The 95% coverage interval for the random slope of sleep deprivation is (-1.14, 22.07), indicating that the effect of sleep deprivation was between -1.14 and 22.07 for 95% of the participants.\n\n\n\n\n(brown2021?)"
  },
  {
    "objectID": "3b_HowTos_LinearMixedModels.html#overview",
    "href": "3b_HowTos_LinearMixedModels.html#overview",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "In this example, we will use the LMM:ri to analyze trajectories of scores on the externalizing subscale of the child behavior checklist (CBCL) obtained across three measurement occasions in a sample of youth taking part in the ABCD Study. Our primary aim is to characterize stability and change in CBCL externalizing scores across assessments, while accounting for observations that are clustered within youth over time. To do so, we will use the LMM:ri to simultaneously model an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory."
  },
  {
    "objectID": "3b_HowTos_LinearMixedModels.html#preliminary-setup",
    "href": "3b_HowTos_LinearMixedModels.html#preliminary-setup",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "Install PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\n\nCode\n#rm(list = ls())\n\n#Load packages\n#library(lme4)\n#library(lmerTest)\n#library(tidyverse)\n#library(afex)\n#library(janitor)\n#library(skimr)\n#library(sdamr)\n\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(afex)\nlibrary(janitor)\nlibrary(skimr)\nlibrary(sdamr)\nlibrary(formatR)\nlibrary(report)\nlibrary(easystats)\nlibrary(emmeans)\nlibrary(poorman)\nlibrary(parameters)\nlibrary(modelbased)\nlibrary(DT)\nlibrary(data.table)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(equatiomatic)\nlibrary(gtsummary)\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                        comment=NA, cache=T, code_folding=T,\n                        R.options=list(width=220), fig.align='center',\n                        out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "3b_HowTos_LinearMixedModels.html#descriptives-overview",
    "href": "3b_HowTos_LinearMixedModels.html#descriptives-overview",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "Read and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n## Read data\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\n#df_wide &lt;- read_csv(\"/path/to/datafile\")\n\n# set types (if necessary)\n#df_long$x &lt;- as.factor(df_long$x)\n#df_long$y &lt;- as.numeric(df_long$y)\n\n\n\n\n\n\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ndescriptives_1  &lt;- tableby.control(test=FALSE, total=FALSE,\n                               numeric.test=\"kwt\", cat.test=\"chisq\",\n                               numeric.stats=c(\"N\", \"meansd\", \"median\", \"range\" \n                                               ), #\"Nmiss2\"\n                               cat.stats=c(\"countpct\"), #\"Nmiss2\"\n                               stats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n                                                 ='Median', range='Min - Max'\n                                                 )) #, Nmiss2 ='Missing'\n\nmy_cont_labels &lt;- list(\n  age = \"Age\",\n  vg_total = \"Weekly # of Video Gaming Hrs\",\n  cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                            cbcl_extern,\n                            data=df_long, control=descriptives_1)\n\n#summary(tab_descriptives_1, labelTranslations = my_cont_labels , text=TRUE, title = #\"Continuous Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ndescriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\n                               numeric.test=\"kwt\", cat.test=\"chisq\",\n                               numeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n                                               ), # \"Nmiss2\"\n                               cat.stats=c(\"countpct\"), # \"Nmiss2\"\n                               stats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n                                                 ='Median', range='Min - Max'\n                                                 )) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n\ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, \n                            data=df_long, control=descriptives_2)\n\n#summary(tab_descriptives_2, labelTranslations = my_cat_labels , text=TRUE, title = #\"Categorical Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Categorical Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table."
  },
  {
    "objectID": "3b_HowTos_LinearMixedModels.html#results",
    "href": "3b_HowTos_LinearMixedModels.html#results",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "::: panel-tabset ### Build Model {.tabset .tabset-fade .tabset-pills}\n::: blue\nThe code snippet below tells R to compute xxxxx by xxxxxxx. Next, xxxxx is conducted to examine whether xxxxxx does xxxxxxx (indicating xxxxx). The xxxx function (xxx) is provided by the r ‘xxx’ package. The code above is very similar to the code for the random intercept model, except that now we use the code (1 + Days | Subject) to specify a random intercept for each Subject, and a random slope of Days for each Subject. This allows both the intercept and the slope of days to vary across participants.\nSTEP 1: Compute xxxxxxxx\n\n\nCode\n## Linear Mixed Model with a random intercept (LMM-ri)\n#really still an intercept only model\nrandom_slopes &lt;- lmer(cbcl_extern ~ 1 + event + (1|ids), data = df_long, REML=F)\nprint(random_slopes)\n\n\nLinear mixed model fit by maximum likelihood  ['lmerModLmerTest']\nFormula: cbcl_extern ~ 1 + event + (1 | ids)\n   Data: df_long\n      AIC       BIC    logLik  deviance  df.resid \n 606.4845  619.4601 -298.2423  596.4845        94 \nRandom effects:\n Groups   Name        Std.Dev.\n ids      (Intercept) 4.881   \n Residual             3.528   \nNumber of obs: 99, groups:  ids, 37\nFixed Effects:\n(Intercept)  eventYear_1  eventYear_2  \n     4.5897       0.7558       1.7460  \n\n\n\n\ntesting\nsummary(random_slopes)\n\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: cbcl_extern ~ 1 + event + (1 | ids)\n   Data: df_long\n\n     AIC      BIC   logLik deviance df.resid \n   606.5    619.5   -298.2    596.5       94 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.7525 -0.4865 -0.1845  0.2842  2.9679 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ids      (Intercept) 23.82    4.881   \n Residual             12.45    3.528   \nNumber of obs: 99, groups:  ids, 37\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)   4.5897     1.0059 59.7864   4.563 2.56e-05 ***\neventYear_1   0.7558     0.8618 64.8217   0.877   0.3837    \neventYear_2   1.7460     0.9021 65.6574   1.935   0.0572 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) evnY_1\neventYear_1 -0.419       \neventYear_2 -0.401  0.475\n\n\ntesting\n## Output and reports extending from the LMM-ri analyses\nsummary(random_slopes)\n\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: cbcl_extern ~ 1 + event + (1 | ids)\n   Data: df_long\n\n     AIC      BIC   logLik deviance df.resid \n   606.5    619.5   -298.2    596.5       94 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.7525 -0.4865 -0.1845  0.2842  2.9679 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ids      (Intercept) 23.82    4.881   \n Residual             12.45    3.528   \nNumber of obs: 99, groups:  ids, 37\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)   4.5897     1.0059 59.7864   4.563 2.56e-05 ***\neventYear_1   0.7558     0.8618 64.8217   0.877   0.3837    \neventYear_2   1.7460     0.9021 65.6574   1.935   0.0572 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) evnY_1\neventYear_1 -0.419       \neventYear_2 -0.401  0.475\n\n\ntesting\nconfint(random_slopes, level = 0.95, method = \"Wald\")\n\n\n                  2.5 %   97.5 %\n.sig01               NA       NA\n.sigma               NA       NA\n(Intercept)  2.61814609 6.561329\neventYear_1 -0.93332355 2.445020\neventYear_2 -0.02209218 3.514008\n\n\ntesting\nreport(random_slopes)\n\n\nWe fitted a linear mixed model (estimated using ML and nloptwrap optimizer) to\npredict cbcl_extern with event (formula: cbcl_extern ~ 1 + event). The model\nincluded ids as random effect (formula: ~1 | ids). The model's total\nexplanatory power is substantial (conditional R2 = 0.66) and the part related\nto the fixed effects alone (marginal R2) is of 0.01. The model's intercept,\ncorresponding to event = Baseline, is at 4.59 (95% CI [2.59, 6.59], t(94) =\n4.56, p &lt; .001). Within this model:\n\n  - The effect of event [Year_1] is statistically non-significant and positive\n(beta = 0.76, 95% CI [-0.96, 2.47], t(94) = 0.88, p = 0.383; Std. beta = 0.12,\n95% CI [-0.15, 0.40])\n  - The effect of event [Year_2] is statistically non-significant and positive\n(beta = 1.75, 95% CI [-0.05, 3.54], t(94) = 1.94, p = 0.056; Std. beta = 0.28,\n95% CI [-7.28e-03, 0.57])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\ntesting\nreport_performance(random_slopes)\n\n\nThe model's total explanatory power is substantial (conditional R2 = 0.66) and\nthe part related to the fixed effects alone (marginal R2) is of 0.01\n\n\ntesting\nreport_statistics(random_slopes)\n\n\nbeta = 4.59, 95% CI [2.59, 6.59], t(94) = 4.56, p &lt; .001; Std. beta = -0.17, 95% CI [-0.50, 0.15]\nbeta = 0.76, 95% CI [-0.96, 2.47], t(94) = 0.88, p = 0.383; Std. beta = 0.12, 95% CI [-0.15, 0.40]\nbeta = 1.75, 95% CI [-0.05, 3.54], t(94) = 1.94, p = 0.056; Std. beta = 0.28, 95% CI [-7.28e-03, 0.57]\n\n\ntesting\nrandom &lt;- estimate_grouplevel(random_slopes)\n\n\n\nThe summary function is used to print out the results from the random intercept model and\nSTEP 2: Conduct xxxxxxx\n\n\nCode\n## Obtain LMM-ri model parameters to plot/graph of results\n## Fixed-Effects\nmodel_intercept &lt;- rep(coef(random_slopes)$ids[,1], each = 4)\nslopes2 &lt;- rep(coef(random_slopes)$ids[,2], each = 4)\n#This code allows for extracting the fixed effects estimates for the model intercept and slope.\n\n\nThe output from our model provides: i. a parameter estimate; ii. standard error; iii. p-value. In our example p = .001 which is less than .05 indicating significant differences in predicted cbcl externalizing scores between boys and girls in the ABCD Study. An examination of the regression coeefficient for sex (female = 0; male = 1) is b = .xx, indicating the difference in cbcl externalizing scores from Time 1 to Time 2 is significantly greater in boys taking part in the ABCD Study relative to girls. Then we conclude that participant sex (does/does not) predict change in cbcl externalizing scores from t1 to t2.\nFrom the fixed effects section of the model summary, we can conclude that there is strong evidence that number of days of sleep deprivation significantly increased reaction time under a significance level of 0.05. On average, for each additional day of sleep deprivation, reaction time increased by 10.47ms (b = 10.47, SE = 1.55, p &lt; .001).\nWe are 95% confident that the average increase was between 7.44 and 13.50.\nFrom the fixed effects section, we estimated the average intercept and average effect of days of sleep deprivation (slopes of Days). We also estimated the corresponding 95% confidence intervals. Using the results from the random effects section, we can calculate the coverage intervals for both the intercept and the slope.\nThe variance of the intercept and for the slope of Days is 612.1 and 35.1 respectively. Taking their square root, the corresponding standard deviations are 24.7 and 5.9. The 95% coverage interval of the intercept is 251.4 ± 1.96*24.7. The lower bound is 203.0 and the upper bound is 299.8. It is therefore estimated that 95% of the participants had a reaction time between 203.0 and 299.8 at Day 0.\nThe 95% coverage interval of the slope of Days is 10.5 ± 1.96*5.9. The lower bound is -1.1 and the upper bound is 22.1. It is therefore estimated that for 95% of the participants, the effect of each additional day of sleep deprivation was between -1.1 and 22.1. This is not to be confused with the 95% confidence interval (7.4 and 13.5), which means that we are 95% confident that average effect (across all participants) of each additional day of sleep deprivation on reaction time was between 7.4 and 13.5. The model now estimates a variance of the random slopes effects, as well as a correlation between the random intercept and slope effects. :::\n\n\nCode\n# # ! THIS PLOT RUNS & PRINTS TO SCREEN. I am temporarily commenting it out due to a side-effect of the \n# #\"intercepts2 variable\"\n# ggplot(df_long, aes(x = event, y = cbcl_extern)) + \n#   geom_abline(model_slope = slopes2, model_intercept = intercepts2, \n#               linetype = \"solid\", color = \"black\", linewidth = 1) + \n#   # geom_abline(mapping = aes(slopes2 = model_slope, intercepts2 = model_intercept, linetype = PID), \n#   #             linetype = \"dashed\", color = \"grey70\", linewidth = .4) +\n#   #geom_point(aes(shape = ids), size = 3.25, color = \"grey70\") + \n#   #scale_shape_manual() + \n#   # geom_segment(aes(x = event, xend = event, \n#   #                  y = cbcl1, yend = fitted(model_slope)), \n#   #              color = \"grey70\") +\n#   scale_y_continuous(expand = c(0, 0), breaks = c(0, 100, 200, 300, 400, 500), \n#                      limits = c(0, 500)) +\n#   scale_x_continuous(expand = c(0, 0), breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), \n#                      limits = c(-0.5, 10.5)) +\n#   theme(panel.background = element_blank(),         \n#           panel.grid.major = element_blank(),\n#             panel.grid.minor = element_blank(),\n#             panel.border = element_rect(colour = \"black\", fill = NA),\n#           legend.position = \"none\", \n#           axis.text = element_text(size = 14),\n#           axis.title = element_text(size = 14)) +\n#     labs (x = \"event\", y = \"cbcl_extern\") \n#   \n# #Save the figure\n#  ggsave(\"random_slopes.png\", units = \"in\", width = 9, height = 6, dpi = 300)\n\n\n\n\n:::blue\n\n\nCode\n# #| messages: FALSE\n# #| warning: FALSE\n# #| echo: FALSE\n# #| column: screen-inset-shaded\n# #| layout-nrow: 2\n#     \n# ## xxxxx plot\n# random_intercepts.std &lt;- resid(model_intercept)/sd(resid(model_intercept))\n# plot (random_intercepts.std, ylab=\"Standardized Residuals\")\n# \n# ## Outlier Tests. \n# #car::outlierTest(random_intercepts)\n# car::infIndexPlot(random_intercepts)\n# \n# ## qqplot\n# ggplot(as.data.frame(random_intercepts.std), aes(sample = random_intercepts.std)) +\n#   geom_qq() +\n#   geom_qq_line()\n# \n# ## Predicted vs Actual plot\n# predicted &lt;- estimate_expectation(random_intercepts, data = \"grid\")\n# plot(predicted)\n# \n# ## Estimated means plot\n# means &lt;- estimate_means(random_intercepts)\n# plot(means)\n\n\n#Build diagnostic plots. Observations with a Bonferroni p &lt; .05 might #be considered as outliers and might need further investigation. Examination of this scatterplot indicates xxxxx.\n\n\nCode\n# Basic ggplot2 barplot with mean\np &lt;-df_long %&gt;%\n    filter(!is.na(event)) %&gt;% # filter on non-missing values  \n    ggplot(aes(x = mature_vg, y = cbcl_extern, fill = sex)) +\n    geom_col(position = \"dodge\",\n           stat = \"summary\",\n           fun = \"mean\",\n           #fill = \"#AA4A44\",\n           #color = \"#0099f9\"\n           ) +\n    #scale_fill_brewer(palette = \"Set1\") +\n    scale_fill_manual(values = c(\"#3db5ff\", \"#0099f9\")) +\n    #scale_fill_gradient(high = \"#B00B69\", low = \"#0e0e63\") +\n    #geom_text(aes(label = cu_traits), position = position_dodge(0.9), \n              #vjust = 2, size = 4, color = \"#ffffff\") +\n    labs(title = \"Behavior Problems by Video Game Groups\", subtitle = \"Simple bar chart\",\n         caption = \"Simple caption\", x = \"DBD Group\", y = \"CBCL Externalizing\") +\n              #coord_flip() +\n    #geom_hline(yintercept = mean(df$cbcl_agg), linetype = \"dashed\", size = 1) +\n    theme_minimal() +\n    theme(\n          plot.title = element_text(color = \"#0099f9\", size = 20, hjust = 0.5),\n          plot.subtitle = element_text(face = \"bold\", hjust = 1),\n          plot.caption = element_text(face = \"italic\", hjust = 0),\n            axis.title.x = element_text(color = \"#0099f9\", size = 15, face = \"bold\"),\n            axis.title.y = element_text(size = 15, face = \"italic\")\n    )\n\n\nExamination of this scatterplot indicates xxxxx.\n\n\nCode\n#Random Intercept LMM Plot/Graph\n#random_intercepts &lt;- lmer(Externalizing ~ 1 + Event + DBD + Sex + (1|ids), data = df, #REML=T)\n\n##  LMM-ri plot of estimated random intercepts \nmodel &lt;- lmer(cbcl_extern ~ mature_vg + (1 | sex), data = df_long)\npreds &lt;- estimate_relation(model, include_random = TRUE)\n    \n## Adding fixed effect trajectory to LMM-ri plot \nfixed_pred &lt;- estimate_relation(model) # This time, include_random is FALSE (default)\n plot(preds, ribbon = list(alpha = 0)) + # Previous plot\n  geom_ribbon(data = fixed_pred, aes(x = mature_vg, ymin = CI_low, ymax = CI_high), alpha = 0.4) +\n  geom_line(data = fixed_pred, aes(x = mature_vg, y = Predicted), size = 2)\n\n\n\n\n\nCode\n# ggplot(df_long_sub, aes(x = event, y = cbcl_agg, color=sex, shape=sex)) + \n# geom_abline(slope = model_slope, intercept = model_intercept, linetype = \"solid\", color = \"red\", linewidth = 1) + \n# geom_point(color = \"grey70\") + \n# geom_smooth(method=lm, se=FALSE, fullrange=TRUE)+\n# scale_shape() + \n# geom_segment(aes(x = event, xend = event, y = cbcl_agg, yend = fitted(cbcl_agg)), color = \"grey70\") + \n# scale_y_continuous(expand = c(0, 0), breaks = c(0, 20, 40, 60, 80, 100), limits = c(0, 100)) + \n# scale_x_continuous(expand = c(0, 0), breaks = c(1, 2, 3, 4), limits = c(0, 4)) +\n# theme(panel.background = element_blank(),         \n#         panel.grid.major = element_blank(),\n#         panel.grid.minor = element_blank(),\n#         panel.border = element_rect(colour = \"black\", fill = NA),\n#         legend.position = \"none\",\n#         axis.text = element_text(size = 14), \n#         axis.title = element_text(size = 14)) +\n#         labs (x = \"Event\", y= \"CBCL Aggression\")\n\n#Save the plot\n#ggsave(\"random_intercept.png\", units = \"in\", width = 9, height = 6, dpi = 300)  \n\n\n\nFigure x: The overall group-mean (fixed effects) trajectory is shown in blue. The faded lines represent each individual youth’s estimated trajectory. An examination of this figure shows happiness scores to be increasing across measurement occasions, however, there appears to be substantial variability in the youth’s initial happiness scores.\n\nExamination of this barplot indicates xxxxx."
  },
  {
    "objectID": "3b_HowTos_LinearMixedModels.html#wrapping-up",
    "href": "3b_HowTos_LinearMixedModels.html#wrapping-up",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "::: panel-tabset ### Write-up {.tabset .tabset-fade .tabset-pills}\n\nA random slope model is used to test if sleep deprivation affects reaction time. To account for the repeated measures design, a random intercept was specified for participants. The random slope for days of sleep deprivation was included in the model to allow the effect of sleep deprivation to vary across participants. Results are shown in Table 1. Using a significant level of 0.05, results indicate that sleep deprivation significantly increased reaction time. On average, each additional day of sleep deprivation increased reaction time by 10.47ms (b = 10.47, 95% CI = [7.44, 13.50], p &lt; .001). Model fit comparison between model with and without random slope for sleep deprivation shows that the effect of sleep deprivation varied across participants, χ2(2)= 42.14, p &lt; .001. The 95% coverage interval for the random slope of sleep deprivation is (-1.14, 22.07), indicating that the effect of sleep deprivation was between -1.14 and 22.07 for 95% of the participants."
  },
  {
    "objectID": "3b_HowTos_LinearMixedModels.html#references",
    "href": "3b_HowTos_LinearMixedModels.html#references",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "(brown2021?)"
  },
  {
    "objectID": "16_HowTos_LatentCurveModelsStructuredResiduals.html",
    "href": "16_HowTos_LatentCurveModelsStructuredResiduals.html",
    "title": "Latent Curve Models with Structured Residuals",
    "section": "",
    "text": "test page for LCM-SR how tos"
  },
  {
    "objectID": "2_HowTos_ResidualizedChangeScores.html",
    "href": "2_HowTos_ResidualizedChangeScores.html",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "insert text\n\n\n\n\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\n\nCode\n#rm(list = ls())\n\n#Load packages\nlibrary(rstatix)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(emmeans)\nlibrary(arrow)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(rstatix)\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220), fig.align='center',\n                      out.width='75%', fig.asp=.75)\n\n\n\n\n\n\n\n\n\n\nRead and View Data\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n## Read data\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\ndf_wide &lt;- read_csv(\"/Users/shawes/Desktop/data/df_wide.csv\")\n\n# set types (if necessary)\ndf_long$ids &lt;- as.factor(df_long$ids)\ndf_long$event &lt;- as.factor(df_long$event)\ndf_long$site_id &lt;- as.factor(df_long$site_id)\ndf_long$fam_id &lt;- as.factor(df_long$fam_id)\ndf_long$sex &lt;- as.factor(df_long$sex)\ndf_long$age &lt;- as.numeric(df_long$age)\ndf_long$mature_vg &lt;- as.numeric(df_long$mature_vg)\ndf_long$cbcl_extern &lt;- as.numeric(df_long$cbcl_extern)\ndf_long$vg_total &lt;- as.numeric(df_long$vg_total)\n\n\n\n\n\n\n\n\n\nThis code creates a table of descriptive information for continuous outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_1 &lt;- tableby.control(test=FALSE, total=FALSE, numeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"), #\"Nmiss2\"\ncat.stats=c(\"countpct\"), #\"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median ='Median', \n                  range='Min - Max'))  #, Nmiss2 ='Missing'\nmy_cont_labels &lt;- list(age = \"Age\", vg_total = \"Weekly # of Video Gaming Hrs\",\n            cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                                      cbcl_extern,\n                                      data=df_long, control=tab_descriptives_1)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", \n                full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15, position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;% \n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis code creates a descriptives table for categorical outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n), # \"Nmiss2\"\ncat.stats=c(\"countpct\"), # \"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n)) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n          \ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, data=df_long, control=tab_descriptives_2)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n            summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Categorical Outcomes\") %&gt;%\n            kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size =\n                            15, position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n::: panel-tabset ### Build Model {.tabset .tabset-fade .tabset-pills}\n::: blue\nThe code snippet below tells R to compute xxxxx by xxxxxxx. Next, xxxxx is conducted to examine whether xxxxxx does xxxxxxx (indicating xxxxx). The xxxx function (xxx) is provided by the r ‘xxx’ package.\nSTEP 1: Compute xxxxxxxx\n\n\nCode\n#A multiple regression approach can be used to examine effects of a continuous covariate  when controlling for autoregressive effects (t1-&gt;t2) \n\n#Multiple regression model\nresult = lm(cbcl_extern_Year_1 ~ cbcl_extern_Baseline + vg_total_Baseline, data = df_wide)\nstr(df_wide)\n\n\nspc_tbl_ [99 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ids                 : num [1:99] 1 2 3 4 5 6 7 8 9 10 ...\n $ site_id             : chr [1:99] \"site06\" \"site06\" \"site06\" \"site10\" ...\n $ fam_id              : num [1:99] 8781 8781 8781 10210 10210 ...\n $ sex                 : chr [1:99] \"Female\" \"Female\" \"Female\" \"Female\" ...\n $ age                 : num [1:99] 9 10 9 9 9 10 10 10 10 9 ...\n $ mature_vg           : num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ vg_total_Year_1     : num [1:99] 7 7 7 7 4 0 4 1 1 2 ...\n $ vg_total_Baseline   : num [1:99] 4 7 4 2 42 0 4 2 2 2 ...\n $ vg_total_Year_2     : num [1:99] 1 1 2 0 3 0 2 2 7 3 ...\n $ cbcl_extern_Year_1  : num [1:99] 7 7 7 7 2 0 4 1 1 2 ...\n $ cbcl_extern_Baseline: num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ cbcl_extern_Year_2  : num [1:99] 7 7 7 7 4 6 4 4 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ids = col_double(),\n  ..   site_id = col_character(),\n  ..   fam_id = col_double(),\n  ..   sex = col_character(),\n  ..   age = col_double(),\n  ..   mature_vg = col_double(),\n  ..   vg_total_Year_1 = col_double(),\n  ..   vg_total_Baseline = col_double(),\n  ..   vg_total_Year_2 = col_double(),\n  ..   cbcl_extern_Year_1 = col_double(),\n  ..   cbcl_extern_Baseline = col_double(),\n  ..   cbcl_extern_Year_2 = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nCode\n# fit ML model including mean structure to make comparable with FIML fit below\n# (means are always included with FIML model fits)\n# sem.mod.fit &lt;- sem(sem.mod, data=tpb.df, meanstructure=TRUE)\n\n# fit again including missing data also\n#sem.mod.fit.fiml &lt;- sem(sem.mod, data=tpb.df, missing=\"ML\")\n\n\n\n\nCode\n#Diagnostic Plots\n\nsummary(result)\n\n\n\nCall:\nlm(formula = cbcl_extern_Year_1 ~ cbcl_extern_Baseline + vg_total_Baseline, \n    data = df_wide)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.105  -5.762  -2.445   2.433  25.490 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           7.40596    1.18952   6.226 1.26e-08 ***\ncbcl_extern_Baseline  0.05118    0.18507   0.277    0.783    \nvg_total_Baseline     0.10404    0.07174   1.450    0.150    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.316 on 96 degrees of freedom\nMultiple R-squared:  0.02203,   Adjusted R-squared:  0.00166 \nF-statistic: 1.081 on 2 and 96 DF,  p-value: 0.3432\n\n\nCode\n# residuals vs. fitted values plot.\nresid_plot&lt;- plot(result, add.smooth = FALSE, which = 1)\n\n\n\n\n\nCode\n# normal probability plot\nnorm_plot&lt;- plot(result, which = 2)\n\n\n\n\n\nCode\n# scale location plot\nscale_plot&lt;- plot(result, add.smooth = FALSE, which = 3)\n\n\n\n\n\nCode\n# boxplot\n#boxplot &lt;- ggplot(df_wide, aes(x = Externalizing_T1, y = Externalizing_T0, colour = Sex)) + geom_point()\n\n#suppressWarnings(print(resid_plot))\n#suppressWarnings(print(norm_plot))\n#suppressWarnings(print(scale_plot))\n#suppressWarnings(print(boxplot))\n\n\nThis summary of xxxx indicates xxxxx.\nThe output from our model provides: i. xxxx; ii. xxxxx; iii. xxxx. In our example xxxxx indicates xxxxx. An examination of xxxxx is xxxx, indicating xxxxxx. Then we conclude that xxxxxx.\n\n\nCode\n# Boxplots\n\ndf_wide %&gt;%\n            group_by(sex) %&gt;%  \n            summarise(mean_grade = mean(cbcl_extern_Baseline),\n            sd_grade = sd(cbcl_extern_Baseline),\n            mean_exam = mean(cbcl_extern_Year_1),\n            sd_exam = sd(cbcl_extern_Year_1))\n\n\n\n\n  \n\n\n\nCode\n# Boxplot of CBCL Externalizing scores at baseline by sex\nboxplot_cbclExt_T1 &lt;- boxplot(cbcl_extern_Baseline ~ sex,data = df_wide,\nmain = \"CBCL Ext Baseline Score by sex\",\nxlab = \"Sex\",ylab = \"Baseline CBCL Externalizing Score\",\ncol = \"red\",border = \"black\")\n\n\n\n\n\nCode\n# Boxplot of CBCL Externalizing scores at 1-Year follow-up by sex\nboxplot_cbclExt_T2 &lt;- boxplot(cbcl_extern_Year_1 ~ sex, data = df_wide,\nmain = \"CBCL Ext 1-Year Follow-up Score by sex\",\nxlab = \"Sex\",ylab = \"1-Year Follow-up CBCL Externalizing Score\",\ncol = \"red\",border = \"black\")\n\n\n\n\n\nCode\nsuppressWarnings(print(boxplot_cbclExt_T1))\n\n\n$stats\n     [,1] [,2]\n[1,]  0.0    0\n[2,]  0.0    0\n[3,]  1.0    1\n[4,]  3.5    4\n[5,]  8.0    8\n\n$n\n[1] 56 43\n\n$conf\n          [,1]       [,2]\n[1,] 0.2610227 0.03620904\n[2,] 1.7389773 1.96379096\n\n$out\n [1] 12 28  9  9 12 12 19 11 12 12\n\n$group\n [1] 1 1 1 1 2 2 2 2 2 2\n\n$names\n[1] \"Female\" \"Male\"  \n\n\nCode\nsuppressWarnings(print(boxplot_cbclExt_T2))\n\n\n$stats\n     [,1] [,2]\n[1,]  0.0  1.0\n[2,]  2.0  3.0\n[3,]  5.5  9.0\n[4,]  9.0 12.5\n[5,] 16.0 16.0\n\n$n\n[1] 56 43\n\n$conf\n         [,1]      [,2]\n[1,] 4.022045  6.710996\n[2,] 6.977955 11.289004\n\n$out\n [1] 26 28 23 33 23 28 28 28 28 33 28 28\n\n$group\n [1] 1 1 1 1 1 1 2 2 2 2 2 2\n\n$names\n[1] \"Female\" \"Male\"  \n\n\nThese boxplots indicates xxxxxx.\n\n\n\n\n\n\nWrite-up\n\n\n\nA xxxxxx analysis was conducted to examine xxxxx. Findings showed xxxxxx"
  },
  {
    "objectID": "2_HowTos_ResidualizedChangeScores.html#overview",
    "href": "2_HowTos_ResidualizedChangeScores.html#overview",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "insert text"
  },
  {
    "objectID": "2_HowTos_ResidualizedChangeScores.html#preliminary-setup",
    "href": "2_HowTos_ResidualizedChangeScores.html#preliminary-setup",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Install PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\n\nCode\n#rm(list = ls())\n\n#Load packages\nlibrary(rstatix)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(emmeans)\nlibrary(arrow)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(rstatix)\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220), fig.align='center',\n                      out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "2_HowTos_ResidualizedChangeScores.html#descriptives-overview",
    "href": "2_HowTos_ResidualizedChangeScores.html#descriptives-overview",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Read and View Data\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n## Read data\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\ndf_wide &lt;- read_csv(\"/Users/shawes/Desktop/data/df_wide.csv\")\n\n# set types (if necessary)\ndf_long$ids &lt;- as.factor(df_long$ids)\ndf_long$event &lt;- as.factor(df_long$event)\ndf_long$site_id &lt;- as.factor(df_long$site_id)\ndf_long$fam_id &lt;- as.factor(df_long$fam_id)\ndf_long$sex &lt;- as.factor(df_long$sex)\ndf_long$age &lt;- as.numeric(df_long$age)\ndf_long$mature_vg &lt;- as.numeric(df_long$mature_vg)\ndf_long$cbcl_extern &lt;- as.numeric(df_long$cbcl_extern)\ndf_long$vg_total &lt;- as.numeric(df_long$vg_total)\n\n\n\n\n\n\n\n\n\nThis code creates a table of descriptive information for continuous outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_1 &lt;- tableby.control(test=FALSE, total=FALSE, numeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"), #\"Nmiss2\"\ncat.stats=c(\"countpct\"), #\"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median ='Median', \n                  range='Min - Max'))  #, Nmiss2 ='Missing'\nmy_cont_labels &lt;- list(age = \"Age\", vg_total = \"Weekly # of Video Gaming Hrs\",\n            cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                                      cbcl_extern,\n                                      data=df_long, control=tab_descriptives_1)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", \n                full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15, position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;% \n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis code creates a descriptives table for categorical outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n), # \"Nmiss2\"\ncat.stats=c(\"countpct\"), # \"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n)) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n          \ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, data=df_long, control=tab_descriptives_2)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n            summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Categorical Outcomes\") %&gt;%\n            kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size =\n                            15, position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "2_HowTos_ResidualizedChangeScores.html#results",
    "href": "2_HowTos_ResidualizedChangeScores.html#results",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "::: panel-tabset ### Build Model {.tabset .tabset-fade .tabset-pills}\n::: blue\nThe code snippet below tells R to compute xxxxx by xxxxxxx. Next, xxxxx is conducted to examine whether xxxxxx does xxxxxxx (indicating xxxxx). The xxxx function (xxx) is provided by the r ‘xxx’ package.\nSTEP 1: Compute xxxxxxxx\n\n\nCode\n#A multiple regression approach can be used to examine effects of a continuous covariate  when controlling for autoregressive effects (t1-&gt;t2) \n\n#Multiple regression model\nresult = lm(cbcl_extern_Year_1 ~ cbcl_extern_Baseline + vg_total_Baseline, data = df_wide)\nstr(df_wide)\n\n\nspc_tbl_ [99 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ids                 : num [1:99] 1 2 3 4 5 6 7 8 9 10 ...\n $ site_id             : chr [1:99] \"site06\" \"site06\" \"site06\" \"site10\" ...\n $ fam_id              : num [1:99] 8781 8781 8781 10210 10210 ...\n $ sex                 : chr [1:99] \"Female\" \"Female\" \"Female\" \"Female\" ...\n $ age                 : num [1:99] 9 10 9 9 9 10 10 10 10 9 ...\n $ mature_vg           : num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ vg_total_Year_1     : num [1:99] 7 7 7 7 4 0 4 1 1 2 ...\n $ vg_total_Baseline   : num [1:99] 4 7 4 2 42 0 4 2 2 2 ...\n $ vg_total_Year_2     : num [1:99] 1 1 2 0 3 0 2 2 7 3 ...\n $ cbcl_extern_Year_1  : num [1:99] 7 7 7 7 2 0 4 1 1 2 ...\n $ cbcl_extern_Baseline: num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ cbcl_extern_Year_2  : num [1:99] 7 7 7 7 4 6 4 4 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ids = col_double(),\n  ..   site_id = col_character(),\n  ..   fam_id = col_double(),\n  ..   sex = col_character(),\n  ..   age = col_double(),\n  ..   mature_vg = col_double(),\n  ..   vg_total_Year_1 = col_double(),\n  ..   vg_total_Baseline = col_double(),\n  ..   vg_total_Year_2 = col_double(),\n  ..   cbcl_extern_Year_1 = col_double(),\n  ..   cbcl_extern_Baseline = col_double(),\n  ..   cbcl_extern_Year_2 = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nCode\n# fit ML model including mean structure to make comparable with FIML fit below\n# (means are always included with FIML model fits)\n# sem.mod.fit &lt;- sem(sem.mod, data=tpb.df, meanstructure=TRUE)\n\n# fit again including missing data also\n#sem.mod.fit.fiml &lt;- sem(sem.mod, data=tpb.df, missing=\"ML\")\n\n\n\n\nCode\n#Diagnostic Plots\n\nsummary(result)\n\n\n\nCall:\nlm(formula = cbcl_extern_Year_1 ~ cbcl_extern_Baseline + vg_total_Baseline, \n    data = df_wide)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.105  -5.762  -2.445   2.433  25.490 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           7.40596    1.18952   6.226 1.26e-08 ***\ncbcl_extern_Baseline  0.05118    0.18507   0.277    0.783    \nvg_total_Baseline     0.10404    0.07174   1.450    0.150    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.316 on 96 degrees of freedom\nMultiple R-squared:  0.02203,   Adjusted R-squared:  0.00166 \nF-statistic: 1.081 on 2 and 96 DF,  p-value: 0.3432\n\n\nCode\n# residuals vs. fitted values plot.\nresid_plot&lt;- plot(result, add.smooth = FALSE, which = 1)\n\n\n\n\n\nCode\n# normal probability plot\nnorm_plot&lt;- plot(result, which = 2)\n\n\n\n\n\nCode\n# scale location plot\nscale_plot&lt;- plot(result, add.smooth = FALSE, which = 3)\n\n\n\n\n\nCode\n# boxplot\n#boxplot &lt;- ggplot(df_wide, aes(x = Externalizing_T1, y = Externalizing_T0, colour = Sex)) + geom_point()\n\n#suppressWarnings(print(resid_plot))\n#suppressWarnings(print(norm_plot))\n#suppressWarnings(print(scale_plot))\n#suppressWarnings(print(boxplot))\n\n\nThis summary of xxxx indicates xxxxx.\nThe output from our model provides: i. xxxx; ii. xxxxx; iii. xxxx. In our example xxxxx indicates xxxxx. An examination of xxxxx is xxxx, indicating xxxxxx. Then we conclude that xxxxxx.\n\n\nCode\n# Boxplots\n\ndf_wide %&gt;%\n            group_by(sex) %&gt;%  \n            summarise(mean_grade = mean(cbcl_extern_Baseline),\n            sd_grade = sd(cbcl_extern_Baseline),\n            mean_exam = mean(cbcl_extern_Year_1),\n            sd_exam = sd(cbcl_extern_Year_1))\n\n\n\n\n  \n\n\n\nCode\n# Boxplot of CBCL Externalizing scores at baseline by sex\nboxplot_cbclExt_T1 &lt;- boxplot(cbcl_extern_Baseline ~ sex,data = df_wide,\nmain = \"CBCL Ext Baseline Score by sex\",\nxlab = \"Sex\",ylab = \"Baseline CBCL Externalizing Score\",\ncol = \"red\",border = \"black\")\n\n\n\n\n\nCode\n# Boxplot of CBCL Externalizing scores at 1-Year follow-up by sex\nboxplot_cbclExt_T2 &lt;- boxplot(cbcl_extern_Year_1 ~ sex, data = df_wide,\nmain = \"CBCL Ext 1-Year Follow-up Score by sex\",\nxlab = \"Sex\",ylab = \"1-Year Follow-up CBCL Externalizing Score\",\ncol = \"red\",border = \"black\")\n\n\n\n\n\nCode\nsuppressWarnings(print(boxplot_cbclExt_T1))\n\n\n$stats\n     [,1] [,2]\n[1,]  0.0    0\n[2,]  0.0    0\n[3,]  1.0    1\n[4,]  3.5    4\n[5,]  8.0    8\n\n$n\n[1] 56 43\n\n$conf\n          [,1]       [,2]\n[1,] 0.2610227 0.03620904\n[2,] 1.7389773 1.96379096\n\n$out\n [1] 12 28  9  9 12 12 19 11 12 12\n\n$group\n [1] 1 1 1 1 2 2 2 2 2 2\n\n$names\n[1] \"Female\" \"Male\"  \n\n\nCode\nsuppressWarnings(print(boxplot_cbclExt_T2))\n\n\n$stats\n     [,1] [,2]\n[1,]  0.0  1.0\n[2,]  2.0  3.0\n[3,]  5.5  9.0\n[4,]  9.0 12.5\n[5,] 16.0 16.0\n\n$n\n[1] 56 43\n\n$conf\n         [,1]      [,2]\n[1,] 4.022045  6.710996\n[2,] 6.977955 11.289004\n\n$out\n [1] 26 28 23 33 23 28 28 28 28 33 28 28\n\n$group\n [1] 1 1 1 1 1 1 2 2 2 2 2 2\n\n$names\n[1] \"Female\" \"Male\"  \n\n\nThese boxplots indicates xxxxxx."
  },
  {
    "objectID": "2_HowTos_ResidualizedChangeScores.html#wrapping-up",
    "href": "2_HowTos_ResidualizedChangeScores.html#wrapping-up",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Write-up\n\n\n\nA xxxxxx analysis was conducted to examine xxxxx. Findings showed xxxxxx"
  },
  {
    "objectID": "10_HowTos_LatentGrowthCurveModels.html",
    "href": "10_HowTos_LatentGrowthCurveModels.html",
    "title": "Latent Growth Curve Models",
    "section": "",
    "text": "test page for lgcm howtos"
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html",
    "href": "3_Tutorials_LinearMixedModels.html",
    "title": "Linear Mixed Models",
    "section": "",
    "text": "Linear mixed models (LMMs) are a powerful statistical tool that allows the analysis of complex data structures that contain both fixed and random effects (West et al., 2015). LMMs are widely used in various fields, including social sciences, biology, and engineering, due to their ability to handle hierarchical data structures and account for within-subject correlations (Bates et al., 2015). LMMs are an extension of the general linear model (GLM), where both fixed and random effects can be included in the model, making them more flexible and robust (Pinheiro & Bates, 2000). These models are particularly useful when analyzing longitudinal data, where measurements are taken repeatedly over time, and correlations between observations must be accounted for (Singer & Willett, 2003). Specifically, the LMM framework accounts for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. This approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory. It is this “mixture” of fixed and random effects from which these models derive their name.\n\n\n\nLinear Mixed Models\n\n\n\n\nYou should use LMMs in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal linear mixed models (LLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal linear mixed models.\nFit a longitudinal linear mixed model using example data in R.\nInterpret the results of the LLMM analysis."
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html#overview",
    "href": "3_Tutorials_LinearMixedModels.html#overview",
    "title": "Linear Mixed Models",
    "section": "",
    "text": "Linear mixed models (LMMs) are a powerful statistical tool that allows the analysis of complex data structures that contain both fixed and random effects (West et al., 2015). LMMs are widely used in various fields, including social sciences, biology, and engineering, due to their ability to handle hierarchical data structures and account for within-subject correlations (Bates et al., 2015). LMMs are an extension of the general linear model (GLM), where both fixed and random effects can be included in the model, making them more flexible and robust (Pinheiro & Bates, 2000). These models are particularly useful when analyzing longitudinal data, where measurements are taken repeatedly over time, and correlations between observations must be accounted for (Singer & Willett, 2003). Specifically, the LMM framework accounts for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. This approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory. It is this “mixture” of fixed and random effects from which these models derive their name.\n\n\n\nLinear Mixed Models\n\n\n\n\nYou should use LMMs in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of longitudinal linear mixed models (LLMMs) and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of longitudinal linear mixed models.\nFit a longitudinal linear mixed model using example data in R.\nInterpret the results of the LLMM analysis."
  },
  {
    "objectID": "3_Tutorials_LinearMixedModels.html#basic-example",
    "href": "3_Tutorials_LinearMixedModels.html#basic-example",
    "title": "Linear Mixed Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nSubject ID\nTime (in years)\nOutcome variable (e.g., a measure of cognitive performance)\n\n\n\n\nSubject ID\nTime\nOutcome\n\n\n\n\n1\n0\n100\n\n\n1\n1\n105\n\n\n1\n2\n110\n\n\n2\n0\n95\n\n\n2\n1\n100\n\n\n\n\nModel Specification and Estimation\nWe will use the lme4 package in R to fit a longitudinal linear mixed model. First, install and load the required package:\n\n\nCode\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nlibrary(lme4)\n\n\nNext, create a data frame with the example data:\n\n\nCode\ndata &lt;- data.frame(\n  subject_id = c(1, 1, 1, 2, 2),\n  time = c(0, 1, 2, 0, 1),\n  outcome = c(100, 105, 110, 95, 100)\n)\n\n\nFit the LLMM with a random intercept for each subject and a fixed effect of time:\n\n\nCode\nmodel &lt;- lmer(outcome ~ time + (1 | subject_id), data = data)\n\n\n\n\nInterpreting the Results\nTo interpret the results of the LLMM analysis, we can use the summary() function in R to display the estimated fixed effects and random effects:\n\n\nCode\nsummary(model)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: outcome ~ time + (1 | subject_id)\n   Data: data\n\nREML criterion at convergence: -44.7\n\nScaled residuals: \n       Min         1Q     Median         3Q        Max \n-1.141e-07 -5.704e-08  8.556e-08  1.426e-07  1.996e-07 \n\nRandom effects:\n Groups     Name        Variance  Std.Dev. \n subject_id (Intercept) 4.167e+00 2.041e+00\n Residual               2.483e-13 4.983e-07\nNumber of obs: 5, groups:  subject_id, 2\n\nFixed effects:\n             Estimate Std. Error   t value\n(Intercept) 9.750e+01  1.444e+00 6.751e+01\ntime        5.000e+00  3.151e-07 1.587e+07\n\nCorrelation of Fixed Effects:\n     (Intr)\ntime 0.000 \noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00500608 (tol = 0.002, component 1)\n\n\nThe output will show the estimated fixed effect of time, which represents the average change in the outcome variable over time across subjects. The random effects estimates show the variation in the intercept (initial level) of the outcome variable across subjects. By examining the fixed and random effects, we can gain insights into how the outcome variable changes over time and how this change differs between subjects."
  },
  {
    "objectID": "9_Tutorials_LatentChangeScoresModels.html",
    "href": "9_Tutorials_LatentChangeScoresModels.html",
    "title": "Latent Change Score Models",
    "section": "",
    "text": "xxx In this tutorial, we’ll introduce Latent Change Score Models (LCSM), a powerful technique for analyzing longitudinal data. Latent Change Score Models allow researchers to examine individual differences in change over time, as well as the factors that might influence these changes. We’ll walk through an example using a dataset with three time points and a larger sample size of 250 participants. xxx\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "9_Tutorials_LatentChangeScoresModels.html#overview",
    "href": "9_Tutorials_LatentChangeScoresModels.html#overview",
    "title": "Latent Change Score Models",
    "section": "",
    "text": "xxx In this tutorial, we’ll introduce Latent Change Score Models (LCSM), a powerful technique for analyzing longitudinal data. Latent Change Score Models allow researchers to examine individual differences in change over time, as well as the factors that might influence these changes. We’ll walk through an example using a dataset with three time points and a larger sample size of 250 participants. xxx\n[+add diagrams/figures]\n\n\nYou should use xxxxxxx in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\n\n\nTo follow along with this tutorial, you’ll need to have R installed on your computer, as well as the “lavaan” package for fitting latent variable models.\nYou can install the “lavaan” package using the following code:\n\n\nCode\nif (!(\"lavaan\" %in% installed.packages())) {\n  install.packages(\"lavaan\")\n}"
  },
  {
    "objectID": "9_Tutorials_LatentChangeScoresModels.html#basic-example",
    "href": "9_Tutorials_LatentChangeScoresModels.html#basic-example",
    "title": "Latent Change Score Models",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we’ll use a hypothetical dataset called “data” with the following variables:\nsubject_id: A unique identifier for each participant score_t1: The measurement of a variable of interest at Time 1 score_t2: The measurement of the same variable at Time 2 score_t3: The measurement of the same variable at Time 3 First, let’s load the “lavaan” package and create a larger dataset for this example:\n\n\nCode\nlibrary(lavaan)\n\n# Create a sample dataset with 250 participants\nset.seed(42) # For reproducibility\nsubject_id &lt;- 1:250\nscore_t1 &lt;- rnorm(250, mean = 20, sd = 5)\nscore_t2 &lt;- score_t1 + rnorm(250, mean = 2, sd = 3)\nscore_t3 &lt;- score_t2 + rnorm(250, mean = 3, sd = 4)\ndata &lt;- data.frame(subject_id, score_t1, score_t2, score_t3)\n\n\n\nModel Specification and Estimation\nNow, let’s specify the Latent Change Score Model. In this example, we’ll estimate the mean change in the variable of interest from Time 1 to Time 2 and from Time 2 to Time 3, as well as the variances of the change scores.\n\n::: {.cell hash='9_Tutorials_LatentChangeScoresModels_cache/html/unnamed-chunk-3_4c6ae3706e63906c93faa359ec254305'}\n\n```{.r .cell-code}\n# Define the Latent Change Score Model\nmodel &lt;- '\n  # Latent variables\n    delta12 =~ 1 * score_t2 - 1 * score_t1\n    delta23 =~ 1 * score_t3 - 1 * score_t2\n\n  # Means\n    delta12 ~ mu_delta12\n    delta23 ~ mu_delta23\n\n  # Variances\n    delta12 ~~ var_delta12 * delta12\n    delta23 ~~ var_delta23 * delta23\n`\n:::\n\n\nCode\n# Fit the model\nfit &lt;- sem(model, data = data, missing = \"FIML\")\n\n\n\n\nInterpreting the Results\nWe can now examine the results of our Latent Change Score Model. The main parameters of interest are:\nmu_delta12: The mean change in the variable of interest from Time 1 to Time 2 mu_delta23: The mean change in the variable of interest from Time 2 to Time 3 var_delta12: The variance of the change scores from Time 1 to Time 2, which reflects individual differences in change var_delta23: The variance of the change xxxx"
  },
  {
    "objectID": "14_HowTos_StateTraitModels.html",
    "href": "14_HowTos_StateTraitModels.html",
    "title": "State-Trait Models",
    "section": "",
    "text": "test page for state-trait howtos"
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html",
    "href": "2_Tutorials_ResidualizedChangeScores.html",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Residualized change scores are a statistical method used to assess the degree of change in a variable while controlling for its initial level. The approach involves calculating the residualized change scores by regressing post-treatment scores on pre-treatment scores and using the resulting residuals as the measure of change. This estimated change score adjusts for baseline scores while ignoring any prior group assignments/differences. The residualized change score is often included in subsequent analysis, such as an examination of intervention effects in pre-test/post-test designs (Kisbu-Sakarya2013?). This method is useful when there is a high correlation between the pre-treatment and post-treatment scores, which can make it difficult to determine the true degree of change. Research studies have shown that this method can provide more accurate and reliable results compared to other methods of measuring change, such as raw change scores or gain scores (Kenny, 1979; Rogosa & Willett, 1985).\nResidualized change scores are a method used to analyze change in a variable over time, while accounting for the initial level of that variable. By using residualized change scores, we can examine the extent to which changes in one variable are associated with changes in another variable, controlling for the initial level of the variables.\n\n\n\nResidualized Change Score 1_Tutorial\n\n\n\n\nYou should use residualized change scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of residualized change scores and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of residualized change scores.\nCalculate residualized change scores using example data.\nInterpret the results of the residualized change scores analysis."
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html#overview",
    "href": "2_Tutorials_ResidualizedChangeScores.html#overview",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Residualized change scores are a statistical method used to assess the degree of change in a variable while controlling for its initial level. The approach involves calculating the residualized change scores by regressing post-treatment scores on pre-treatment scores and using the resulting residuals as the measure of change. This estimated change score adjusts for baseline scores while ignoring any prior group assignments/differences. The residualized change score is often included in subsequent analysis, such as an examination of intervention effects in pre-test/post-test designs (Kisbu-Sakarya2013?). This method is useful when there is a high correlation between the pre-treatment and post-treatment scores, which can make it difficult to determine the true degree of change. Research studies have shown that this method can provide more accurate and reliable results compared to other methods of measuring change, such as raw change scores or gain scores (Kenny, 1979; Rogosa & Willett, 1985).\nResidualized change scores are a method used to analyze change in a variable over time, while accounting for the initial level of that variable. By using residualized change scores, we can examine the extent to which changes in one variable are associated with changes in another variable, controlling for the initial level of the variables.\n\n\n\nResidualized Change Score 1_Tutorial\n\n\n\n\nYou should use residualized change scores in the following scenario:\n\nYou want to know xxxxx\nYour variable xxxxx\nYou have xxxxx\n\n\n\n\nIn this tutorial, we will introduce the concept of residualized change scores and guide you through a simple example using a small dataset. By the end of this tutorial, you will be able to:\n\nUnderstand the basic concepts of residualized change scores.\nCalculate residualized change scores using example data.\nInterpret the results of the residualized change scores analysis."
  },
  {
    "objectID": "2_Tutorials_ResidualizedChangeScores.html#basic-example",
    "href": "2_Tutorials_ResidualizedChangeScores.html#basic-example",
    "title": "Residualized Change Scores",
    "section": "Basic Example",
    "text": "Basic Example\nFor this tutorial, we will use a simple dataset containing the following information for a group of individuals:\n\nTime point (T1, T2)\nJob satisfaction (independent variable)\nLife satisfaction (dependent variable)\n\n\n\n\nIndividual\nTime Point\nJob Satisfaction\nLife Satisfaction\n\n\n\n\nA\nT1\n7\n6\n\n\nA\nT2\n8\n7\n\n\nB\nT1\n6\n5\n\n\nB\nT2\n7\n6\n\n\n\n\nModel Specification and Estimation\nTo calculate residualized change scores, we will follow these steps:\n\nCalculate the raw change scores for each variable by subtracting the T1 value from the T2 value.\nFit a regression model with the change score of the dependent variable (life satisfaction) as the outcome and the change score of the independent variable (job satisfaction) and the initial level of the dependent variable (T1 life satisfaction) as predictors.\nExtract the residuals from the regression model. These residuals represent the residualized change scores.\n\nUsing the example dataset, we can calculate the residualized change scores for life satisfaction as follows:\n\nCalculate raw change scores:\n\n\n\nIndividual\nJob Satisfaction Change\nLife Satisfaction Change\n\n\n\n\nA\n1\n1\n\n\nB\n1\n1\n\n\n\nFit the regression model:\nLife Satisfaction Change = b0 + b1 * Job Satisfaction Change + b2 * T1 Life Satisfaction\nExtract residuals:\n\n\n\nIndividual\nResidualized Change Score\n\n\n\n\nA\ne1\n\n\nB\ne2\n\n\n\n\n\n\nInterpreting the Results\nResidualized change scores represent the change in the dependent variable (life satisfaction) after accounting for the initial level of that variable and the change in the independent variable (job satisfaction). By examining the association between the residualized change scores of two variables, we can gain insights into how changes in one variable are related to changes in another variable, controlling for initial levels."
  },
  {
    "objectID": "3a_HowTos_LinearMixedModels.html",
    "href": "3a_HowTos_LinearMixedModels.html",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "",
    "text": "The LMM:ri is similar to traditional (fixed-effect) linear regression extending on this approach by including a subject-specific random-effect that allows each participant to have their own unique intercept value, in addition to the overall mean-level (fixed-effect) intercept value zzzzt\nIn this example, we will use the LMM:ri to analyze trajectories of scores on the externalizing subscale of the child behavior checklist (CBCL) obtained across three measurement occasions in a sample of youth taking part in the ABCD Study. Our primary aim is to characterize stability and change in CBCL externalizing scores across assessments, while accounting for observations that are clustered within youth over time. To do so, we will use the LMM:ri to simultaneously model an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory."
  },
  {
    "objectID": "3a_HowTos_LinearMixedModels.html#linear-mixed-model-with-a-random-intercept-lmmri",
    "href": "3a_HowTos_LinearMixedModels.html#linear-mixed-model-with-a-random-intercept-lmmri",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "",
    "text": "The LMM:ri is similar to traditional (fixed-effect) linear regression extending on this approach by including a subject-specific random-effect that allows each participant to have their own unique intercept value, in addition to the overall mean-level (fixed-effect) intercept value zzzzt\nIn this example, we will use the LMM:ri to analyze trajectories of scores on the externalizing subscale of the child behavior checklist (CBCL) obtained across three measurement occasions in a sample of youth taking part in the ABCD Study. Our primary aim is to characterize stability and change in CBCL externalizing scores across assessments, while accounting for observations that are clustered within youth over time. To do so, we will use the LMM:ri to simultaneously model an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory."
  },
  {
    "objectID": "3a_HowTos_LinearMixedModels.html#preliminary-setup",
    "href": "3a_HowTos_LinearMixedModels.html#preliminary-setup",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nLoad LibrariesLoad PackagesConfig Options\n\n\nexample-text before code block\n\n\n\nCode\n## Install necessary packages (if not already installed)\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nif (!(\"lmerTest\" %in% installed.packages())) install.packages(\"lmerTest\")\nif (!(\"tidyverse\" %in% installed.packages())) install.packages(\"tidyverse\")\nif (!(\"arrow\" %in% installed.packages())) install.packages(\"arrow\")\nif (!(\"afex\" %in% installed.packages())) install.packages(\"afex\")\nif (!(\"janitor\" %in% installed.packages())) install.packages(\"janitor\")\nif (!(\"skimr\" %in% installed.packages())) install.packages(\"skimr\")\nif (!(\"sdamr\" %in% installed.packages())) install.packages(\"sdamr\")\nif (!(\"formatR\" %in% installed.packages())) install.packages(\"formatR\")\nif (!(\"report\" %in% installed.packages())) install.packages(\"report\")\nif (!(\"easystats\" %in% installed.packages())) install.packages(\"easystats\")\nif (!(\"emmeans\" %in% installed.packages())) install.packages(\"emmeans\")\nif (!(\"poorman\" %in% installed.packages())) install.packages(\"poorman\")\nif (!(\"parameters\" %in% installed.packages())) install.packages(\"parameters\")\nif (!(\"modelbased\" %in% installed.packages())) install.packages(\"modelbased\")\nif (!(\"DT\" %in% installed.packages())) install.packages(\"DT\")\nif (!(\"data.table\" %in% installed.packages())) install.packages(\"data.table\")\nif (!(\"arsenal\" %in% installed.packages())) install.packages(\"arsenal\")\nif (!(\"kableExtra\" %in% installed.packages())) install.packages(\"kableExtra\")\nif (!(\"equatiomatic\" %in% installed.packages())) install.packages(\"equatiomatic\")\nif (!(\"gtsummary\" %in% installed.packages())) install.packages(\"gtsummary\")\n\n\n\nexample-text after code block\n\n\n\n\n\nCode\n## Load packages\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(afex)\nlibrary(janitor)\nlibrary(skimr)\nlibrary(sdamr)\nlibrary(formatR)\nlibrary(report)\nlibrary(easystats)\nlibrary(emmeans)\nlibrary(poorman)\nlibrary(parameters)\nlibrary(modelbased)\nlibrary(DT)\nlibrary(data.table)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(equatiomatic)\nlibrary(gtsummary)\n\n\n\n\n\n\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220), fig.align='center', \n                      out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "3a_HowTos_LinearMixedModels.html#descriptives-overview",
    "href": "3a_HowTos_LinearMixedModels.html#descriptives-overview",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Descriptives Overview",
    "text": "Descriptives Overview\n\nData TableDescriptives\n\n\n\n\n\nCode\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\n#df_long_sub&lt;- read_csv(\"/Users/shawes/Desktop/df_long_sub.csv\")\n\n## Create a viewable 'datatable' of the primary dataframe (df)\ndatatable(head(df_long, 50, rownames = FALSE),extensions = 'AutoFill','ColReorder', options = list(autoFill = TRUE,colReorder = TRUE,\n  columnDefs = list(list(className = 'dt-center', targets = 10)),\n  order = list(list(3, 'asc'), list(4, 'desc')),\n  pageLength = 10,\n  lengthMenu = c(10, 15, 20),\n  initComplete = JS(\n    \"function(settings, json) {\",\n    \"$(this.api().table().header()).css({'background-color': '#808080', 'color': '#fff'});\",\n    \"}\")\n))\n\n\n\n\n\n\n\nCode\n## Not run: \n# Specify table size by pixels\n#kable(cbind(df_long, df_long), \"html\") %&gt;%\n#    kable_styling() %&gt;%\n#    scroll_box(width = \"100%\", height = \"500px\")\n\n\n\n\n\n\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ndescriptives_1  &lt;- tableby.control(test=FALSE, total=FALSE,\n                               numeric.test=\"kwt\", cat.test=\"chisq\",\n                               numeric.stats=c(\"N\", \"meansd\", \"median\", \"range\" \n                                               ), #\"Nmiss2\"\n                               cat.stats=c(\"countpct\"), #\"Nmiss2\"\n                               stats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n                                                 ='Median', range='Min - Max'\n                                                 )) #, Nmiss2 ='Missing'\n\nmy_cont_labels &lt;- list(\n  age = \"Age\",\n  vg_total = \"Weekly # of Video Gaming Hrs\",\n  cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                            cbcl_extern,\n                            data=df_long, control=descriptives_1)\n\n#summary(tab_descriptives_1, labelTranslations = my_cont_labels , text=TRUE, title = #\"Continuous Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ndescriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\n                               numeric.test=\"kwt\", cat.test=\"chisq\",\n                               numeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n                                               ), # \"Nmiss2\"\n                               cat.stats=c(\"countpct\"), # \"Nmiss2\"\n                               stats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n                                                 ='Median', range='Min - Max'\n                                                 )) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n\ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, \n                            data=df_long, control=descriptives_2)\n\n#summary(tab_descriptives_2, labelTranslations = my_cat_labels , text=TRUE, title = #\"Categorical Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n  summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n  kable(caption = \"Categorical Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table."
  },
  {
    "objectID": "3a_HowTos_LinearMixedModels.html#results",
    "href": "3a_HowTos_LinearMixedModels.html#results",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Results",
    "text": "Results\n\nBuild ModelModel OutputModel Report\n\n\n\n\n\nCode\n## Linear Mixed Model with a random intercept (LMM-ri)\nrandom_intercepts &lt;- lmer(cbcl_extern ~ 1 + event + sex + (1|ids), data = df_long, REML=T)\n\nprint(random_intercepts)\n\n\nLinear mixed model fit by REML ['lmerModLmerTest']\nFormula: cbcl_extern ~ 1 + event + sex + (1 | ids)\n   Data: df_long\nREML criterion at convergence: 588.7995\nRandom effects:\n Groups   Name        Std.Dev.\n ids      (Intercept) 5.020   \n Residual             3.587   \nNumber of obs: 99, groups:  ids, 37\nFixed Effects:\n(Intercept)  eventYear_1  eventYear_2      sexMale  \n     4.3204       0.7650       1.7481       0.5837  \n\n\n\n\nThe code snippet above tells R to run a linear mixed model using lmer from the lme4 library. The left side of the “~” symbol specifies the dependent variable; the right side specifies days as the independent variable(s). The code (1 | Subject) specifies a random intercept for each subject.\n\n\n\n\n\n\ntesting\n## Output and reports extending from the LMM-ri analyses\nsummary(random_intercepts)\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: cbcl_extern ~ 1 + event + sex + (1 | ids)\n   Data: df_long\n\nREML criterion at convergence: 588.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.7239 -0.4710 -0.1888  0.2910  2.9047 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ids      (Intercept) 25.20    5.020   \n Residual             12.86    3.587   \nNumber of obs: 99, groups:  ids, 37\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)   \n(Intercept)   4.3204     1.3277 46.9852   3.254  0.00211 **\neventYear_1   0.7650     0.8768 62.6158   0.873  0.38626   \neventYear_2   1.7481     0.9173 63.4712   1.906  0.06123 . \nsexMale       0.5837     1.8240 36.0452   0.320  0.75081   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) evnY_1 evnY_2\neventYear_1 -0.343              \neventYear_2 -0.317  0.475       \nsexMale     -0.631  0.032  0.013\n\n\ntesting\nconfint(random_intercepts, level = 0.95, method = \"Wald\")\n\n\n                  2.5 %   97.5 %\n.sig01               NA       NA\n.sigma               NA       NA\n(Intercept)  1.71808695 6.922714\neventYear_1 -0.95342829 2.483383\neventYear_2 -0.04987969 3.546050\nsexMale     -2.99121329 4.158581\n\n\ntesting\nreport(random_intercepts)\n\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\nto predict cbcl_extern with event and sex (formula: cbcl_extern ~ 1 + event +\nsex). The model included ids as random effect (formula: ~1 | ids). The model's\ntotal explanatory power is substantial (conditional R2 = 0.67) and the part\nrelated to the fixed effects alone (marginal R2) is of 0.02. The model's\nintercept, corresponding to event = Baseline and sex = Female, is at 4.32 (95%\nCI [1.68, 6.96], t(93) = 3.25, p = 0.002). Within this model:\n\n  - The effect of event [Year_1] is statistically non-significant and positive\n(beta = 0.76, 95% CI [-0.98, 2.51], t(93) = 0.87, p = 0.385; Std. beta = 0.12,\n95% CI [-0.16, 0.40])\n  - The effect of event [Year_2] is statistically non-significant and positive\n(beta = 1.75, 95% CI [-0.07, 3.57], t(93) = 1.91, p = 0.060; Std. beta = 0.28,\n95% CI [-0.01, 0.58])\n  - The effect of sex [Male] is statistically non-significant and positive (beta\n= 0.58, 95% CI [-3.04, 4.21], t(93) = 0.32, p = 0.750; Std. beta = 0.09, 95% CI\n[-0.49, 0.68])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\ntesting\nreport_performance(random_intercepts)\n\n\nThe model's total explanatory power is substantial (conditional R2 = 0.67) and\nthe part related to the fixed effects alone (marginal R2) is of 0.02\n\n\ntesting\nreport_statistics(random_intercepts)\n\n\nbeta = 4.32, 95% CI [1.68, 6.96], t(93) = 3.25, p = 0.002; Std. beta = -0.22, 95% CI [-0.64, 0.21]\nbeta = 0.76, 95% CI [-0.98, 2.51], t(93) = 0.87, p = 0.385; Std. beta = 0.12, 95% CI [-0.16, 0.40]\nbeta = 1.75, 95% CI [-0.07, 3.57], t(93) = 1.91, p = 0.060; Std. beta = 0.28, 95% CI [-0.01, 0.58]\nbeta = 0.58, 95% CI [-3.04, 4.21], t(93) = 0.32, p = 0.750; Std. beta = 0.09, 95% CI [-0.49, 0.68]\n\n\ntesting\nrandom &lt;- estimate_grouplevel(random_intercepts)\n\n\n\n\n\n\n\n\nCode\n#df_long %&gt;%\n#  report() %&gt;%\n#  summary()"
  },
  {
    "objectID": "3a_HowTos_LinearMixedModels.html#visualizations",
    "href": "3a_HowTos_LinearMixedModels.html#visualizations",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Visualizations",
    "text": "Visualizations\n\nExtract ParamsDiagnostic PlotsBar PlotRandom Intercept LMM Plot/Graph\n\n\n\n\n\nCode\n## Obtain LMM-ri model parameters to plot/graph of results\nmodel_intercept &lt;- as.numeric(fixef(random_intercepts)[1])\nmodel_slope &lt;- as.numeric(fixef(random_intercepts)[2])\n\n\n\n\nThis code allows for extracting the fixed effects estimates for the model intercept and slope.\n\n\n\n\n\nExtract the individual participant intercepts (random effects) for this model and add it to the data frame for plotting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild diagnostic plots. Observations with a Bonferroni p &lt; .05 might be considered as outliers and might need further investigation.\n\n\n\n\n\nCode\n# Basic ggplot2 barplot with mean\np&lt;-df_long %&gt;%\n    filter(!is.na(mature_vg)) %&gt;% # filter on non-missing values  \n    ggplot(aes(x = mature_vg, y = cbcl_extern, fill = sex)) +\n    geom_col(position = \"dodge\",\n           stat = \"summary\",\n           fun = \"mean\",\n           #fill = \"#AA4A44\",\n           #color = \"#0099f9\"\n           ) +\n    #scale_fill_brewer(palette = \"Set1\") +\n    scale_fill_manual(values = c(\"#3db5ff\", \"#0099f9\")) +\n    #scale_fill_gradient(high = \"#B00B69\", low = \"#0e0e63\") +\n    #geom_text(aes(label = cu_traits), position = position_dodge(0.9), \n              #vjust = 2, size = 4, color = \"#ffffff\") +\n    labs(title = \"Behavior Problems by Video Game Groups\", subtitle = \"Simple bar chart\",\n         caption = \"Simple caption\", x = \"DBD Group\", y = \"CBCL Externalizing\") +\n              #coord_flip() +\n    #geom_hline(yintercept = mean(df$cbcl_agg), linetype = \"dashed\", size = 1) +\n    theme_minimal() +\n    theme(\n          plot.title = element_text(color = \"#0099f9\", size = 20, hjust = 0.5),\n          plot.subtitle = element_text(face = \"bold\", hjust = 1),\n          plot.caption = element_text(face = \"italic\", hjust = 0),\n          axis.title.x = element_text(color = \"#0099f9\", size = 15, face = \"bold\"),\n          axis.title.y = element_text(size = 15, face = \"italic\")\n  )\np\n\n\n\n\n\n\n\n\n\n\nCode\n#random_intercepts &lt;- lmer(Externalizing ~ 1 + Event + DBD + Sex + (1|ids), data = df, #REML=T)\n\n## LMM-ri plot of estimated random intercepts \nmodel &lt;- lmer(cbcl_extern ~ mature_vg + (1 | sex), data = df_long)\npreds &lt;- estimate_relation(model, include_random = TRUE)\n\n## Adding fixed effect trajectory to LMM-ri plot \nfixed_pred &lt;- estimate_relation(model) # This time, include_random is FALSE (default)\nplot(preds, ribbon = list(alpha = 0)) + # Previous plot\n  geom_ribbon(data = fixed_pred, aes(x = mature_vg, ymin = CI_low, ymax = CI_high), alpha = 0.4) +\n  geom_line(data = fixed_pred, aes(x = mature_vg, y = Predicted), size = 2)\n\n\n\n\n\nThis is a caption for my figure, using YAML formatting, etc.#|\n\n\n\n\nCode\n######\n# ggplot(df_long_sub, aes(x = event, y = cbcl_agg, color=sex, shape=sex)) + \n# geom_abline(slope = model_slope, intercept = model_intercept, linetype = \"solid\", color = \"red\", linewidth = 1) + \n# geom_point(color = \"grey70\") + \n# geom_smooth(method=lm, se=FALSE, fullrange=TRUE)+\n# scale_shape() + \n# geom_segment(aes(x = event, xend = event, y = cbcl_agg, yend = fitted(cbcl_agg)), color = \"grey70\") + \n# scale_y_continuous(expand = c(0, 0), breaks = c(0, 20, 40, 60, 80, 100), limits = c(0, 100)) + \n# scale_x_continuous(expand = c(0, 0), breaks = c(1, 2, 3, 4), limits = c(0, 4)) +\n# theme(panel.background = element_blank(),         \n#         panel.grid.major = element_blank(),\n#         panel.grid.minor = element_blank(),\n#         panel.border = element_rect(colour = \"black\", fill = NA),\n#         legend.position = \"none\",\n#         axis.text = element_text(size = 14), \n#         axis.title = element_text(size = 14)) +\n#         labs (x = \"Event\", y= \"CBCL Aggression\")\n\n#Save the plot\n#ggsave(\"random_intercept.png\", units = \"in\", width = 9, height = 6, dpi = 300)  \n\n\n\n\n\n\n\nFigure x: The overall group-mean (fixed effects) trajectory is shown in blue. The faded lines represent each individual youth’s estimated trajectory. An examination of this figure shows happiness scores to be increasing across measurement occasions, however, there appears to be substantial variability in the youth’s initial happiness scores.\n\n\nInterpretation\nThe estimated correlation between x and y was “r cor(x,y). There are \"r nrow(my_data) individuals.\nFrom the fixed effects section of the model summary, we can conclude that there is strong evidence that RT increased significantly over time (i.e., # of years). On average for each additional year, RT increased by 10.46 (b = 10.46, SE = 0.80, p &lt; .001).We are 95% confident that the average increase was between 8.89 and 12.04.\nIn the above, we estimate that the average intercept across all participants is 251.4. Results from the random effects section below show that the variance of the intercept for Subject is 1378.2. Taking the square root, the standard deviation of the intercept is thus 37.1.\nWe can calculate the 95% coverage interval as 251.4 ± 1.96*37.1. The lower bound of the 95% coverage interval is thus 178.7 and the upper bound is 324.1. We therefore estimated that 95% of the participants have an intercept between 178.7 and 324.1. This means that 95% of the participants have a reaction time between 178.7 and 324.1 at Day 0. This is not to be confused with the 95% confidence interval of the intercept. The 95% confidence interval is (232.3, 270.5), and this indicates that we are 95% confident that the average intercept is somewhere between 232.3 and 270.5.\nIn this model, we have accounted for the repeated measures design (observations nested within individuals) by including a random intercept for each participants. Each individual has his/her own intercept. The effect of time(Year) on RT is assumed to be the same across individuals. This assumption can be relaxed by fitting a random slope model.\n\n\nMock Write-up\nA random slope model is used to test if sleep deprivation affects reaction time. To account for the repeated measures design, a random intercept was specified for participants. The random slope for days of sleep deprivation was included in the model to allow the effect of sleep deprivation to vary across participants. Results are shown in Table 1. Using a significant level of 0.05, results indicate that sleep deprivation significantly increased reaction time. On average, each additional day of sleep deprivation increased reaction time by 10.47ms (b = 10.47, 95% CI = [7.44, 13.50], p &lt; .001). Model fit comparison between model with and without random slope for sleep deprivation shows that the effect of sleep deprivation varied across participants, χ2(2)= 42.14, p &lt; .001. The 95% coverage interval for the random slope of sleep deprivation is (-1.14, 22.07), indicating that the effect of sleep deprivation was between -1.14 and 22.07 for 95% of the participants. :::"
  },
  {
    "objectID": "3a_HowTos_LinearMixedModels.html#references",
    "href": "3a_HowTos_LinearMixedModels.html#references",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "References",
    "text": "References\n(brown2021?)"
  },
  {
    "objectID": "1b_HowTos_DifferenceScores_SimpleRegression.html#overview-1",
    "href": "1b_HowTos_DifferenceScores_SimpleRegression.html#overview-1",
    "title": "Difference Scores: Simple Regression",
    "section": "Overview",
    "text": "Overview\n\nThis example will examine whether average change in CBCL externalizing scores from Basline (T0) to the 1-Year follow-up (T1) differs significantly between boys and girls taking part in the ABCD Study. This analysis is conducted in two primary steps: 1) computing a difference score (DiffScore = CBCL EXT T2 - CBCL EXT T1); 2) conducting a simple regression on the difference score. Our primary aim is to determine whether group membership (boys, girls) predict the average difference value in CBCL externalizing scores from T1 to T2."
  },
  {
    "objectID": "1b_HowTos_DifferenceScores_SimpleRegression.html#preliminary-setup",
    "href": "1b_HowTos_DifferenceScores_SimpleRegression.html#preliminary-setup",
    "title": "Difference Scores: Simple Regression",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\n#rm(list = ls())\n\n#Load packages\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(arsenal)\nlibrary(kableExtra)\nlibrary(rstatix)\nlibrary(ggpubr)\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                                  comment=NA, cache=T, code_folding=T,\n                                  R.options=list(width=220), fig.align='center', \n                                  out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "1b_HowTos_DifferenceScores_SimpleRegression.html#descriptives-overview",
    "href": "1b_HowTos_DifferenceScores_SimpleRegression.html#descriptives-overview",
    "title": "Difference Scores: Simple Regression",
    "section": "Descriptives Overview",
    "text": "Descriptives Overview\n\nRead and View Data\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n## Read data\ndf_long&lt;- read_csv(\"/Users/shawes/Desktop/data/df_long.csv\")\ndf_wide &lt;- read_csv(\"/Users/shawes/Desktop/data/df_wide.csv\")\nstr(df_wide)\n\n\nspc_tbl_ [99 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ids                 : num [1:99] 1 2 3 4 5 6 7 8 9 10 ...\n $ site_id             : chr [1:99] \"site06\" \"site06\" \"site06\" \"site10\" ...\n $ fam_id              : num [1:99] 8781 8781 8781 10210 10210 ...\n $ sex                 : chr [1:99] \"Female\" \"Female\" \"Female\" \"Female\" ...\n $ age                 : num [1:99] 9 10 9 9 9 10 10 10 10 9 ...\n $ mature_vg           : num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ vg_total_Year_1     : num [1:99] 7 7 7 7 4 0 4 1 1 2 ...\n $ vg_total_Baseline   : num [1:99] 4 7 4 2 42 0 4 2 2 2 ...\n $ vg_total_Year_2     : num [1:99] 1 1 2 0 3 0 2 2 7 3 ...\n $ cbcl_extern_Year_1  : num [1:99] 7 7 7 7 2 0 4 1 1 2 ...\n $ cbcl_extern_Baseline: num [1:99] 0 1 0 1 0 0 0 1 1 0 ...\n $ cbcl_extern_Year_2  : num [1:99] 7 7 7 7 4 6 4 4 2 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ids = col_double(),\n  ..   site_id = col_character(),\n  ..   fam_id = col_double(),\n  ..   sex = col_character(),\n  ..   age = col_double(),\n  ..   mature_vg = col_double(),\n  ..   vg_total_Year_1 = col_double(),\n  ..   vg_total_Baseline = col_double(),\n  ..   vg_total_Year_2 = col_double(),\n  ..   cbcl_extern_Year_1 = col_double(),\n  ..   cbcl_extern_Baseline = col_double(),\n  ..   cbcl_extern_Year_2 = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nCode\n# set types\ndf_long$ids &lt;- as.factor(df_long$ids)\ndf_long$event &lt;- as.factor(df_long$event)\ndf_long$site_id &lt;- as.factor(df_long$site_id)\ndf_long$fam_id &lt;- as.factor(df_long$fam_id)\ndf_long$sex &lt;- as.factor(df_long$sex)\ndf_long$age &lt;- as.numeric(df_long$age)\ndf_long$mature_vg &lt;- as.numeric(df_long$mature_vg)\ndf_long$cbcl_extern &lt;- as.numeric(df_long$cbcl_extern)\ndf_long$vg_total &lt;- as.numeric(df_long$vg_total)\n\n\n\n\n\n\n\nContinuous Outcomes\n\nThis code creates a table of descriptive information for continuous outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_1 &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\" \n), #\"Nmiss2\"\ncat.stats=c(\"countpct\"), #\"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n))  # , Nmiss2 ='Missing'\n\nmy_cont_labels &lt;- list(\n  age = \"Age\",\n  vg_total = \"Weekly # of Video Gaming Hrs\",\n  cbcl_extern = \"CBCL Externalizing Scale\"\n)\n\ntab_descriptives_1 &lt;- tableby(event ~ age + vg_total + \n                                      cbcl_extern,\n                                      data=df_long, control=tab_descriptives_1)\n          \n#summary(tab_descriptives_1, labelTranslations = my_cont_labels , text=TRUE, title = #\"Continuous Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_1 %&gt;%\n                summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Continuous Outcomes\") %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE, html_font = \"Cambria\",\n                font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n  column_spec(2, width = \"20em\", border_right = T) %&gt;%\n            column_spec(3, width = \"20em\", border_right = T) %&gt;%\n            footnote(general = \"Here is a general comments of the table. \") %&gt;%\n            scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nContinuous Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nage\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n9.3 (0.5)\n9.5 (0.5)\n9.6 (0.5)\n\n\n- Median\n9.0\n9.5\n10.0\n\n\n- Min - Max\n9.0 - 10.0\n9.0 - 10.0\n9.0 - 10.0\n\n\nvg_total\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n8.7 (8.4)\n8.7 (8.1)\n6.8 (4.3)\n\n\n- Median\n6.0\n7.0\n7.0\n\n\n- Min - Max\n0.0 - 28.0\n0.0 - 28.0\n1.0 - 16.0\n\n\ncbcl_extern\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n4.8 (5.7)\n5.5 (6.1)\n6.9 (6.9)\n\n\n- Median\n3.0\n4.0\n4.5\n\n\n- Min - Max\n0.0 - 21.0\n0.0 - 25.0\n0.0 - 25.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategorical Outcomes\n\nThis code creates a descriptives table for categorical outcomes\n\n\nCode\n## Create a descriptives table of study variables by measurement occasion \ntab_descriptives_2  &lt;- tableby.control(test=FALSE, total=FALSE,\nnumeric.test=\"kwt\", cat.test=\"chisq\",\nnumeric.stats=c(\"N\", \"meansd\", \"median\", \"range\"\n), # \"Nmiss2\"\ncat.stats=c(\"countpct\"), # \"Nmiss2\"\nstats.labels=list(N='Count', meansd=\"Mean (SD)\", median\n='Median', range='Min - Max'\n)) # , Nmiss2 ='Missing'\n\nmy_cat_labels  &lt;- list(\n  event = \"Year\",\n  sex = \"Sex\",\n  mature_vg = \"Mature Video Games\"\n  )\n          \ntab_descriptives_2 &lt;- tableby(event ~ sex + mature_vg, data=df_long, control=tab_descriptives_2)\n\n#summary(tab_descriptives_2, labelTranslations = my_cat_labels , text=TRUE, title = #\"Categorical Outcomes\", term.name = TRUE)\n\n# Push table object through kable and kable_styling\ntab_descriptives_2 %&gt;%\n            summary(text=TRUE, digits.pct=1, digits=1) %&gt;%\n            kable(caption = \"Categorical Outcomes\") %&gt;%\n            kable_styling(bootstrap_options = \"striped\", full_width = FALSE, font_size = 15,\n                position = \"center\", fixed_thead = T) %&gt;%\n  row_spec(2:3,  bold = F, extra_css = 'vertical-align: middle !important;') %&gt;%\n  column_spec(1, width = \"20em\", background = \"light grey\", bold = T, border_right = T) %&gt;%\n            column_spec(2, width = \"20em\", border_right = T) %&gt;%\n  #column_spec(3, width = \"20em\", border_right = T) %&gt;%\n  footnote(general = \"Here is a general comments of the table. \") %&gt;%\n  scroll_box(width = \"75%\", height = \"500px\")\n\n\n\n\nCategorical Outcomes\n\n\n\nBaseline (N=35)\nYear_1 (N=34)\nYear_2 (N=30)\n\n\n\n\nsex\n\n\n\n\n\n- Female\n19 (54.3%)\n20 (58.8%)\n17 (56.7%)\n\n\n- Male\n16 (45.7%)\n14 (41.2%)\n13 (43.3%)\n\n\nmature_vg\n\n\n\n\n\n- Count\n35\n34\n30\n\n\n- Mean (SD)\n0.6 (0.9)\n1.7 (6.3)\n0.6 (0.9)\n\n\n- Median\n0.0\n0.0\n0.0\n\n\n- Min - Max\n0.0 - 3.0\n0.0 - 37.0\n0.0 - 3.0\n\n\n\nNote: \n\n\n\n\n\n Here is a general comments of the table.\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "1b_HowTos_DifferenceScores_SimpleRegression.html#results",
    "href": "1b_HowTos_DifferenceScores_SimpleRegression.html#results",
    "title": "Difference Scores: Simple Regression",
    "section": "Results",
    "text": "Results\n\n\n::: panel-tabset ### Build Model {.tabset .tabset-fade .tabset-pills}\n\nThe code snippet below tells R to compute a difference score by subtracting each participant’s Externalizing score at T2 from their Externalizing score at T1. Next, a simple regression analyses is conducted to examine whether a grouping variable (participant sex) significantly predicts the difference score value (indicating significant group differences in the average difference score). The simple regression function (lm) is provided by the r ‘stats’ package.\nxxx First, compute the difference (\\Delta) between a score on some measure (x) assessed at baseline (x_{t1}) and follow-up (x_{t2}). The result of this formula (\\Delta=x_{t2} - x_{t1}) can be included as the outcome variable in a regression model that analyzes the role of the grouping variable (e.g., 0 = boy; 1 = girl) on changes in scores on the measure across follow-ups. xxx\nSTEP 1: Compute Difference Score\n\n\nCode\n# Compute difference score based on CBCL Externalizing subscale scores at baseline (t1) and 1-Year Follow-up (t2)\ndf_wide$diffscore &lt;- (df_wide$cbcl_extern_Year_1 - df_wide$cbcl_extern_Baseline)\n\n\n\n\nCode\n# Compute statistical summaries for the difference score variable\nsummary(df_wide$diffscore)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-27.000   1.000   5.000   5.576   8.000  33.000 \n\n\nThis summary of the difference score variable indicates xxxxx.\n\n\nCode\nhist(df_long$vg_total)\n\n\n\n\n\nCode\n## Summary statistics\nsummary&lt;-df_long %&gt;%\ngroup_by(event) %&gt;%\nget_summary_stats(cbcl_extern, type = \"mean_sd\")\ndata.frame(summary)\n\n\n\n\n  \n\n\n\nThis histogram indicates xxxxxx. The summary command shows xxxxxx.\n\n\nCode\n### Shapiro-Wilk test and normality (Q-Q) plot (visualization of correlation between a given sample and the normal distribution)\nshapiro.test(df_wide$cbcl_extern_Baseline[0:5000])\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  df_wide$cbcl_extern_Baseline[0:5000]\nW = 0.67151, p-value = 1.452e-13\n\n\nThis Shapiro-wilkes test shows xxxxxx.\n\n\nCode\nqqplot &lt;- ggqqplot(df_wide$cbcl_extern_Baseline,\n    ylab = \"Externalizing Difference Score\", xlab = FALSE,\n    ggtheme = theme_minimal()\n)\n\nsuppressWarnings(print(qqplot)) \n\n\n\n\n\nThis qqplot shows xxxxxx.\nSTEP 2: Conduct simple regression on Difference Score\n\n\nCode\n#Simple linear regression is used to examine the relationship between a continuous predictor variable and the average difference score.\n\n#Regression model\nresult &lt;- lm(df_wide$diffscore ~ vg_total_Baseline, data = df_wide)\n#summarize the reults\nsummary(result)\n\n\n\nCall:\nlm(formula = df_wide$diffscore ~ vg_total_Baseline, data = df_wide)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.022  -4.685  -0.387   2.091  28.315 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        4.57285    1.18272   3.866   0.0002 ***\nvg_total_Baseline  0.11219    0.08052   1.393   0.1667    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.337 on 97 degrees of freedom\nMultiple R-squared:  0.01962,   Adjusted R-squared:  0.009511 \nF-statistic: 1.941 on 1 and 97 DF,  p-value: 0.1667\n\n\nThe output from our model provides: i. a parameter estimate; ii. standard error; iii. p-value. In our example p = .001 which is less than .05 indicating significant differences in predicted cbcl externalizing scores between boys and girls in the ABCD Study. An examination of the regression coeefficient for sex (female = 0; male = 1) is b = .xx, indicating the difference in cbcl externalizing scores from Time 1 to Time 2 is significantly greater in boys taking part in the ABCD Study relative to girls. Then we conclude that participant sex (does/does not) predict change in cbcl externalizing scores from t1 to t2.\n\nModel Plots\n\n\n\ntesting\n#Scatterplot to visualize relationship between a continuous predictor and a difference score\nscatterplot &lt;- ggplot (df_wide, aes(x = diffscore, y = vg_total_Baseline)) + geom_point(size = 3) + geom_smooth(method = lm, se = F) +\nxlab(\"Difference Score (x)\") +\nylab(\"Screentime hours (y) Baseline\")\n\nsuppressWarnings(print(scatterplot))\n\n\n\n\n\nExamination of this scatterplot indicates xxxxx.\n\n\nThis output shows xxxxxxxx. Briefly walk through each metric"
  },
  {
    "objectID": "1b_HowTos_DifferenceScores_SimpleRegression.html#wrapping-up",
    "href": "1b_HowTos_DifferenceScores_SimpleRegression.html#wrapping-up",
    "title": "Difference Scores: Simple Regression",
    "section": "Wrapping Up",
    "text": "Wrapping Up\n\n\n\n\n\nWrite-up\n\n\n\nA simple regression analysis was conducted to examine whether participant’s sex predicted change in cbcl externalzing scores measured across two timepoints. Findings showed a significant positive effect such that boys demonstrated increases in cbcl externalzing scores relative to girls (b = .xx; SE = .xx; p = .xx)"
  }
]